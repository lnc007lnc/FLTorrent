#!/usr/bin/env python3
"""
FederatedScope BitTorrentä¼˜å…ˆçº§è¯·æ±‚ç®¡ç†è§£å†³æ–¹æ¡ˆ
è§£å†³ä¼˜å…ˆçº§åè½¬å’Œè¯·æ±‚é˜»å¡é—®é¢˜
"""

import heapq
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class ChunkRequest:
    """Chunkè¯·æ±‚ä¿¡æ¯"""
    peer_id: int
    round_num: int
    source_client_id: int
    chunk_id: int
    importance_score: float
    timestamp: float
    requester_id: int  # è¯·æ±‚æ–¹ID


class PriorityRequestManager:
    """ä¼˜å…ˆçº§è¯·æ±‚ç®¡ç†å™¨ - è§£å†³BitTorrentä¼˜å…ˆçº§åè½¬é—®é¢˜"""
    
    def __init__(self, client_id: int):
        self.client_id = client_id
        
        # ğŸ“Š Configuration - ç»å…¸BitTorrentå‚æ•°
        self.MAX_CONCURRENT_REQUESTS_PER_PEER = 5  # æ¯ä¸ªpeeræœ€å¤š5ä¸ªå¹¶å‘è¯·æ±‚
        self.MAX_TOTAL_CONCURRENT_REQUESTS = 20    # æ€»å…±æœ€å¤š20ä¸ªå¹¶å‘è¯·æ±‚
        self.REQUEST_TIMEOUT = 10.0                # è¯·æ±‚è¶…æ—¶æ—¶é—´
        self.PRIORITY_REEVALUATION_INTERVAL = 2.0  # ä¼˜å…ˆçº§é‡è¯„ä¼°é—´éš”
        
        # ğŸ“‹ Request tracking
        self.pending_requests: Dict[Tuple, ChunkRequest] = {}  # {(round,source,chunk): request}
        self.requests_per_peer: Dict[int, int] = {}           # {peer_id: count}
        
        # ğŸ¯ Priority upload queue (for handling incoming requests)
        self.upload_queue: List[Tuple] = []  # Priority queue: (-importance, timestamp, request)
        
        # â° Timing
        self.last_reevaluation = time.time()
        
    # =================== REQUEST SENDING (ä¸‹è½½ç«¯) ===================
    
    def can_make_request(self, peer_id: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å‘æŒ‡å®špeerå‘é€æ›´å¤šè¯·æ±‚"""
        # æ£€æŸ¥per-peeré™åˆ¶
        peer_requests = self.requests_per_peer.get(peer_id, 0)
        if peer_requests >= self.MAX_CONCURRENT_REQUESTS_PER_PEER:
            return False
            
        # æ£€æŸ¥å…¨å±€é™åˆ¶
        if len(self.pending_requests) >= self.MAX_TOTAL_CONCURRENT_REQUESTS:
            return False
            
        return True
    
    def make_request(self, peer_id: int, round_num: int, source_client_id: int, 
                    chunk_id: int, importance_score: float) -> bool:
        """å‘é€chunkè¯·æ±‚ï¼ˆå¸¦ä¼˜å…ˆçº§æ§åˆ¶ï¼‰"""
        
        if not self.can_make_request(peer_id):
            # å°è¯•å–æ¶ˆä½ä¼˜å…ˆåº¦è¯·æ±‚ä¸ºé«˜ä¼˜å…ˆåº¦è®©è·¯
            if self._try_cancel_low_priority_request(importance_score):
                pass  # æˆåŠŸå–æ¶ˆï¼Œå¯ä»¥ç»§ç»­
            else:
                return False  # æ— æ³•å‘é€è¯·æ±‚
        
        # åˆ›å»ºè¯·æ±‚
        chunk_key = (round_num, source_client_id, chunk_id)
        request = ChunkRequest(
            peer_id=peer_id,
            round_num=round_num,
            source_client_id=source_client_id,
            chunk_id=chunk_id,
            importance_score=importance_score,
            timestamp=time.time(),
            requester_id=self.client_id
        )
        
        # è®°å½•è¯·æ±‚
        self.pending_requests[chunk_key] = request
        self.requests_per_peer[peer_id] = self.requests_per_peer.get(peer_id, 0) + 1
        
        print(f"ğŸš€ Client {self.client_id}: Made request to peer {peer_id} for chunk "
              f"{source_client_id}:{chunk_id} (importance: {importance_score:.4f}, "
              f"pending: {len(self.pending_requests)})")
        
        return True
    
    def _try_cancel_low_priority_request(self, new_importance: float) -> bool:
        """å°è¯•å–æ¶ˆä½ä¼˜å…ˆåº¦è¯·æ±‚ä¸ºé«˜ä¼˜å…ˆåº¦è¯·æ±‚è®©è·¯"""
        
        # æ‰¾åˆ°æœ€ä½ä¼˜å…ˆåº¦çš„è¯·æ±‚
        lowest_priority = float('inf')
        lowest_request_key = None
        
        for chunk_key, request in self.pending_requests.items():
            if request.importance_score < lowest_priority:
                lowest_priority = request.importance_score
                lowest_request_key = chunk_key
        
        # å¦‚æœæ–°è¯·æ±‚ä¼˜å…ˆåº¦æ˜¾è‘—æ›´é«˜ï¼Œå–æ¶ˆæ—§è¯·æ±‚
        if lowest_request_key and new_importance > lowest_priority * 1.5:  # 50%æå‡é˜ˆå€¼
            canceled_request = self.pending_requests[lowest_request_key]
            self.cancel_request(lowest_request_key)
            
            print(f"ğŸš« Client {self.client_id}: Canceled low-priority request "
                  f"{canceled_request.source_client_id}:{canceled_request.chunk_id} "
                  f"(importance: {canceled_request.importance_score:.4f}) "
                  f"for higher priority request (importance: {new_importance:.4f})")
            
            return True
        
        return False
    
    def cancel_request(self, chunk_key: Tuple):
        """å–æ¶ˆæŒ‡å®šçš„chunkè¯·æ±‚"""
        if chunk_key in self.pending_requests:
            request = self.pending_requests[chunk_key]
            
            # å‘é€å–æ¶ˆæ¶ˆæ¯åˆ°peer (éœ€è¦åœ¨å®é™…BitTorrentä¸­å®ç°)
            # self._send_cancel_message(request.peer_id, request.round_num, 
            #                          request.source_client_id, request.chunk_id)
            
            # æ¸…ç†è®°å½•
            del self.pending_requests[chunk_key]
            self.requests_per_peer[request.peer_id] -= 1
            if self.requests_per_peer[request.peer_id] == 0:
                del self.requests_per_peer[request.peer_id]
    
    def handle_piece_received(self, chunk_key: Tuple):
        """å¤„ç†æ¥æ”¶åˆ°chunkæ•°æ®"""
        if chunk_key in self.pending_requests:
            request = self.pending_requests[chunk_key]
            print(f"âœ… Client {self.client_id}: Received chunk {request.source_client_id}:{request.chunk_id} "
                  f"from peer {request.peer_id} (importance: {request.importance_score:.4f})")
            
            # æ¸…ç†è¯·æ±‚è®°å½•
            del self.pending_requests[chunk_key]
            self.requests_per_peer[request.peer_id] -= 1
            if self.requests_per_peer[request.peer_id] == 0:
                del self.requests_per_peer[request.peer_id]
    
    # =================== REQUEST HANDLING (ä¸Šä¼ ç«¯) ===================
    
    def add_upload_request(self, requester_id: int, round_num: int, 
                          source_client_id: int, chunk_id: int, importance_score: float):
        """æ·»åŠ ä¸Šä¼ è¯·æ±‚åˆ°ä¼˜å…ˆçº§é˜Ÿåˆ—"""
        request = ChunkRequest(
            peer_id=requester_id,  # è¿™é‡Œpeer_idæ˜¯è¯·æ±‚æ–¹
            round_num=round_num,
            source_client_id=source_client_id,
            chunk_id=chunk_id,
            importance_score=importance_score,
            timestamp=time.time(),
            requester_id=requester_id
        )
        
        # ä½¿ç”¨è´Ÿé‡è¦åº¦åˆ†æ•°å®ç°æœ€å¤§å †ï¼ˆé‡è¦åº¦é«˜çš„ä¼˜å…ˆï¼‰
        priority_tuple = (-importance_score, request.timestamp, request)
        heapq.heappush(self.upload_queue, priority_tuple)
        
        print(f"ğŸ“¥ Client {self.client_id}: Queued upload request from peer {requester_id} "
              f"for chunk {source_client_id}:{chunk_id} (importance: {importance_score:.4f}, "
              f"queue_size: {len(self.upload_queue)})")
    
    def get_next_upload_request(self) -> Optional[ChunkRequest]:
        """è·å–ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„ä¸Šä¼ è¯·æ±‚ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰"""
        if not self.upload_queue:
            return None
            
        _, _, request = heapq.heappop(self.upload_queue)
        
        print(f"ğŸ”¼ Client {self.client_id}: Processing upload request from peer {request.requester_id} "
              f"for chunk {request.source_client_id}:{request.chunk_id} "
              f"(importance: {request.importance_score:.4f})")
        
        return request
    
    # =================== PERIODIC MAINTENANCE ===================
    
    def reevaluate_priorities(self, current_importance_scores: Dict[Tuple, float]):
        """å®šæœŸé‡æ–°è¯„ä¼°è¯·æ±‚ä¼˜å…ˆçº§"""
        current_time = time.time()
        if current_time - self.last_reevaluation < self.PRIORITY_REEVALUATION_INTERVAL:
            return
        
        self.last_reevaluation = current_time
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯·æ±‚çš„é‡è¦åº¦å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–
        to_cancel = []
        for chunk_key, request in self.pending_requests.items():
            current_importance = current_importance_scores.get(chunk_key, request.importance_score)
            
            # å¦‚æœé‡è¦åº¦æ˜¾è‘—ä¸‹é™ï¼Œè€ƒè™‘å–æ¶ˆ
            if current_importance < request.importance_score * 0.5:  # ä¸‹é™50%ä»¥ä¸Š
                to_cancel.append(chunk_key)
        
        # å–æ¶ˆä½ä¼˜å…ˆåº¦è¯·æ±‚
        for chunk_key in to_cancel:
            self.cancel_request(chunk_key)
            print(f"ğŸš« Client {self.client_id}: Canceled request due to priority drop: {chunk_key}")
    
    def check_timeouts(self):
        """æ£€æŸ¥è¶…æ—¶è¯·æ±‚"""
        current_time = time.time()
        timed_out = []
        
        for chunk_key, request in self.pending_requests.items():
            if current_time - request.timestamp > self.REQUEST_TIMEOUT:
                timed_out.append(chunk_key)
        
        for chunk_key in timed_out:
            print(f"â° Client {self.client_id}: Request timed out: {chunk_key}")
            self.cancel_request(chunk_key)
    
    def get_status(self) -> Dict:
        """è·å–ç®¡ç†å™¨çŠ¶æ€"""
        return {
            'pending_requests': len(self.pending_requests),
            'upload_queue_size': len(self.upload_queue),
            'requests_per_peer': dict(self.requests_per_peer),
            'avg_pending_importance': sum(r.importance_score for r in self.pending_requests.values()) / 
                                    len(self.pending_requests) if self.pending_requests else 0
        }


# =================== USAGE EXAMPLE ===================

def demonstrate_priority_management():
    """æ¼”ç¤ºä¼˜å…ˆçº§è¯·æ±‚ç®¡ç†çš„ä½¿ç”¨"""
    
    print("ğŸ¯ FederatedScope BitTorrentä¼˜å…ˆçº§è¯·æ±‚ç®¡ç†æ¼”ç¤º\n")
    
    # åˆ›å»ºClient 1çš„è¯·æ±‚ç®¡ç†å™¨
    client1_manager = PriorityRequestManager(client_id=1)
    
    print("åœºæ™¯1: Client1å‘Client2å‘é€å¤šä¸ªä½é‡è¦åº¦è¯·æ±‚")
    for i in range(8):  # è¶…è¿‡per-peeré™åˆ¶
        success = client1_manager.make_request(
            peer_id=2, 
            round_num=1, 
            source_client_id=2, 
            chunk_id=i, 
            importance_score=0.07
        )
        print(f"   Request {i}: {'Success' if success else 'Failed (limit reached)'}")
    
    print(f"\nçŠ¶æ€: {client1_manager.get_status()}")
    
    print("\nåœºæ™¯2: Client3åŠ å…¥ï¼ŒClient1å‘ç°é«˜é‡è¦åº¦chunk")
    success = client1_manager.make_request(
        peer_id=3, 
        round_num=1, 
        source_client_id=3, 
        chunk_id=0, 
        importance_score=0.35  # é«˜é‡è¦åº¦
    )
    print(f"   High-priority request: {'Success' if success else 'Failed'}")
    
    print(f"\næœ€ç»ˆçŠ¶æ€: {client1_manager.get_status()}")
    
    print("\n" + "="*80)
    print("âœ… ä¼˜å…ˆçº§ç®¡ç†æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demonstrate_priority_management()