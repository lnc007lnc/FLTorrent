#!/usr/bin/env python3
"""
Ray Cloud Integration for FederatedScope
========================================

æ”¯æŒå°†æœ¬åœ°GPUèµ„æºä¸äº‘æœåŠ¡å™¨æ— ç¼ç»“åˆï¼š
- åŠ¨æ€äº‘æœåŠ¡å™¨å‘ç°å’ŒåŠ å…¥
- è·¨äº‘å¹³å°èµ„æºç®¡ç†ï¼ˆAWS, GCP, Azureï¼‰
- è‡ªåŠ¨è´Ÿè½½å‡è¡¡å’Œæ•…éšœåˆ‡æ¢
- æˆæœ¬ä¼˜åŒ–çš„èµ„æºè°ƒåº¦

ä½¿ç”¨æ¡ˆä¾‹ï¼š
1. æœ¬åœ°2 GPU + äº‘æœåŠ¡å™¨4 GPU = 6 GPUè”é‚¦å­¦ä¹ 
2. åœ°ç†åˆ†å¸ƒå¼å®¢æˆ·ç«¯æ¨¡æ‹Ÿï¼ˆä¸åŒåœ°åŒºäº‘æœåŠ¡å™¨ï¼‰  
3. å¼¹æ€§æ‰©å®¹ï¼šè®­ç»ƒè´Ÿè½½é«˜å³°æ—¶è‡ªåŠ¨å¯åŠ¨äº‘å®ä¾‹
"""

import ray
import os
import json
import time
import boto3
import logging
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from ray_distributed_fl import RayFederatedLearning

logger = logging.getLogger(__name__)

@dataclass
class CloudConfig:
    """äº‘æœåŠ¡å™¨é…ç½®"""
    provider: str  # aws, gcp, azure
    region: str
    instance_type: str
    gpu_count: int
    max_instances: int = 5
    credentials: Optional[Dict] = None

@dataclass 
class NodeInfo:
    """RayèŠ‚ç‚¹ä¿¡æ¯"""
    node_id: str
    ip_address: str
    resources: Dict
    cloud_provider: Optional[str] = None
    instance_id: Optional[str] = None

class CloudRayManager:
    """
    äº‘æœåŠ¡å™¨Rayé›†ç¾¤ç®¡ç†å™¨
    è‡ªåŠ¨å‘ç°ã€å¯åŠ¨ã€ç®¡ç†äº‘ç«¯RayèŠ‚ç‚¹
    """
    
    def __init__(self):
        self.cloud_configs: List[CloudConfig] = []
        self.active_instances: List[Dict] = []
        self.ray_cluster_address = None
        
    def add_cloud_config(self, config: CloudConfig):
        """æ·»åŠ äº‘æœåŠ¡å™¨é…ç½®"""
        self.cloud_configs.append(config)
        logger.info(f"ğŸ“‹ æ·»åŠ äº‘é…ç½®: {config.provider} {config.region} {config.instance_type}")
    
    def start_ray_head_node(self, port: int = 10001) -> str:
        """å¯åŠ¨Rayå¤´èŠ‚ç‚¹ï¼ˆé€šå¸¸åœ¨æœ¬åœ°æœºå™¨ï¼‰"""
        # è·å–æœ¬æœºIP
        import socket
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        
        # å¯åŠ¨Rayå¤´èŠ‚ç‚¹
        ray.init(
            address=None,  # æœ¬åœ°æ¨¡å¼
            _node_ip_address=local_ip,
            port=port,
            include_dashboard=True,
            dashboard_host='0.0.0.0',
            dashboard_port=8265
        )
        
        self.ray_cluster_address = f"ray://{local_ip}:{port}"
        logger.info(f"ğŸ¯ Rayå¤´èŠ‚ç‚¹å·²å¯åŠ¨: {self.ray_cluster_address}")
        logger.info(f"ğŸ“Š Ray Dashboard: http://{local_ip}:8265")
        
        return self.ray_cluster_address
    
    def launch_aws_instances(self, config: CloudConfig, num_instances: int = 1) -> List[str]:
        """å¯åŠ¨AWS EC2å®ä¾‹å¹¶åŠ å…¥Rayé›†ç¾¤"""
        try:
            import boto3
        except ImportError:
            logger.error("âŒ boto3æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨AWSåŠŸèƒ½")
            return []
        
        if not config.credentials:
            logger.warning("âš ï¸ AWSå‡­è¯æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å‡­è¯")
        
        ec2 = boto3.client('ec2', region_name=config.region, **config.credentials or {})
        
        # å¯åŠ¨å®ä¾‹çš„ç”¨æˆ·è„šæœ¬
        user_data_script = f'''#!/bin/bash
# å®‰è£…Rayå’Œä¾èµ–
pip3 install ray torch torchvision

# è¿æ¥åˆ°Rayé›†ç¾¤
ray start --address={self.ray_cluster_address} --num-gpus={config.gpu_count}

# ä¸‹è½½å’Œé…ç½®FederatedScopeï¼ˆå¦‚éœ€è¦ï¼‰
# git clone https://github.com/alibaba/FederatedScope.git
# cd FederatedScope && pip install -e .
'''
        
        # å¯åŠ¨å®ä¾‹
        response = ec2.run_instances(
            ImageId='ami-0c02fb55956c7d316',  # Ubuntu 20.04 with GPU support
            MinCount=num_instances,
            MaxCount=num_instances,
            InstanceType=config.instance_type,
            KeyName='your-key-pair',  # éœ€è¦é…ç½®
            SecurityGroupIds=['sg-xxxxxxxxx'],  # éœ€è¦é…ç½®
            UserData=user_data_script,
            TagSpecifications=[{
                'ResourceType': 'instance',
                'Tags': [
                    {'Key': 'Name', 'Value': 'Ray-FederatedScope-Worker'},
                    {'Key': 'Project', 'Value': 'FederatedLearning'}
                ]
            }]
        )
        
        instance_ids = [inst['InstanceId'] for inst in response['Instances']]
        
        # ç­‰å¾…å®ä¾‹å¯åŠ¨å¹¶è·å–IP
        waiter = ec2.get_waiter('instance_running')
        waiter.wait(InstanceIds=instance_ids)
        
        instances_info = ec2.describe_instances(InstanceIds=instance_ids)
        public_ips = []
        
        for reservation in instances_info['Reservations']:
            for instance in reservation['Instances']:
                public_ip = instance.get('PublicIpAddress')
                if public_ip:
                    public_ips.append(public_ip)
                    self.active_instances.append({
                        'instance_id': instance['InstanceId'],
                        'public_ip': public_ip,
                        'provider': 'aws',
                        'region': config.region,
                        'instance_type': config.instance_type,
                        'gpu_count': config.gpu_count
                    })
        
        logger.info(f"ğŸš€ AWSå®ä¾‹å·²å¯åŠ¨: {instance_ids}")
        logger.info(f"ğŸŒ å…¬ç½‘IP: {public_ips}")
        
        return public_ips
    
    def launch_gcp_instances(self, config: CloudConfig, num_instances: int = 1) -> List[str]:
        """å¯åŠ¨GCPå®ä¾‹å¹¶åŠ å…¥Rayé›†ç¾¤"""
        # TODO: å®ç°GCPé›†æˆ
        logger.info("ğŸ”§ GCPé›†æˆå¼€å‘ä¸­...")
        return []
    
    def auto_scale_cluster(self, target_gpu_count: int) -> bool:
        """
        è‡ªåŠ¨æ‰©å®¹é›†ç¾¤åˆ°ç›®æ ‡GPUæ•°é‡
        
        Args:
            target_gpu_count: ç›®æ ‡GPUæ€»æ•°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡
        """
        current_resources = ray.cluster_resources()
        current_gpu_count = int(current_resources.get('GPU', 0))
        
        if current_gpu_count >= target_gpu_count:
            logger.info(f"âœ… é›†ç¾¤å·²æœ‰{current_gpu_count}ä¸ªGPUï¼Œæ— éœ€æ‰©å®¹")
            return True
        
        needed_gpus = target_gpu_count - current_gpu_count
        logger.info(f"ğŸ“ˆ éœ€è¦æ‰©å®¹{needed_gpus}ä¸ªGPU")
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒäº‘å¹³å°
        for config in self.cloud_configs:
            if needed_gpus <= 0:
                break
                
            instances_needed = min(
                (needed_gpus + config.gpu_count - 1) // config.gpu_count,  # å‘ä¸Šå–æ•´
                config.max_instances
            )
            
            if instances_needed <= 0:
                continue
            
            logger.info(f"ğŸŒ©ï¸ åœ¨{config.provider}å¯åŠ¨{instances_needed}ä¸ªå®ä¾‹...")
            
            if config.provider == 'aws':
                launched_ips = self.launch_aws_instances(config, instances_needed)
                if launched_ips:
                    needed_gpus -= instances_needed * config.gpu_count
                    
                    # ç­‰å¾…å®ä¾‹åŠ å…¥é›†ç¾¤
                    self.wait_for_nodes_join(len(launched_ips))
            
            elif config.provider == 'gcp':
                # GCPæ”¯æŒï¼ˆå¾…å®ç°ï¼‰
                pass
        
        # æ£€æŸ¥æœ€ç»ˆGPUæ•°é‡
        final_resources = ray.cluster_resources()
        final_gpu_count = int(final_resources.get('GPU', 0))
        
        if final_gpu_count >= target_gpu_count:
            logger.info(f"ğŸ¯ é›†ç¾¤æ‰©å®¹æˆåŠŸ: {final_gpu_count} GPU")
            return True
        else:
            logger.warning(f"âš ï¸ é›†ç¾¤æ‰©å®¹ä¸å®Œæ•´: {final_gpu_count}/{target_gpu_count} GPU")
            return False
    
    def wait_for_nodes_join(self, expected_nodes: int, timeout: int = 300):
        """ç­‰å¾…æ–°èŠ‚ç‚¹åŠ å…¥é›†ç¾¤"""
        initial_nodes = len(ray.nodes())
        target_nodes = initial_nodes + expected_nodes
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            current_nodes = len(ray.nodes())
            
            if current_nodes >= target_nodes:
                logger.info(f"âœ… {expected_nodes}ä¸ªæ–°èŠ‚ç‚¹å·²åŠ å…¥é›†ç¾¤")
                return True
                
            logger.info(f"â³ ç­‰å¾…èŠ‚ç‚¹åŠ å…¥: {current_nodes}/{target_nodes}")
            time.sleep(10)
        
        logger.warning(f"â° ç­‰å¾…èŠ‚ç‚¹åŠ å…¥è¶…æ—¶")
        return False
    
    def get_cluster_topology(self) -> Dict:
        """è·å–é›†ç¾¤æ‹“æ‰‘ä¿¡æ¯"""
        nodes = ray.nodes()
        cluster_resources = ray.cluster_resources()
        
        topology = {
            "total_nodes": len(nodes),
            "total_resources": dict(cluster_resources),
            "nodes": [],
            "cloud_instances": self.active_instances
        }
        
        for node in nodes:
            node_info = NodeInfo(
                node_id=node["NodeID"],
                ip_address=node.get("NodeManagerAddress", "N/A"),
                resources=node.get("Resources", {})
            )
            
            # åŒ¹é…äº‘å®ä¾‹ä¿¡æ¯
            for instance in self.active_instances:
                if instance["public_ip"] in node_info.ip_address:
                    node_info.cloud_provider = instance["provider"]
                    node_info.instance_id = instance["instance_id"]
                    break
                    
            topology["nodes"].append({
                "node_id": node_info.node_id,
                "ip_address": node_info.ip_address,
                "resources": node_info.resources,
                "cloud_provider": node_info.cloud_provider,
                "instance_id": node_info.instance_id
            })
        
        return topology
    
    def terminate_cloud_instances(self):
        """ç»ˆæ­¢æ‰€æœ‰äº‘å®ä¾‹"""
        logger.info("ğŸ§¹ ç»ˆæ­¢äº‘å®ä¾‹...")
        
        # ç»ˆæ­¢AWSå®ä¾‹
        aws_instances = [inst for inst in self.active_instances if inst['provider'] == 'aws']
        if aws_instances:
            # æŒ‰regionåˆ†ç»„ç»ˆæ­¢
            by_region = {}
            for inst in aws_instances:
                region = inst['region']
                if region not in by_region:
                    by_region[region] = []
                by_region[region].append(inst['instance_id'])
            
            for region, instance_ids in by_region.items():
                try:
                    ec2 = boto3.client('ec2', region_name=region)
                    ec2.terminate_instances(InstanceIds=instance_ids)
                    logger.info(f"ğŸ”ª å·²ç»ˆæ­¢AWSå®ä¾‹ {region}: {instance_ids}")
                except Exception as e:
                    logger.error(f"âŒ ç»ˆæ­¢AWSå®ä¾‹å¤±è´¥: {e}")
        
        # æ¸…ç©ºæ´»åŠ¨å®ä¾‹è®°å½•
        self.active_instances.clear()
        logger.info("âœ… äº‘å®ä¾‹ç»ˆæ­¢å®Œæˆ")

class HybridCloudFederatedLearning(RayFederatedLearning):
    """
    æ··åˆäº‘è”é‚¦å­¦ä¹ 
    ç»“åˆæœ¬åœ°GPUå’Œäº‘æœåŠ¡å™¨GPUèµ„æº
    """
    
    def __init__(self, config_dir: str = "multi_process_test_v2/configs"):
        super().__init__(config_dir)
        self.cloud_manager = CloudRayManager()
    
    def setup_hybrid_cluster(self, target_gpu_count: int = 6,
                           aws_config: Optional[CloudConfig] = None):
        """
        è®¾ç½®æ··åˆäº‘é›†ç¾¤
        
        Args:
            target_gpu_count: ç›®æ ‡GPUæ€»æ•°
            aws_config: AWSé…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        logger.info(f"ğŸŒ©ï¸ è®¾ç½®æ··åˆäº‘é›†ç¾¤ï¼Œç›®æ ‡GPUæ•°: {target_gpu_count}")
        
        # 1. å¯åŠ¨æœ¬åœ°Rayå¤´èŠ‚ç‚¹
        cluster_address = self.cloud_manager.start_ray_head_node()
        
        # 2. æ·»åŠ äº‘é…ç½®
        if aws_config:
            self.cloud_manager.add_cloud_config(aws_config)
        
        # 3. è‡ªåŠ¨æ‰©å®¹åˆ°ç›®æ ‡GPUæ•°
        success = self.cloud_manager.auto_scale_cluster(target_gpu_count)
        
        if success:
            logger.info("âœ… æ··åˆäº‘é›†ç¾¤è®¾ç½®å®Œæˆ")
            
            # æ˜¾ç¤ºé›†ç¾¤æ‹“æ‰‘
            topology = self.cloud_manager.get_cluster_topology()
            logger.info(f"ğŸ—ºï¸ é›†ç¾¤æ‹“æ‰‘: {topology['total_nodes']}èŠ‚ç‚¹, {topology['total_resources']}")
            
            return cluster_address
        else:
            logger.error("âŒ æ··åˆäº‘é›†ç¾¤è®¾ç½®å¤±è´¥")
            return None
    
    def start_hybrid_federated_learning(self, num_clients: int = 6,
                                      total_rounds: int = 5,
                                      monitor_duration: int = 1200):
        """
        å¯åŠ¨æ··åˆäº‘è”é‚¦å­¦ä¹ 
        å……åˆ†åˆ©ç”¨æœ¬åœ°+äº‘ç«¯GPUèµ„æº
        """
        logger.info(f"ğŸš€ å¯åŠ¨æ··åˆäº‘è”é‚¦å­¦ä¹ : {num_clients}å®¢æˆ·ç«¯")
        
        # æ£€æŸ¥é›†ç¾¤èµ„æº
        cluster_resources = ray.cluster_resources()
        total_gpus = int(cluster_resources.get('GPU', 0))
        
        if total_gpus < num_clients:
            logger.warning(f"âš ï¸ GPUä¸è¶³: {total_gpus} < {num_clients}ï¼Œéƒ¨åˆ†å®¢æˆ·ç«¯å°†ä½¿ç”¨CPU")
        
        # å¯åŠ¨è”é‚¦å­¦ä¹ ï¼ˆç»§æ‰¿çˆ¶ç±»é€»è¾‘ï¼‰
        self.start_federated_learning(num_clients, total_rounds, monitor_duration)
    
    def cleanup_hybrid_cluster(self):
        """æ¸…ç†æ··åˆäº‘é›†ç¾¤"""
        logger.info("ğŸ§¹ æ¸…ç†æ··åˆäº‘é›†ç¾¤...")
        
        # åœæ­¢è”é‚¦å­¦ä¹ 
        self.stop_all()
        
        # ç»ˆæ­¢äº‘å®ä¾‹
        self.cloud_manager.terminate_cloud_instances()
        
        # å…³é—­Ray
        ray.shutdown()
        
        logger.info("âœ… æ··åˆäº‘é›†ç¾¤æ¸…ç†å®Œæˆ")

def create_sample_aws_config() -> CloudConfig:
    """åˆ›å»ºç¤ºä¾‹AWSé…ç½®"""
    return CloudConfig(
        provider='aws',
        region='us-west-2',
        instance_type='g4dn.xlarge',  # 1 GPUå®ä¾‹
        gpu_count=1,
        max_instances=4,
        credentials={
            'aws_access_key_id': 'YOUR_ACCESS_KEY',
            'aws_secret_access_key': 'YOUR_SECRET_KEY'
        }
    )

def main_hybrid_demo():
    """æ··åˆäº‘è”é‚¦å­¦ä¹ æ¼”ç¤º"""
    print("ğŸŒ©ï¸ æ··åˆäº‘è”é‚¦å­¦ä¹ æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæ··åˆäº‘FLå®ä¾‹
    hybrid_fl = HybridCloudFederatedLearning()
    
    try:
        # AWSé…ç½®ï¼ˆéœ€è¦ç”¨æˆ·æä¾›çœŸå®å‡­è¯ï¼‰
        aws_config = create_sample_aws_config()
        
        # è®¾ç½®æ··åˆäº‘é›†ç¾¤ï¼ˆæœ¬åœ°2GPU + äº‘ç«¯4GPU = 6GPUï¼‰
        cluster_address = hybrid_fl.setup_hybrid_cluster(
            target_gpu_count=6,
            aws_config=aws_config
        )
        
        if cluster_address:
            # å¯åŠ¨6å®¢æˆ·ç«¯è”é‚¦å­¦ä¹ ï¼ˆå……åˆ†åˆ©ç”¨6ä¸ªGPUï¼‰
            hybrid_fl.start_hybrid_federated_learning(
                num_clients=6,
                total_rounds=5,
                monitor_duration=1800  # 30åˆ†é’Ÿ
            )
        
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        logger.error(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        # æ¸…ç†æ‰€æœ‰èµ„æºï¼ˆåŒ…æ‹¬äº‘å®ä¾‹ï¼‰
        hybrid_fl.cleanup_hybrid_cluster()
        
        print("ğŸ‰ æ··åˆäº‘è”é‚¦å­¦ä¹ ç»“æŸï¼")

if __name__ == "__main__":
    # åŸºç¡€ç¤ºä¾‹ï¼šä»…æœ¬åœ°Rayé›†ç¾¤
    if len(os.sys.argv) > 1 and os.sys.argv[1] == '--hybrid':
        main_hybrid_demo()
    else:
        print("ğŸ’¡ æœ¬åœ°Rayé›†ç¾¤æ¼”ç¤ºï¼Œä½¿ç”¨ '--hybrid' å‚æ•°ä½“éªŒæ··åˆäº‘æ¨¡å¼")
        from ray_distributed_fl import main
        main()