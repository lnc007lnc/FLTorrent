# =============================================================================
# Full Experiment Suite: Gossip-DFL vs CFL Comparison
# =============================================================================
# Total: 12 experiments
#   - Set 1: Gossip-DFL + CelebA/ResNet18 (3 experiments, 300 rounds)
#   - Set 2: Gossip-DFL + TinyBERT/SST2 (3 experiments, 150 rounds)
#   - Set 3: CFL + CelebA/ResNet18 (3 experiments, 100 rounds)
#   - Set 4: CFL + TinyBERT/SST2 (3 experiments, 50 rounds)
# =============================================================================

global:
  code_snapshot_dir: "./experiments_snapshots"
  output_base_dir: "./experiments_output_full"

  # GPU3 Node Resources
  partition: "gpu3"
  nodes: 1
  gpus_per_node: 2
  cpus_per_task: 128
  mem: "1400G"
  time_limit: "72:00:00"

  # Common settings for all experiments
  CLIENT_NUM: 50
  CHUNK_NUM: 16
  CHUNK_TMP_DIR: "/tmp/fl_chunks_gpu3"

  # Data settings
  DATA_ROOT: "./data/"
  DATA_SPLITTER: "lda"
  DATA_SPLITS: [0.8, 0.1, 0.1]
  DATA_SUBSAMPLE: 1.0
  DATA_SHARE_TEST_DATASET: true

experiments:
  # ===========================================================================
  # Set 1: Gossip-DFL + CelebA/ResNet18 (300 rounds, 10 warmup + 290 cosine)
  # ===========================================================================
  - name: "gossip_celeba_resnet_alpha100000"
    description: "Gossip-DFL: CelebA+ResNet18, mesh-4, 300 rounds, alpha=100000 (IID)"
    config:
      # Dataset & Model
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']

      # Training
      TOTAL_ROUNDS: 300
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 100000

      # LR Scheduler: 10 warmup + 290 cosine annealing
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 290
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]

      # Topology (mesh-4)
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4

      # Gossip-DFL settings
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true

      # BitTorrent
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  - name: "gossip_celeba_resnet_alpha1"
    description: "Gossip-DFL: CelebA+ResNet18, mesh-4, 300 rounds, alpha=1.0 (moderate non-IID)"
    config:
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']
      TOTAL_ROUNDS: 300
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 1.0
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 290
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  - name: "gossip_celeba_resnet_alpha03"
    description: "Gossip-DFL: CelebA+ResNet18, mesh-4, 300 rounds, alpha=0.3 (high non-IID)"
    config:
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']
      TOTAL_ROUNDS: 300
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 0.3
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 290
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  # ===========================================================================
  # Set 2: Gossip-DFL + TinyBERT/SST2 (150 rounds = 3x FLTorrent's 50 rounds)
  # ===========================================================================
  - name: "gossip_tinybert_sst2_alpha10000"
    description: "Gossip-DFL: TinyBERT+SST2, mesh-4, 150 rounds, alpha=10000 (IID)"
    config:
      # Dataset & Model
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']

      # Training
      TOTAL_ROUNDS: 150
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 10000

      # No LR scheduler (same as FLTorrent)
      LR_SCHEDULER_TYPE: ""

      # Topology (mesh-4)
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4

      # Gossip-DFL settings
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true

      # BitTorrent
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  - name: "gossip_tinybert_sst2_alpha1"
    description: "Gossip-DFL: TinyBERT+SST2, mesh-4, 150 rounds, alpha=1.0 (moderate non-IID)"
    config:
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']
      TOTAL_ROUNDS: 150
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 1.0
      LR_SCHEDULER_TYPE: ""
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  - name: "gossip_tinybert_sst2_alpha03"
    description: "Gossip-DFL: TinyBERT+SST2, mesh-4, 150 rounds, alpha=0.3 (high non-IID)"
    config:
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']
      TOTAL_ROUNDS: 150
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 0.3
      LR_SCHEDULER_TYPE: ""
      TOPOLOGY_TYPE: "mesh"
      TOPOLOGY_CONNECTIONS: 4
      GOSSIP_ENABLE: true
      GOSSIP_MODE: "neighbor_avg"
      GOSSIP_ITERATIONS: 2
      GOSSIP_MIXING_WEIGHT: 0.5
      BT_NEIGHBOR_ONLY: true
      BITTORRENT_ENABLE: true
      BITTORRENT_TIMEOUT: 1000000.0
      BT_ENABLE_COMPENSATION: false

  # ===========================================================================
  # Set 3: CFL + CelebA/ResNet18 (100 rounds, same as FLTorrent)
  # ===========================================================================
  - name: "cfl_celeba_resnet_alpha100000"
    description: "CFL: CelebA+ResNet18, 100 rounds, alpha=100000 (IID)"
    config:
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']
      TOTAL_ROUNDS: 100
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 100000
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 90
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]
      # CFL: No BitTorrent, no topology
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false

  - name: "cfl_celeba_resnet_alpha1"
    description: "CFL: CelebA+ResNet18, 100 rounds, alpha=1.0 (moderate non-IID)"
    config:
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']
      TOTAL_ROUNDS: 100
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 1.0
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 90
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false

  - name: "cfl_celeba_resnet_alpha03"
    description: "CFL: CelebA+ResNet18, 100 rounds, alpha=0.3 (high non-IID)"
    config:
      DATASET: "celeba"
      MODEL_TYPE: "resnet18"
      MODEL_OUT_CHANNELS: 1
      CRITERION_TYPE: "BCEWithLogitsLoss"
      TRAINER_TYPE: "cvtrainer"
      EVAL_METRICS: ['acc', 'correct', 'f1']
      TOTAL_ROUNDS: 100
      BATCH_SIZE: 16
      LEARNING_RATE: 0.0001
      OPTIMIZER: "Adam"
      WEIGHT_DECAY: 0.0005
      GRAD_CLIP: 5.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 0.3
      LR_SCHEDULER_TYPE: "SequentialLR"
      LR_SCHEDULER_PHASE1_START_FACTOR: 0.01
      LR_SCHEDULER_PHASE1_TOTAL_ITERS: 10
      LR_SCHEDULER_PHASE2_T_MAX: 90
      LR_SCHEDULER_PHASE2_ETA_MIN: 1e-8
      LR_SCHEDULER_MILESTONES: [11]
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false

  # ===========================================================================
  # Set 4: CFL + TinyBERT/SST2 (50 rounds, same as FLTorrent)
  # ===========================================================================
  - name: "cfl_tinybert_sst2_alpha100000"
    description: "CFL: TinyBERT+SST2, 50 rounds, alpha=100000 (IID)"
    config:
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']
      TOTAL_ROUNDS: 50
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 100000
      LR_SCHEDULER_TYPE: ""
      # CFL: No BitTorrent, no topology
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false

  - name: "cfl_tinybert_sst2_alpha1"
    description: "CFL: TinyBERT+SST2, 50 rounds, alpha=1.0 (moderate non-IID)"
    config:
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']
      TOTAL_ROUNDS: 50
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 1.0
      LR_SCHEDULER_TYPE: ""
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false

  - name: "cfl_tinybert_sst2_alpha03"
    description: "CFL: TinyBERT+SST2, 50 rounds, alpha=0.3 (high non-IID)"
    config:
      DATASET: "sst2@huggingface_datasets"
      DATA_ROOT: "glue"
      DATA_MERGE_LEAF_BEFORE_SPLIT: false
      DATA_HF_HALF_VAL_DUMMY_TEST: true
      MODEL_TYPE: "./pretrained_models/TinyBERT_General_4L_312D@transformers"
      MODEL_TASK: "SequenceClassification"
      MODEL_OUT_CHANNELS: 2
      CRITERION_TYPE: "CrossEntropyLoss"
      TRAINER_TYPE: "nlptrainer"
      EVAL_METRICS: ['acc', 'f1']
      TOTAL_ROUNDS: 50
      BATCH_SIZE: 32
      LEARNING_RATE: 0.00002
      OPTIMIZER: "AdamW"
      WEIGHT_DECAY: 0.01
      GRAD_CLIP: 1.0
      LOCAL_UPDATE_STEPS: 1
      DATA_SPLIT_ALPHA: 0.3
      LR_SCHEDULER_TYPE: ""
      TOPOLOGY_USE: false
      BITTORRENT_ENABLE: false
      GOSSIP_ENABLE: false
