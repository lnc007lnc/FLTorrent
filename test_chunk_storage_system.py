#!/usr/bin/env python3
"""
æµ‹è¯•åŸºäºæ‚¨ç®—æ³•çš„åˆ†å—æƒé‡ä¿å­˜æ•°æ®åº“ç³»ç»Ÿ
éªŒè¯ChunkManagerçš„åŠŸèƒ½å’ŒèŠ‚ç‚¹ç‰¹å®šæ•°æ®åº“å­˜å‚¨
"""

import sys
import os
sys.path.insert(0, os.getcwd())

import torch
import torch.nn as nn
import numpy as np
import shutil
import logging
from federatedscope.core.chunk_manager import ChunkManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TestModel(nn.Module):
    """æµ‹è¯•ç”¨çš„ç®€å•æ¨¡å‹"""
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(10, 20)
        self.fc2 = nn.Linear(20, 15)
        self.fc3 = nn.Linear(15, 5)
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x


def cleanup_test_data():
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    test_dir = os.path.join(os.getcwd(), "tmp")
    if os.path.exists(test_dir):
        shutil.rmtree(test_dir)
        print("ğŸ§¹ æ¸…ç†äº†ä¹‹å‰çš„æµ‹è¯•æ•°æ®")


def test_model_splitting():
    """æµ‹è¯•æ¨¡å‹åˆ†å‰²ç®—æ³•"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åˆ†å‰²ç®—æ³•...")
    
    model = TestModel()
    params = ChunkManager.model_to_params(model)
    
    # è®¡ç®—æ€»å‚æ•°æ•°é‡
    total_elements = sum(np.prod(p.shape) for p in params.values())
    print(f"   æ¨¡å‹æ€»å‚æ•°æ•°é‡: {total_elements}")
    
    # æ˜¾ç¤ºå„å‚æ•°çš„è¯¦ç»†ä¿¡æ¯
    print("   å‚æ•°è¯¦æƒ…:")
    for name, param in params.items():
        print(f"     {name}: shape={param.shape}, elements={np.prod(param.shape)}")
    
    # æµ‹è¯•ä¸åŒçš„chunkæ•°é‡
    for num_chunks in [3, 5, 8]:
        print(f"\n   åˆ†å‰²ä¸º {num_chunks} ä¸ªchunks:")
        chunks = ChunkManager.split_model(params, num_chunks)
        
        total_chunk_elements = 0
        for chunk in chunks:
            print(f"     Chunk {chunk['chunk_id']}: {chunk['flat_size']} ä¸ªå…ƒç´ ")
            print(f"       åŒ…å«å‚æ•°: {list(chunk['parts'].keys())}")
            total_chunk_elements += chunk['flat_size']
            
        assert len(chunks) == num_chunks, f"åº”è¯¥æœ‰ {num_chunks} ä¸ªchunks"
        assert total_chunk_elements == total_elements, "chunkæ€»å…ƒç´ æ•°åº”ç­‰äºæ¨¡å‹æ€»å…ƒç´ æ•°"
        
    print("   âœ… æ¨¡å‹åˆ†å‰²æµ‹è¯•é€šè¿‡")
    return True


def test_chunk_extraction():
    """æµ‹è¯•chunkæ•°æ®æå–"""
    print("\nğŸ§ª æµ‹è¯•chunkæ•°æ®æå–...")
    
    model = TestModel()
    params = ChunkManager.model_to_params(model)
    chunks = ChunkManager.split_model(params, num_chunks=5)
    
    chunk_manager = ChunkManager(client_id=999)  # ä¸´æ—¶æµ‹è¯•ç”¨
    
    total_extracted = 0
    for chunk_info in chunks:
        chunk_data = chunk_manager.extract_chunk_data(params, chunk_info)
        print(f"   Chunk {chunk_info['chunk_id']}: æå–äº† {len(chunk_data)} ä¸ªå…ƒç´ ")
        assert len(chunk_data) == chunk_info['flat_size'], "æå–çš„æ•°æ®å¤§å°åº”åŒ¹é…chunkå®šä¹‰"
        total_extracted += len(chunk_data)
        
    total_elements = sum(np.prod(p.shape) for p in params.values())
    assert total_extracted == total_elements, "æ€»æå–å…ƒç´ æ•°åº”ç­‰äºæ¨¡å‹æ€»å…ƒç´ æ•°"
    
    print("   âœ… chunkæ•°æ®æå–æµ‹è¯•é€šè¿‡")
    return True


def test_node_specific_databases():
    """æµ‹è¯•èŠ‚ç‚¹ç‰¹å®šæ•°æ®åº“åˆ›å»ºå’Œå­˜å‚¨"""
    print("\nğŸ§ª æµ‹è¯•èŠ‚ç‚¹ç‰¹å®šæ•°æ®åº“...")
    
    # æµ‹è¯•å¤šä¸ªå®¢æˆ·ç«¯çš„æ•°æ®åº“åˆ›å»º
    client_ids = [1, 2, 3]
    chunk_managers = {}
    
    for client_id in client_ids:
        chunk_manager = ChunkManager(client_id=client_id)
        chunk_managers[client_id] = chunk_manager
        
        # éªŒè¯æ•°æ®åº“è·¯å¾„
        expected_path = os.path.join(os.getcwd(), "tmp", f"client_{client_id}", f"client_{client_id}_chunks.db")
        assert chunk_manager.db_path == expected_path, f"å®¢æˆ·ç«¯ {client_id} æ•°æ®åº“è·¯å¾„ä¸æ­£ç¡®"
        assert os.path.exists(chunk_manager.db_path), f"å®¢æˆ·ç«¯ {client_id} æ•°æ®åº“æ–‡ä»¶åº”è¯¥å­˜åœ¨"
        
        print(f"   âœ… å®¢æˆ·ç«¯ {client_id} æ•°æ®åº“åˆ›å»ºæˆåŠŸ: {chunk_manager.db_path}")
    
    print("   âœ… èŠ‚ç‚¹ç‰¹å®šæ•°æ®åº“æµ‹è¯•é€šè¿‡")
    return chunk_managers


def test_chunk_storage_and_retrieval():
    """æµ‹è¯•chunkå­˜å‚¨å’Œæ£€ç´¢"""
    print("\nğŸ§ª æµ‹è¯•chunkå­˜å‚¨å’Œæ£€ç´¢...")
    
    # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ›å»ºç•¥æœ‰ä¸åŒçš„æ¨¡å‹
    models = {}
    for client_id in [1, 2, 3]:
        model = TestModel()
        # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯çš„æ¨¡å‹æ·»åŠ ä¸åŒçš„å˜åŒ–
        with torch.no_grad():
            for param in model.parameters():
                param.data += torch.randn_like(param) * 0.01 * client_id
        models[client_id] = model
    
    # ä¿å­˜å¤šè½®æ¬¡çš„chunks
    for round_num in range(1, 4):  # 3è½®è®­ç»ƒ
        print(f"\n   ç¬¬ {round_num} è½®è®­ç»ƒ:")
        
        for client_id in [1, 2, 3]:
            chunk_manager = ChunkManager(client_id=client_id)
            model = models[client_id]
            
            # æ¨¡æ‹Ÿè®­ç»ƒåçš„æ¨¡å‹å˜åŒ–
            with torch.no_grad():
                for param in model.parameters():
                    param.data += torch.randn_like(param) * 0.001
            
            # ä¿å­˜chunks
            saved_hashes = chunk_manager.save_model_chunks(
                model=model,
                round_num=round_num,
                num_chunks=5
            )
            
            print(f"     å®¢æˆ·ç«¯ {client_id}: ä¿å­˜äº† {len(saved_hashes)} ä¸ªchunks")
            assert len(saved_hashes) == 5, f"åº”è¯¥ä¿å­˜5ä¸ªchunks"
            
            # æµ‹è¯•æ£€ç´¢
            chunks = chunk_manager.load_chunks_by_round(round_num)
            assert len(chunks) == 5, f"åº”è¯¥æ£€ç´¢åˆ°5ä¸ªchunks"
            
            # æµ‹è¯•æŒ‰IDè·å–chunk
            for chunk_id in range(5):
                chunk_result = chunk_manager.get_chunk_by_id(round_num, chunk_id)
                assert chunk_result is not None, f"åº”è¯¥èƒ½è·å–åˆ°chunk {chunk_id}"
    
    print("   âœ… chunkå­˜å‚¨å’Œæ£€ç´¢æµ‹è¯•é€šè¿‡")
    return True


def test_storage_statistics():
    """æµ‹è¯•å­˜å‚¨ç»Ÿè®¡åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•å­˜å‚¨ç»Ÿè®¡...")
    
    for client_id in [1, 2, 3]:
        chunk_manager = ChunkManager(client_id=client_id)
        stats = chunk_manager.get_storage_stats()
        
        print(f"   å®¢æˆ·ç«¯ {client_id} å­˜å‚¨ç»Ÿè®¡:")
        print(f"     æ•°æ®åº“è·¯å¾„: {stats['db_path']}")
        print(f"     å…ƒæ•°æ®æ¡ç›®: {stats['total_metadata_entries']}")
        print(f"     å”¯ä¸€chunks: {stats['unique_chunks']}")
        print(f"     å­˜å‚¨å¤§å°: {stats['storage_size_mb']:.3f} MB")
        print(f"     è½®æ¬¡èŒƒå›´: {stats['round_range']}")
        
        # éªŒè¯ç»Ÿè®¡æ•°æ®
        assert stats['client_id'] == client_id
        assert stats['total_metadata_entries'] == 15  # 3è½® Ã— 5chunks
        assert stats['round_range'] == (1, 3)
        
    print("   âœ… å­˜å‚¨ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
    return True


def test_model_reconstruction():
    """æµ‹è¯•ä»chunksé‡æ„æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹é‡æ„...")
    
    client_id = 1
    chunk_manager = ChunkManager(client_id=client_id)
    
    # åˆ›å»ºåŸå§‹æ¨¡å‹
    original_model = TestModel()
    original_params = {name: param.clone() for name, param in original_model.named_parameters()}
    
    # ä¿å­˜æ¨¡å‹chunks
    chunk_manager.save_model_chunks(original_model, round_num=99, num_chunks=6)
    
    # åˆ›å»ºæ–°æ¨¡å‹å¹¶ç”¨éšæœºæƒé‡åˆå§‹åŒ–
    reconstructed_model = TestModel()
    with torch.no_grad():
        for param in reconstructed_model.parameters():
            param.data = torch.randn_like(param)
    
    # ä»chunksé‡æ„æ¨¡å‹
    success = chunk_manager.reconstruct_model_from_chunks(round_num=99, target_model=reconstructed_model)
    assert success, "æ¨¡å‹é‡æ„åº”è¯¥æˆåŠŸ"
    
    # éªŒè¯é‡æ„çš„å‡†ç¡®æ€§
    for name, original_param in original_params.items():
        reconstructed_param = dict(reconstructed_model.named_parameters())[name]
        diff = torch.abs(original_param - reconstructed_param).max().item()
        print(f"   å‚æ•° {name} æœ€å¤§å·®å¼‚: {diff:.10f}")
        assert diff < 1e-6, f"å‚æ•° {name} é‡æ„å·®å¼‚è¿‡å¤§: {diff}"
    
    print("   âœ… æ¨¡å‹é‡æ„æµ‹è¯•é€šè¿‡")
    return True


def test_cleanup_functionality():
    """æµ‹è¯•æ¸…ç†åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ¸…ç†åŠŸèƒ½...")
    
    client_id = 1
    chunk_manager = ChunkManager(client_id=client_id)
    model = TestModel()
    
    # ä¿å­˜å¤šè½®æ•°æ®
    for round_num in range(1, 11):  # 10è½®
        chunk_manager.save_model_chunks(model, round_num=round_num, num_chunks=3)
    
    # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
    stats_before = chunk_manager.get_storage_stats()
    print(f"   æ¸…ç†å‰: {stats_before['total_metadata_entries']} æ¡å…ƒæ•°æ®")
    
    # æ‰§è¡Œæ¸…ç†ï¼ˆä¿ç•™æœ€è¿‘3è½®ï¼‰
    chunk_manager.cleanup_old_rounds(keep_rounds=3)
    
    # è·å–æ¸…ç†åçš„ç»Ÿè®¡
    stats_after = chunk_manager.get_storage_stats()
    print(f"   æ¸…ç†å: {stats_after['total_metadata_entries']} æ¡å…ƒæ•°æ®")
    print(f"   è½®æ¬¡èŒƒå›´: {stats_after['round_range']}")
    
    # éªŒè¯æ¸…ç†æ•ˆæœ
    assert stats_after['total_metadata_entries'] <= 9, "æ¸…ç†ååº”è¯¥åªå‰©ä¸‹æœ€è¿‘3è½®çš„æ•°æ®"
    assert stats_after['round_range'][0] >= 8, "æœ€å°è½®æ¬¡åº”è¯¥æ˜¯8æˆ–æ›´å¤§"
    
    print("   âœ… æ¸…ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    return True


def test_aggregation_scenario():
    """æµ‹è¯•èšåˆåœºæ™¯ï¼šä»å¤šä¸ªèŠ‚ç‚¹æ•°æ®åº“è¯»å–ç›¸åŒchunkè¿›è¡Œèšåˆ"""
    print("\nğŸ§ª æµ‹è¯•èšåˆåœºæ™¯...")
    
    # æ¨¡æ‹Ÿ3ä¸ªå®¢æˆ·ç«¯ï¼Œæ¯ä¸ªéƒ½ä¿å­˜äº†ç¬¬1è½®çš„chunks
    chunk_managers = {1: ChunkManager(1), 2: ChunkManager(2), 3: ChunkManager(3)}
    
    # ä»æ¯ä¸ªå®¢æˆ·ç«¯è·å–ç¬¬1è½®çš„chunk 0æ•°æ®
    chunk_0_data = {}
    for client_id, chunk_manager in chunk_managers.items():
        chunk_result = chunk_manager.get_chunk_by_id(round_num=1, chunk_id=0)
        if chunk_result:
            chunk_info, chunk_data = chunk_result
            chunk_0_data[client_id] = chunk_data
            print(f"   å®¢æˆ·ç«¯ {client_id} chunk 0: {len(chunk_data)} ä¸ªå…ƒç´ ")
    
    # è¿›è¡Œç®€å•çš„å¹³å‡èšåˆ
    if len(chunk_0_data) >= 2:
        aggregated_chunk = np.mean(list(chunk_0_data.values()), axis=0)
        print(f"   èšåˆåçš„chunk 0: {len(aggregated_chunk)} ä¸ªå…ƒç´ ")
        print("   âœ… å¯ä»¥æˆåŠŸä»å¤šä¸ªèŠ‚ç‚¹æ•°æ®åº“è·å–ç›¸åŒchunkè¿›è¡Œèšåˆ")
    else:
        print("   âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„chunkæ•°æ®è¿›è¡Œèšåˆæµ‹è¯•")
    
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ§ª åˆ†å—æƒé‡ä¿å­˜æ•°æ®åº“ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ•°æ®
    cleanup_test_data()
    
    tests = [
        ("æ¨¡å‹åˆ†å‰²ç®—æ³•", test_model_splitting),
        ("Chunkæ•°æ®æå–", test_chunk_extraction),
        ("èŠ‚ç‚¹ç‰¹å®šæ•°æ®åº“", test_node_specific_databases),
        ("Chunkå­˜å‚¨å’Œæ£€ç´¢", test_chunk_storage_and_retrieval),
        ("å­˜å‚¨ç»Ÿè®¡", test_storage_statistics),
        ("æ¨¡å‹é‡æ„", test_model_reconstruction),
        ("æ¸…ç†åŠŸèƒ½", test_cleanup_functionality),
        ("èšåˆåœºæ™¯", test_aggregation_scenario),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*20} {test_name} {'='*20}")
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # æ‰“å°æµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    total_tests = len(results)
    passed_tests = sum(1 for _, success in results if success)
    
    print(f"\n   æ€»è®¡: {passed_tests}/{total_tests} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("âœ… åˆ†å—æƒé‡ä¿å­˜æ•°æ®åº“ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        print("\nğŸ“ ç³»ç»Ÿç‰¹æ€§:")
        print("   1. ä½¿ç”¨æ‚¨çš„ç®—æ³•è¿›è¡Œæ¨¡å‹åˆ†å—")
        print("   2. æŒ‰èŠ‚ç‚¹ååˆ›å»ºç‹¬ç«‹æ•°æ®åº“æ–‡ä»¶")
        print("   3. æ”¯æŒchunkçš„å­˜å‚¨ã€æ£€ç´¢å’Œé‡æ„")
        print("   4. æä¾›å­˜å‚¨ç»Ÿè®¡å’Œæ¸…ç†åŠŸèƒ½")
        print("   5. æ”¯æŒå¤šèŠ‚ç‚¹èšåˆåœºæ™¯")
    else:
        print(f"\nâŒ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()