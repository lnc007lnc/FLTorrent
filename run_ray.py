#!/usr/bin/env python3
"""
Ray-Powered FederatedScope V2 Script
===================================

ä¸€é”®å¯åŠ¨åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ ï¼Œå®Œå…¨æ›¿ä»£ä¼ ç»Ÿshellè„šæœ¬
- è‡ªåŠ¨GPUèµ„æºç®¡ç†å’Œåˆ†é…
- åŠ¨æ€IPç«¯å£åˆ†é…
- å®æ—¶ç›‘æ§å’Œæ—¥å¿—
- æ”¯æŒäº‘æœåŠ¡å™¨æ‰©å±•

ç›´æ¥è¿è¡Œå³å¯å¯åŠ¨å®Œæ•´çš„FLç³»ç»Ÿ
"""

import ray
import os
import sys
import time
import yaml
import logging
import psutil
import subprocess
import docker
import random
import threading
import signal
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field

# ============================================================================
# ğŸ”§ é…ç½®åŒºåŸŸ - æ‰€æœ‰è®¾ç½®é›†ä¸­åœ¨æ­¤å¤„ï¼Œæ–¹ä¾¿ä¿®æ”¹
# ============================================================================

@dataclass
class EdgeDeviceProfile:
    """è¾¹ç¼˜è®¾å¤‡ç¡¬ä»¶å’Œç½‘ç»œé…ç½®æ¡£æ¡ˆ"""
    device_id: str
    device_type: str  # "smartphone_high", "smartphone_low", "raspberry_pi", "iot_device", "edge_server"
    docker_image: str
    
    # ç¡¬ä»¶èµ„æºé™åˆ¶
    cpu_limit: str = "0.5"                 # CPUé™åˆ¶ (Dockeræ ¼å¼)
    memory_limit: str = "1g"               # å†…å­˜é™åˆ¶ (Dockeræ ¼å¼) 
    storage_limit: str = "8g"              # å­˜å‚¨é™åˆ¶
    
    # ç½‘ç»œç‰¹æ€§
    bandwidth_up_kbps: int = 10000         # ä¸Šè¡Œå¸¦å®½ (kbps)
    bandwidth_down_kbps: int = 50000       # ä¸‹è¡Œå¸¦å®½ (kbps)
    latency_ms: int = 50                   # ç½‘ç»œå»¶è¿Ÿ (æ¯«ç§’)
    packet_loss_rate: float = 0.01        # ä¸¢åŒ…ç‡ (0-1)
    jitter_ms: int = 10                    # ç½‘ç»œæŠ–åŠ¨ (æ¯«ç§’)
    
    # è®¾å¤‡ç‰¹æ€§
    training_speed_multiplier: float = 1.0  # è®­ç»ƒé€Ÿåº¦å€æ•°
    availability_ratio: float = 0.9        # å¯ç”¨æ€§æ¯”ä¾‹ (0-1)
    battery_constraint: bool = False        # æ˜¯å¦æœ‰ç”µæ± é™åˆ¶
    mobility_pattern: str = "static"        # ç§»åŠ¨æ¨¡å¼: static, mobile, intermittent

@dataclass
class FLConfig:
    """è”é‚¦å­¦ä¹ é…ç½®å‚æ•°"""
    
    # === åŸºç¡€è®¾ç½® ===
    CLIENT_NUM: int = 2                     # å®¢æˆ·ç«¯æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
    TOTAL_ROUNDS: int = 2                   # è®­ç»ƒè½®æ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰
    CHUNK_NUM: int = 10                    # æ¯ä¸ªå®¢æˆ·ç«¯æ¨¡å‹chunkæ•°
    IMPORTANCE_METHOD: str = "snip"         # chunké‡è¦åº¦æ–¹æ³•: magnitude, l2_norm, snip, fisher
    
    # === æ•°æ®é›†è®¾ç½® ===
    DATASET: str = "CIFAR10@torchvision"   # æ•°æ®é›†
    BATCH_SIZE: int = 32                   # æ‰¹å¤„ç†å¤§å°
    DATA_SPLIT_ALPHA: float = 0.1          # LDAæ•°æ®åˆ’åˆ†å‚æ•°
    
    # === æ¨¡å‹è®¾ç½® ===
    MODEL_TYPE: str = "convnet2"          # æ¨¡å‹ç±»å‹
    MODEL_HIDDEN: int = 512               # éšè—å±‚å¤§å°
    MODEL_OUT_CHANNELS: int = 10          # è¾“å‡ºé€šé“æ•°
    MODEL_DROPOUT: float = 0.0            # Dropoutç‡
    
    # === Dockerè®¾ç½® ===
    USE_DOCKER: bool = True                # å¯ç”¨Dockerå®¹å™¨æ¨¡å¼
    BASE_DOCKER_IMAGE: str = "federatedscope:base"  # åŸºç¡€é•œåƒ
    DOCKER_NETWORK_NAME: str = "fl_network"         # Dockerç½‘ç»œåç§°
    ENABLE_NETWORK_SIMULATION: bool = True          # å¯ç”¨ç½‘ç»œä»¿çœŸ
    
    # === ç½‘ç»œä»¿çœŸè®¾ç½® ===
    NETWORK_PROFILES: Dict[str, Dict] = field(default_factory=lambda: {
        "smartphone_high": {
            "bandwidth_up_kbps": 50000,
            "bandwidth_down_kbps": 100000,
            "latency_ms": 20,
            "packet_loss_rate": 0.005,
            "jitter_ms": 5
        },
        "smartphone_low": {
            "bandwidth_up_kbps": 5000,
            "bandwidth_down_kbps": 20000,
            "latency_ms": 100,
            "packet_loss_rate": 0.02,
            "jitter_ms": 20
        },
        "raspberry_pi": {
            "bandwidth_up_kbps": 10000,
            "bandwidth_down_kbps": 50000,
            "latency_ms": 30,
            "packet_loss_rate": 0.01,
            "jitter_ms": 10
        },
        "iot_device": {
            "bandwidth_up_kbps": 128,
            "bandwidth_down_kbps": 512,
            "latency_ms": 300,
            "packet_loss_rate": 0.05,
            "jitter_ms": 50
        },
        "edge_server": {
            "bandwidth_up_kbps": 100000,
            "bandwidth_down_kbps": 1000000,
            "latency_ms": 5,
            "packet_loss_rate": 0.001,
            "jitter_ms": 1
        }
    })
    
    # === è®¾å¤‡åˆ†å¸ƒé…ç½® ===
    DEVICE_DISTRIBUTION: Dict[str, float] = field(default_factory=lambda: {
        "smartphone_high": 0.20,    # 20% é«˜ç«¯æ‰‹æœº
        "smartphone_low": 0.40,     # 40% ä½ç«¯æ‰‹æœº
        "raspberry_pi": 0.15,       # 15% æ ‘è“æ´¾
        "iot_device": 0.20,         # 20% IoTè®¾å¤‡
        "edge_server": 0.05         # 5% è¾¹ç¼˜æœåŠ¡å™¨
    })
    
    # === è®­ç»ƒè®¾ç½® ===
    LOCAL_UPDATE_STEPS: int = 1           # æœ¬åœ°è®­ç»ƒæ­¥æ•°
    LEARNING_RATE: float = 0.01           # å­¦ä¹ ç‡
    OPTIMIZER: str = "SGD"                # ä¼˜åŒ–å™¨
    WEIGHT_DECAY: float = 0.0001          # æƒé‡è¡°å‡
    GRAD_CLIP: float = 5.0                # æ¢¯åº¦è£å‰ª
    
    # === BitTorrentè®¾ç½® ===
    BITTORRENT_TIMEOUT: float = 600.0     # BitTorrentè¶…æ—¶
    BT_CHUNK_SELECTION: str = "rarest_first"  # chunké€‰æ‹©ç­–ç•¥
    BT_MIN_COMPLETION_RATIO: float = 0.8   # æœ€å°å®Œæˆæ¯”ç‡
    
    # === æ‹“æ‰‘è®¾ç½® ===
    TOPOLOGY_TYPE: str = "mesh"           # æ‹“æ‰‘ç±»å‹: star, ring, mesh
    TOPOLOGY_TIMEOUT: float = 600.0       # æ‹“æ‰‘æ„å»ºè¶…æ—¶
    
    # === Dockerå’Œç½‘ç»œä»¿çœŸè®¾ç½® ===
    USE_DOCKER: bool = True               # å¯ç”¨Dockerå®¹å™¨åŒ–
    ENABLE_NETWORK_SIMULATION: bool = True # å¯ç”¨ç½‘ç»œä»¿çœŸ
    DOCKER_BASE_IMAGE: str = "federatedscope:base"  # DockeråŸºç¡€é•œåƒ
    
    # è¾¹ç¼˜è®¾å¤‡åˆ†å¸ƒé…ç½® (è®¾å¤‡ç±»å‹ -> å æ¯”)
    DEVICE_DISTRIBUTION: Dict[str, float] = field(default_factory=lambda: {
        "smartphone_high": 0.2,   # 20% é«˜ç«¯æ‰‹æœº
        "smartphone_low": 0.4,    # 40% ä½ç«¯æ‰‹æœº
        "raspberry_pi": 0.2,      # 20% æ ‘è“æ´¾
        "iot_device": 0.15,       # 15% IoTè®¾å¤‡
        "edge_server": 0.05       # 5% è¾¹ç¼˜æœåŠ¡å™¨
    })
    
    # === Rayèµ„æºè®¾ç½® ===
    RAY_AUTO_GPU_DETECTION: bool = True   # è‡ªåŠ¨GPUæ£€æµ‹
    RAY_MAX_CPUS: Optional[int] = None     # æœ€å¤§CPUæ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
    RAY_MAX_GPUS: Optional[int] = None     # æœ€å¤§GPUæ•°ï¼ˆNone=è‡ªåŠ¨ï¼‰
    
    # === ç›‘æ§è®¾ç½® ===
    MONITOR_DURATION: int = 120           # ç›‘æ§æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ˆæµ‹è¯•ç”¨ï¼‰
    LOG_LEVEL: str = "INFO"               # æ—¥å¿—çº§åˆ«
    ENABLE_RAY_DASHBOARD: bool = True     # å¯ç”¨Ray Dashboard
    
    # === è¾“å‡ºè®¾ç½® ===
    OUTPUT_DIR: str = "ray_v2_output"     # è¾“å‡ºç›®å½•
    LOG_DIR: str = "logs"                 # æ—¥å¿—ç›®å½•

# è¾¹ç¼˜è®¾å¤‡é…ç½®æ¡£æ¡ˆåº“
EDGE_DEVICE_PROFILES = {
    "smartphone_high": EdgeDeviceProfile(
        device_id="smartphone_high",
        device_type="smartphone", 
        docker_image="federatedscope:base",  # ä¸´æ—¶ä½¿ç”¨baseé•œåƒ
        cpu_limit="1.0", memory_limit="4g", storage_limit="32g",
        bandwidth_up_kbps=50000, bandwidth_down_kbps=100000,
        latency_ms=20, packet_loss_rate=0.005, jitter_ms=5,
        training_speed_multiplier=1.2, availability_ratio=0.95,
        mobility_pattern="mobile"
    ),
    
    "smartphone_low": EdgeDeviceProfile(
        device_id="smartphone_low", 
        device_type="smartphone",
        docker_image="federatedscope:base",  # ä¸´æ—¶ä½¿ç”¨baseé•œåƒ
        cpu_limit="0.3", memory_limit="1.5g", storage_limit="8g",
        bandwidth_up_kbps=5000, bandwidth_down_kbps=20000,
        latency_ms=100, packet_loss_rate=0.02, jitter_ms=20,
        training_speed_multiplier=0.4, availability_ratio=0.7,
        battery_constraint=True, mobility_pattern="mobile"
    ),
    
    "raspberry_pi": EdgeDeviceProfile(
        device_id="raspberry_pi",
        device_type="edge_device",
        docker_image="federatedscope:base",  # ä¸´æ—¶ä½¿ç”¨baseé•œåƒ
        cpu_limit="0.6", memory_limit="4g", storage_limit="64g",
        bandwidth_up_kbps=10000, bandwidth_down_kbps=50000,
        latency_ms=30, packet_loss_rate=0.01, jitter_ms=10,
        training_speed_multiplier=0.6, availability_ratio=0.95,
        mobility_pattern="static"
    ),
    
    "iot_device": EdgeDeviceProfile(
        device_id="iot_device",
        device_type="iot",
        docker_image="federatedscope:base",  # ä¸´æ—¶ä½¿ç”¨baseé•œåƒ
        cpu_limit="0.1", memory_limit="256m", storage_limit="2g", 
        bandwidth_up_kbps=128, bandwidth_down_kbps=512,
        latency_ms=300, packet_loss_rate=0.05, jitter_ms=50,
        training_speed_multiplier=0.1, availability_ratio=0.6,
        battery_constraint=True, mobility_pattern="intermittent"
    ),
    
    "edge_server": EdgeDeviceProfile(
        device_id="edge_server",
        device_type="edge_server", 
        docker_image="federatedscope:base",  # ä¸´æ—¶ä½¿ç”¨baseé•œåƒ
        cpu_limit="2.0", memory_limit="8g", storage_limit="100g",
        bandwidth_up_kbps=100000, bandwidth_down_kbps=1000000,
        latency_ms=10, packet_loss_rate=0.001, jitter_ms=2,
        training_speed_multiplier=2.0, availability_ratio=0.99,
        mobility_pattern="static"
    )
}

# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
CONFIG = FLConfig()

# ============================================================================
# ğŸŒ ç½‘ç»œä»¿çœŸç±»
# ============================================================================

class NetworkSimulator:
    """Dockerå®¹å™¨ç½‘ç»œä»¿çœŸæ§åˆ¶å™¨"""
    
    def __init__(self):
        self.active_limitations = {}
        
    def apply_network_constraints(self, container, profile: EdgeDeviceProfile):
        """ä¸ºDockerå®¹å™¨åº”ç”¨ç½‘ç»œçº¦æŸ"""
        if not CONFIG.ENABLE_NETWORK_SIMULATION:
            return True
            
        try:
            # åœ¨å®¹å™¨å†…å®‰è£…å¹¶é…ç½®tc (traffic control)
            setup_commands = [
                # å®‰è£…iproute2 (åŒ…å«tcå‘½ä»¤)
                "apt-get update -qq && apt-get install -y iproute2 > /dev/null 2>&1 || apk add iproute2 > /dev/null 2>&1 || true",
                
                # åˆ é™¤ç°æœ‰çš„é˜Ÿåˆ—è§„åˆ™
                "tc qdisc del dev eth0 root 2>/dev/null || true",
                
                # åˆ›å»ºæ ¹HTBé˜Ÿåˆ—
                "tc qdisc add dev eth0 root handle 1: htb default 30",
                
                # è®¾ç½®æ€»å¸¦å®½é™åˆ¶ (ä¸Šè¡Œ)
                f"tc class add dev eth0 parent 1: classid 1:1 htb rate {profile.bandwidth_up_kbps}kbit ceil {profile.bandwidth_up_kbps}kbit",
                
                # æ·»åŠ ç½‘ç»œå»¶è¿Ÿã€æŠ–åŠ¨å’Œä¸¢åŒ…
                f"tc qdisc add dev eth0 parent 1:1 handle 10: netem delay {profile.latency_ms}ms {profile.jitter_ms}ms loss {profile.packet_loss_rate * 100}%"
            ]
            
            for cmd in setup_commands:
                result = container.exec_run(
                    f"sh -c '{cmd}'", 
                    privileged=True,
                    user="root"
                )
                # è®°å½•ç½‘ç»œé…ç½®ç»“æœä½†ä¸ç»ˆæ­¢ (æŸäº›å‘½ä»¤å¯èƒ½å¤±è´¥ä½†ä¸å½±å“æ•´ä½“)
                if result.exit_code != 0 and "tc qdisc add" in cmd:
                    print(f"âš ï¸  ç½‘ç»œé…ç½®è­¦å‘Š - å®¢æˆ·ç«¯{profile.device_id}: {result.output.decode()[:100]}")
            
            # è®°å½•æˆåŠŸåº”ç”¨çš„é™åˆ¶
            container_name = container.name
            self.active_limitations[container_name] = {
                "bandwidth_up_kbps": profile.bandwidth_up_kbps,
                "latency_ms": profile.latency_ms,
                "packet_loss_rate": profile.packet_loss_rate,
                "jitter_ms": profile.jitter_ms
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ ç½‘ç»œçº¦æŸåº”ç”¨å¤±è´¥ - {profile.device_id}: {e}")
            return False
    
    def simulate_network_fluctuation(self, container_name: str, duration: int = 60):
        """æ¨¡æ‹Ÿç½‘ç»œæ³¢åŠ¨"""
        if container_name not in self.active_limitations:
            return
            
        def fluctuation_thread():
            try:
                docker_client = docker.from_env()
                container = docker_client.containers.get(container_name)
                base_config = self.active_limitations[container_name]
                
                for _ in range(duration):
                    # éšæœºæ”¹å˜ç½‘ç»œæ¡ä»¶ (Â±30%)
                    multiplier = random.uniform(0.7, 1.3)
                    
                    new_bandwidth = int(base_config["bandwidth_up_kbps"] * multiplier)
                    new_latency = max(10, int(base_config["latency_ms"] * multiplier))
                    
                    # æ›´æ–°ç½‘ç»œé™åˆ¶
                    fluctuation_cmd = f"tc class change dev eth0 classid 1:1 htb rate {new_bandwidth}kbit ceil {new_bandwidth}kbit"
                    container.exec_run(f"sh -c '{fluctuation_cmd}'", privileged=True)
                    
                    time.sleep(1)
                    
            except Exception as e:
                print(f"ç½‘ç»œæ³¢åŠ¨æ¨¡æ‹Ÿé”™è¯¯: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹æ‰§è¡Œç½‘ç»œæ³¢åŠ¨
        threading.Thread(target=fluctuation_thread, daemon=True).start()
    
    def get_network_stats(self, container_name: str) -> Dict:
        """è·å–å®¹å™¨ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
        try:
            docker_client = docker.from_env()
            container = docker_client.containers.get(container_name)
            
            # æ‰§è¡Œç½‘ç»œç»Ÿè®¡å‘½ä»¤
            result = container.exec_run("cat /proc/net/dev")
            if result.exit_code == 0:
                lines = result.output.decode().split('\n')
                for line in lines:
                    if 'eth0:' in line:
                        parts = line.split()
                        return {
                            "rx_bytes": int(parts[1]),
                            "rx_packets": int(parts[2]),
                            "tx_bytes": int(parts[9]), 
                            "tx_packets": int(parts[10]),
                            "active_limits": self.active_limitations.get(container_name, {})
                        }
            return {"error": "æ— æ³•è·å–ç½‘ç»œç»Ÿè®¡"}
            
        except Exception as e:
            return {"error": str(e)}

class DockerManager:
    """Dockerç¯å¢ƒç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self.network_simulator = NetworkSimulator()
        self.fl_network = None
        self.docker_available = self._check_docker_availability()
        
        if self.docker_available:
            try:
                self.client = docker.from_env()
            except Exception as e:
                print(f"âš ï¸  Dockerè¿æ¥å¤±è´¥: {e}")
                self.docker_available = False
                
    def _check_docker_availability(self) -> bool:
        """æ£€æŸ¥Dockeræ˜¯å¦å¯ç”¨"""
        try:
            # å¿«é€Ÿæ£€æŸ¥Dockerå‘½ä»¤æ˜¯å¦å­˜åœ¨
            result = subprocess.run(['which', 'docker'], 
                                  capture_output=True, text=True, timeout=2)
            if result.returncode != 0:
                print(f"âš ï¸  Dockerå‘½ä»¤æœªå®‰è£…")
                return False
            
            # æ£€æŸ¥Dockerç‰ˆæœ¬
            result = subprocess.run(['docker', '--version'], 
                                  capture_output=True, text=True, 
                                  check=True, timeout=3)
            print(f"ğŸ³ Dockerç‰ˆæœ¬: {result.stdout.strip()}")
            
            # å¿«é€Ÿæ£€æŸ¥DockeræœåŠ¡çŠ¶æ€
            result = subprocess.run(['docker', 'ps', '--format', 'table {{.ID}}'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print(f"âœ… DockeræœåŠ¡æ­£å¸¸è¿è¡Œ")
                return True
            else:
                print(f"âš ï¸  DockeræœåŠ¡æœªè¿è¡Œ: {result.stderr.strip()[:100]}")
                return False
            
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired) as e:
            print(f"âš ï¸  Dockerä¸å¯ç”¨: {e}")
            return False
        
    def setup_docker_environment(self):
        """è®¾ç½®Dockerç¯å¢ƒ"""
        try:
            # åˆ›å»ºä¸“ç”¨ç½‘ç»œ
            try:
                self.fl_network = self.client.networks.get(CONFIG.DOCKER_NETWORK_NAME)
                print(f"ğŸ“¶ ä½¿ç”¨ç°æœ‰Dockerç½‘ç»œ: {CONFIG.DOCKER_NETWORK_NAME}")
            except docker.errors.NotFound:
                self.fl_network = self.client.networks.create(
                    CONFIG.DOCKER_NETWORK_NAME,
                    driver="bridge",
                    options={
                        "com.docker.network.bridge.enable_icc": "true",
                        "com.docker.network.bridge.enable_ip_masquerade": "true"
                    }
                )
                print(f"ğŸ“¶ åˆ›å»ºDockerç½‘ç»œ: {CONFIG.DOCKER_NETWORK_NAME}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Dockerç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False
    
    def cleanup_docker_environment(self):
        """æ¸…ç†Dockerç¯å¢ƒ"""
        try:
            # åœæ­¢å¹¶åˆ é™¤æ‰€æœ‰FLç›¸å…³å®¹å™¨
            containers = self.client.containers.list(all=True)
            for container in containers:
                if container.name.startswith('fl_'):
                    try:
                        container.stop(timeout=10)
                        container.remove()
                        print(f"ğŸ—‘ï¸  æ¸…ç†å®¹å™¨: {container.name}")
                    except:
                        pass
            
            # åˆ é™¤ç½‘ç»œ (å¦‚æœæ²¡æœ‰å…¶ä»–å®¹å™¨ä½¿ç”¨)
            if self.fl_network:
                try:
                    self.fl_network.remove()
                    print(f"ğŸ—‘ï¸  æ¸…ç†ç½‘ç»œ: {CONFIG.DOCKER_NETWORK_NAME}")
                except:
                    pass
                    
        except Exception as e:
            print(f"âš ï¸  Dockeræ¸…ç†è­¦å‘Š: {e}")
    
    def check_required_images(self) -> bool:
        """æ£€æŸ¥æ‰€éœ€çš„Dockeré•œåƒæ˜¯å¦å­˜åœ¨"""
        if not self.docker_available:
            return False
        
        try:
            # ç®€åŒ–ç‰ˆï¼šåªæ£€æŸ¥baseé•œåƒï¼Œæ‰€æœ‰è®¾å¤‡ä½¿ç”¨åŒä¸€ä¸ªé•œåƒ
            required_images = [
                CONFIG.DOCKER_BASE_IMAGE,  # "federatedscope:base"
            ]
            
            missing_images = []
            for image_name in required_images:
                try:
                    self.client.images.get(image_name)
                    print(f"âœ… Dockeré•œåƒå·²å­˜åœ¨: {image_name}")
                except docker.errors.ImageNotFound:
                    missing_images.append(image_name)
                    print(f"âŒ Dockeré•œåƒç¼ºå¤±: {image_name}")
            
            if missing_images:
                print(f"\nğŸš¨ ç¼ºå¤± {len(missing_images)} ä¸ªDockeré•œåƒ: {missing_images}")
                return False
            else:
                print("âœ… æ‰€æœ‰Dockeré•œåƒéƒ½å·²å°±ç»ª")
                return True
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥Dockeré•œåƒæ—¶å‡ºé”™: {e}")
            return False
    
    def build_required_images(self) -> bool:
        """è‡ªåŠ¨æ„å»ºæ‰€éœ€çš„Dockeré•œåƒ"""
        if not self.docker_available:
            return False
        
        print("ğŸ³ å¼€å§‹è‡ªåŠ¨æ„å»ºFederatedScope Dockeré•œåƒ...")
        
        # ç®€åŒ–ç‰ˆï¼šåªæ„å»ºbaseé•œåƒï¼Œæ‰€æœ‰è®¾å¤‡å…±ç”¨
        build_configs = [
            {
                "dockerfile": "docker/Dockerfile.base",
                "tag": "federatedscope:base",
                "name": "åŸºç¡€é•œåƒ"
            }
        ]
        
        build_success = True
        
        for config in build_configs:
            dockerfile_path = config["dockerfile"]
            tag = config["tag"]
            name = config["name"]
            
            # æ£€æŸ¥Dockerfileæ˜¯å¦å­˜åœ¨
            if not os.path.exists(dockerfile_path):
                print(f"âš ï¸  Dockerfileä¸å­˜åœ¨: {dockerfile_path}ï¼Œè·³è¿‡æ„å»º {tag}")
                continue
            
            print(f"ğŸ“¦ æ­£åœ¨æ„å»º {name} ({tag})...")
            
            try:
                # ä½¿ç”¨Docker Python APIæ„å»ºé•œåƒ
                build_logs = self.client.api.build(
                    path='.',  # æ„å»ºä¸Šä¸‹æ–‡ä¸ºå½“å‰ç›®å½•
                    dockerfile=dockerfile_path,
                    tag=tag,
                    rm=True,  # æ„å»ºååˆ é™¤ä¸­é—´å®¹å™¨
                    decode=True,  # è§£ç æ„å»ºæ—¥å¿—
                    pull=False  # ä¸è‡ªåŠ¨æ‹‰å–åŸºç¡€é•œåƒ
                )
                
                # æ˜¾ç¤ºæ„å»ºè¿›åº¦
                for log_line in build_logs:
                    if 'stream' in log_line:
                        log_msg = log_line['stream'].strip()
                        if log_msg and not log_msg.startswith(' ---> '):
                            print(f"   {log_msg}")
                    elif 'error' in log_line:
                        print(f"âŒ æ„å»ºé”™è¯¯: {log_line['error']}")
                        build_success = False
                        break
                
                if build_success:
                    print(f"âœ… {name} æ„å»ºæˆåŠŸ")
                else:
                    print(f"âŒ {name} æ„å»ºå¤±è´¥")
                    break
                    
            except Exception as e:
                print(f"âŒ æ„å»º {name} æ—¶å‡ºé”™: {e}")
                build_success = False
                break
        
        if build_success:
            print("ğŸ‰ æ‰€æœ‰Dockeré•œåƒæ„å»ºæˆåŠŸ!")
            return True
        else:
            print("âŒ Dockeré•œåƒæ„å»ºå¤±è´¥")
            return False
    
    def ensure_images_ready(self) -> bool:
        """ç¡®ä¿æ‰€éœ€çš„Dockeré•œåƒå·²å°±ç»ªï¼ˆæ£€æŸ¥+è‡ªåŠ¨æ„å»ºï¼‰"""
        if not self.docker_available:
            print("âš ï¸  Dockerä¸å¯ç”¨ï¼Œè·³è¿‡é•œåƒæ£€æŸ¥")
            return False
        
        print("ğŸ” æ£€æŸ¥Dockeré•œåƒçŠ¶æ€...")
        
        # é¦–å…ˆæ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨
        if self.check_required_images():
            return True
        
        # é•œåƒä¸å®Œæ•´ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦è‡ªåŠ¨æ„å»º
        print("\nğŸ¤” æ˜¯å¦è‡ªåŠ¨æ„å»ºç¼ºå¤±çš„Dockeré•œåƒï¼Ÿ")
        print("   è¿™å¯èƒ½éœ€è¦5-10åˆ†é’Ÿæ—¶é—´...")
        
        # åœ¨è‡ªåŠ¨åŒ–ç¯å¢ƒä¸­ç›´æ¥æ„å»ºï¼Œä¸éœ€è¦ç”¨æˆ·ç¡®è®¤
        if os.getenv('CI') or os.getenv('AUTOMATED_BUILD'):
            user_choice = 'y'
        else:
            user_choice = input("   è¾“å…¥ [y/N]: ").lower().strip()
        
        if user_choice in ['y', 'yes', 'æ˜¯']:
            return self.build_required_images()
        else:
            print("âš ï¸  ç”¨æˆ·å–æ¶ˆè‡ªåŠ¨æ„å»ºï¼Œå°†ä½¿ç”¨éDockeræ¨¡å¼")
            return False

# ============================================================================
# ğŸ“Š æ—¥å¿—è®¾ç½®
# ============================================================================

def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(CONFIG.LOG_DIR, exist_ok=True)
    
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    logging.basicConfig(
        level=getattr(logging, CONFIG.LOG_LEVEL),
        format=log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(f"{CONFIG.LOG_DIR}/run_ray.log")
        ]
    )
    return logging.getLogger(__name__)

# ============================================================================
# ğŸ­ Ray Actorå®šä¹‰
# ============================================================================

@ray.remote
class FallbackFederatedScopeServer:
    """åå¤‡çš„FederatedScopeæœåŠ¡å™¨Actorï¼ˆéDockeræ¨¡å¼ï¼‰"""
    
    def __init__(self, config: Dict[str, Any], gpu_id: Optional[int] = None):
        self.config = config
        self.gpu_id = gpu_id
        self.process = None
        self.node_ip = ray.util.get_node_ip_address()
        self.server_port = None
        
    def start(self) -> Tuple[str, int]:
        """å¯åŠ¨æœ¬åœ°è¿›ç¨‹æœåŠ¡å™¨"""
        # åŠ¨æ€åˆ†é…ç«¯å£
        import socket
        sock = socket.socket()
        sock.bind(('', 0))
        self.server_port = sock.getsockname()[1]
        sock.close()
        
        # æ›´æ–°é…ç½®
        self.config['distribute']['server_host'] = self.node_ip
        self.config['distribute']['server_port'] = self.server_port
        self.config['use_gpu'] = False  # å¼ºåˆ¶CPUæ¨¡å¼
        
        # å‡†å¤‡é…ç½®æ–‡ä»¶
        config_dir = f"{CONFIG.OUTPUT_DIR}/configs"
        os.makedirs(config_dir, exist_ok=True)
        config_path = f"{config_dir}/server.yaml"
        
        with open(config_path, 'w') as f:
            yaml.safe_dump(self.config, f)
        
        # å¯åŠ¨è¿›ç¨‹
        try:
            # è®¾ç½®æ—¥å¿—æ–‡ä»¶
            self.log_file = f"{CONFIG.LOG_DIR}/server.log"
            os.makedirs(CONFIG.LOG_DIR, exist_ok=True)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæŒ‰ç…§åŸå§‹ç‰ˆæœ¬çš„ç®€å•æ–¹å¼ï¼‰
            env = os.environ.copy()
            env['PYTHONPATH'] = '.'
            if self.gpu_id is not None:
                env['CUDA_VISIBLE_DEVICES'] = str(self.gpu_id)
            
            # å¯åŠ¨è¿›ç¨‹ï¼ˆä½¿ç”¨åŸå§‹ç‰ˆæœ¬çš„æ–¹å¼ï¼ŒåŒ…æ‹¬æ—¥å¿—é‡å®šå‘ï¼‰
            cmd = [sys.executable, 'federatedscope/main.py', '--cfg', config_path]
            
            with open(self.log_file, 'w') as log_f:
                self.process = subprocess.Popen(
                    cmd, stdout=log_f, stderr=log_f, env=env
                )
            
            return self.node_ip, self.server_port
        except Exception as e:
            print(f"å¯åŠ¨æœåŠ¡å™¨è¿›ç¨‹å¤±è´¥: {e}")
            return None, None
    
    def get_status(self) -> Dict:
        """è·å–è¿›ç¨‹çŠ¶æ€"""
        if self.process is None:
            return {"status": "not_started"}
        
        if self.process.poll() is None:
            return {
                "status": "running",
                "node_ip": self.node_ip,
                "server_port": self.server_port,
                "pid": self.process.pid
            }
        else:
            return {"status": "finished", "return_code": self.process.returncode}
    
    def stop(self):
        """åœæ­¢è¿›ç¨‹"""
        if self.process and self.process.poll() is None:
            self.process.terminate()
            self.process.wait()

@ray.remote
class FallbackFederatedScopeClient:
    """åå¤‡çš„FederatedScopeå®¢æˆ·ç«¯Actorï¼ˆéDockeræ¨¡å¼ï¼‰"""
    
    def __init__(self, client_id: int, config: Dict[str, Any], 
                 server_ip: str, server_port: int, device_profile: EdgeDeviceProfile):
        self.client_id = client_id
        self.config = config.copy()
        self.server_ip = server_ip
        self.server_port = server_port
        self.device_profile = device_profile
        self.process = None
        self.node_ip = ray.util.get_node_ip_address()
        self.client_port = None
        
    def start(self) -> bool:
        """å¯åŠ¨æœ¬åœ°è¿›ç¨‹å®¢æˆ·ç«¯"""
        # åŠ¨æ€åˆ†é…ç«¯å£
        import socket
        sock = socket.socket()
        sock.bind(('', 0))
        self.client_port = sock.getsockname()[1]
        sock.close()
        
        # æ›´æ–°å®¢æˆ·ç«¯ç½‘ç»œé…ç½®
        self.config['distribute']['server_host'] = self.server_ip
        self.config['distribute']['server_port'] = self.server_port
        self.config['distribute']['client_host'] = self.node_ip
        self.config['distribute']['client_port'] = self.client_port
        self.config['distribute']['data_idx'] = self.client_id
        
        # å®¢æˆ·ç«¯ä¸“ç”¨ç§å­
        self.config['seed'] = 12345 + self.client_id
        
        # CPUæ¨¡å¼é…ç½®
        self.config['use_gpu'] = False
        
        # å‡†å¤‡é…ç½®å’Œè¾“å‡ºç›®å½•
        config_dir = f"{CONFIG.OUTPUT_DIR}/configs"
        output_dir = f"{CONFIG.OUTPUT_DIR}/client_{self.client_id}_output"
        os.makedirs(config_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True)
        
        config_path = f"{config_dir}/client_{self.client_id}.yaml"
        self.config['outdir'] = output_dir
        
        with open(config_path, 'w') as f:
            yaml.safe_dump(self.config, f)
        
        # å¯åŠ¨è¿›ç¨‹
        try:
            # è®¾ç½®æ—¥å¿—æ–‡ä»¶
            self.log_file = f"{CONFIG.LOG_DIR}/client_{self.client_id}.log"
            os.makedirs(CONFIG.LOG_DIR, exist_ok=True)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæŒ‰ç…§åŸå§‹ç‰ˆæœ¬çš„ç®€å•æ–¹å¼ï¼‰
            env = os.environ.copy()
            env['PYTHONPATH'] = '.'
            # æ³¨æ„ï¼šè¿™æ˜¯FallbackFederatedScopeClientï¼Œä¸ä½¿ç”¨GPU
            # GPUé…ç½®å·²åœ¨self.configä¸­è®¾ç½®
            
            # å¯åŠ¨è¿›ç¨‹ï¼ˆä½¿ç”¨åŸå§‹ç‰ˆæœ¬çš„æ–¹å¼ï¼ŒåŒ…æ‹¬æ—¥å¿—é‡å®šå‘ï¼‰
            cmd = [sys.executable, 'federatedscope/main.py', '--cfg', config_path]
            
            with open(self.log_file, 'w') as log_f:
                self.process = subprocess.Popen(
                    cmd, stdout=log_f, stderr=log_f, env=env
                )
            
            return True
        except Exception as e:
            print(f"å¯åŠ¨å®¢æˆ·ç«¯{self.client_id}è¿›ç¨‹å¤±è´¥: {e}")
            return False
    
    def get_status(self) -> Dict:
        """è·å–è¿›ç¨‹çŠ¶æ€"""
        if self.process is None:
            return {"status": "not_started"}
        
        if self.process.poll() is None:
            return {
                "status": "running",
                "client_id": self.client_id,
                "device_type": self.device_profile.device_type,
                "node_ip": self.node_ip,
                "client_port": self.client_port,
                "pid": self.process.pid
            }
        else:
            return {"status": "finished", "return_code": self.process.returncode}
    
    def stop(self):
        """åœæ­¢è¿›ç¨‹"""
        if self.process and self.process.poll() is None:
            self.process.terminate()
            self.process.wait()

@ray.remote
class DockerFederatedScopeServer:
    """DockeråŒ–çš„FederatedScopeæœåŠ¡å™¨Actor"""
    
    def __init__(self, config: Dict[str, Any], gpu_id: Optional[int] = None):
        self.config = config
        self.gpu_id = gpu_id
        self.container = None
        self.docker_client = docker.from_env()
        self.node_ip = ray.util.get_node_ip_address()
        self.server_port = None
        self.container_name = "fl_server"
        
    def start(self) -> Tuple[str, int]:
        """å¯åŠ¨DockeræœåŠ¡å™¨å®¹å™¨"""
        # åŠ¨æ€åˆ†é…ç«¯å£
        import socket
        sock = socket.socket()
        sock.bind(('', 0))
        self.server_port = sock.getsockname()[1]
        sock.close()
        
        # æ›´æ–°é…ç½® - Dockeræ¨¡å¼ä¸‰æ®µåœ°å€æ ¼å¼ï¼šç»‘å®šIP|æŠ¥å‘ŠIP|æŠ¥å‘Šç«¯å£
        container_bind_ip = '0.0.0.0'  # å®¹å™¨å†…ç»‘å®šåœ°å€
        external_access_ip = self.node_ip  # å¤–éƒ¨è®¿é—®IP
        external_access_port = self.server_port  # å®¿ä¸»æœºæ˜ å°„ç«¯å£
        self.config['distribute']['server_host'] = f"{container_bind_ip}|{external_access_ip}|{external_access_port}"
        self.config['distribute']['server_port'] = 50051  # å®¹å™¨å†…ç«¯å£ï¼ˆä¿æŒæ•´æ•°ç±»å‹ï¼‰
        
        if self.gpu_id is not None:
            self.config['device'] = 0  # å®¹å™¨å†…GPU ID
            self.config['use_gpu'] = True
        
        # å‡†å¤‡é…ç½®æ–‡ä»¶
        config_dir = f"{CONFIG.OUTPUT_DIR}/configs"
        os.makedirs(config_dir, exist_ok=True)
        config_path = f"{config_dir}/server.yaml"
        
        with open(config_path, 'w') as f:
            yaml.safe_dump(self.config, f)
        
        # å‡†å¤‡æ—¥å¿—ç›®å½•
        log_dir = f"{CONFIG.OUTPUT_DIR}/logs" 
        os.makedirs(log_dir, exist_ok=True)
        
        # Dockerå®¹å™¨é…ç½®
        container_config = {
            "image": CONFIG.DOCKER_BASE_IMAGE,
            "name": self.container_name,
            "hostname": "fl-server",
            "detach": True,
            "remove": True,  # å®¹å™¨åœæ­¢åè‡ªåŠ¨åˆ é™¤
            
            # ç«¯å£æ˜ å°„ï¼šå®¹å™¨å†…50051 -> ä¸»æœºéšæœºç«¯å£
            "ports": {50051: self.server_port},
            
            # ç¯å¢ƒå˜é‡ - æŒ‰ç…§åŸå§‹ç‰ˆæœ¬çš„ç®€å•æ–¹å¼
            "environment": {
                "PYTHONPATH": "/app"
            },
            
            # å·æŒ‚è½½
            "volumes": {
                os.path.abspath(config_path): {"bind": "/app/config.yaml", "mode": "ro"},
                os.path.abspath(log_dir): {"bind": "/app/logs", "mode": "rw"},
                os.path.abspath("data"): {"bind": "/app/data", "mode": "rw"}
            },
            
            # å¯åŠ¨å‘½ä»¤ - ä½¿ç”¨shellåŒ…è£…ä»¥è®¾ç½®å·¥ä½œç›®å½•å’Œç¯å¢ƒ
            "command": ["sh", "-c", "cd /app && PYTHONPATH=/app python federatedscope/main.py --cfg /app/config.yaml"]
        }
        
        # GPUæ”¯æŒ
        if self.gpu_id is not None:
            container_config["device_requests"] = [
                docker.types.DeviceRequest(device_ids=[str(self.gpu_id)], capabilities=[['gpu']])
            ]
        
        try:
            # å¯åŠ¨å®¹å™¨
            self.container = self.docker_client.containers.run(**container_config)
            return self.node_ip, self.server_port
            
        except Exception as e:
            print(f"å¯åŠ¨æœåŠ¡å™¨å®¹å™¨å¤±è´¥: {e}")
            return None, None
    
    def get_status(self) -> Dict:
        """è·å–Dockerå®¹å™¨çŠ¶æ€"""
        if self.container is None:
            return {"status": "not_started"}
        
        try:
            self.container.reload()
            return {
                "status": self.container.status,
                "container_id": self.container.id[:12], 
                "node_ip": self.node_ip,
                "server_port": self.server_port,
                "gpu_id": self.gpu_id,
                "container_name": self.container_name
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def stop(self):
        """åœæ­¢Dockerå®¹å™¨"""
        if self.container:
            try:
                self.container.stop(timeout=10)
            except Exception as e:
                print(f"åœæ­¢æœåŠ¡å™¨å®¹å™¨å¤±è´¥: {e}")

@ray.remote
class DockerFederatedScopeClient:
    """DockeråŒ–çš„FederatedScopeå®¢æˆ·ç«¯Actor"""
    
    def __init__(self, client_id: int, config: Dict[str, Any], 
                 server_ip: str, server_port: int, device_profile: EdgeDeviceProfile):
        self.client_id = client_id
        self.config = config.copy()
        self.server_ip = server_ip
        self.server_port = server_port
        self.device_profile = device_profile
        self.container = None
        self.docker_client = docker.from_env()
        self.node_ip = ray.util.get_node_ip_address()
        self.client_port = None
        self.container_name = f"fl_client_{client_id}"
        
    def start(self) -> bool:
        """å¯åŠ¨Dockerå®¢æˆ·ç«¯å®¹å™¨"""
        # åŠ¨æ€åˆ†é…ç«¯å£
        import socket
        sock = socket.socket()
        sock.bind(('', 0))
        self.client_port = sock.getsockname()[1]
        sock.close()
        
        # åº”ç”¨è®¾å¤‡ç‰¹å®šé…ç½®
        self._apply_device_constraints()
        
        # æ›´æ–°å®¢æˆ·ç«¯ç½‘ç»œé…ç½®  
        self.config['distribute']['server_host'] = self.server_ip
        self.config['distribute']['server_port'] = self.server_port
        # Dockeræ¨¡å¼ä¸‰æ®µåœ°å€æ ¼å¼ï¼šç»‘å®šIP|æŠ¥å‘ŠIP|æŠ¥å‘Šç«¯å£
        container_bind_ip = '0.0.0.0'  # å®¹å™¨å†…ç»‘å®šåœ°å€
        external_access_ip = self.node_ip  # å¤–éƒ¨è®¿é—®IP  
        external_access_port = self.client_port  # å®¿ä¸»æœºæ˜ å°„ç«¯å£
        self.config['distribute']['client_host'] = f"{container_bind_ip}|{external_access_ip}|{external_access_port}"
        self.config['distribute']['client_port'] = 50052  # å®¹å™¨å†…ç«¯å£ï¼ˆä¿æŒæ•´æ•°ç±»å‹ï¼‰
        self.config['distribute']['data_idx'] = self.client_id
        
        # å®¢æˆ·ç«¯ä¸“ç”¨ç§å­
        self.config['seed'] = 12345 + self.client_id
        
        # ğŸ® GPUé…ç½®ï¼šæ ¹æ®è®¾å¤‡ç±»å‹å’ŒRayåˆ†é…å†³å®š
        if self.device_profile.device_type in ["smartphone_high", "edge_server"]:
            # é«˜ç«¯è®¾å¤‡æ”¯æŒGPUï¼Œä½†æœ€ç»ˆç”±Rayèµ„æºåˆ†é…å†³å®š
            self.config['device'] = 0  # å®¹å™¨å†…GPUè®¾å¤‡ID
            self.config['use_gpu'] = True
        else:
            # ä½ç«¯è®¾å¤‡å¼ºåˆ¶ä½¿ç”¨CPU
            self.config['use_gpu'] = False
        
        # å®¢æˆ·ç«¯è¾“å‡ºç›®å½•
        self.config['outdir'] = f"/app/output"
        
        # å‡†å¤‡é…ç½®å’Œè¾“å‡ºç›®å½•
        config_dir = f"{CONFIG.OUTPUT_DIR}/configs"
        output_dir = f"{CONFIG.OUTPUT_DIR}/client_{self.client_id}_output"
        log_dir = f"{CONFIG.OUTPUT_DIR}/logs"
        data_dir = "data"
        
        os.makedirs(config_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True) 
        os.makedirs(log_dir, exist_ok=True)
        os.makedirs(data_dir, exist_ok=True)
        
        config_path = f"{config_dir}/client_{self.client_id}.yaml"
        with open(config_path, 'w') as f:
            yaml.safe_dump(self.config, f)
        
        # å¯åŠ¨Dockerå®¹å™¨
        return self._start_docker_container(config_path, output_dir, log_dir, data_dir)
    
    def _apply_device_constraints(self):
        """æ ¹æ®è®¾å¤‡ç‰¹æ€§åº”ç”¨é…ç½®çº¦æŸ"""
        profile = self.device_profile
        
        # æ ¹æ®è®¾å¤‡èƒ½åŠ›è°ƒæ•´batch size
        if profile.device_type == "iot_device":
            self.config['dataloader']['batch_size'] = 8  # IoTè®¾å¤‡ä½¿ç”¨å°æ‰¹é‡
        elif profile.device_type == "smartphone_low":
            self.config['dataloader']['batch_size'] = 16  # ä½ç«¯æ‰‹æœºé€‚ä¸­
        else:
            self.config['dataloader']['batch_size'] = 32  # é«˜ç«¯è®¾å¤‡ä½¿ç”¨åŸå§‹é…ç½®
        
        # æ ¹æ®è®­ç»ƒé€Ÿåº¦è°ƒæ•´æœ¬åœ°æ›´æ–°æ­¥æ•°
        base_steps = self.config['train']['local_update_steps']
        adjusted_steps = max(1, int(base_steps * profile.training_speed_multiplier))
        self.config['train']['local_update_steps'] = adjusted_steps
        
    def _start_docker_container(self, config_path: str, output_dir: str, log_dir: str, data_dir: str) -> bool:
        """å¯åŠ¨Dockerå®¹å™¨"""
        profile = self.device_profile
        
        # è®¡ç®—CPUé™é¢ (ä»¥å¾®ç§’ä¸ºå•ä½)
        cpu_period = 100000  # 100ms
        cpu_quota = int(float(profile.cpu_limit) * cpu_period)
        
        # Dockerå®¹å™¨é…ç½®
        container_config = {
            "image": profile.docker_image,
            "name": self.container_name,
            "hostname": f"client-{self.client_id}",
            "detach": True,
            "remove": True,
            
            # èµ„æºé™åˆ¶
            "cpu_period": cpu_period,
            "cpu_quota": cpu_quota,
            "mem_limit": profile.memory_limit,
            "memswap_limit": profile.memory_limit,  # ç¦ç”¨swap
            
            # ç«¯å£æ˜ å°„
            "ports": {50052: self.client_port},
            
            # ç¯å¢ƒå˜é‡ - æŒ‰ç…§åŸå§‹ç‰ˆæœ¬çš„ç®€å•æ–¹å¼
            "environment": {
                "PYTHONPATH": "/app"
            },
            
            # å·æŒ‚è½½
            "volumes": {
                os.path.abspath(config_path): {"bind": "/app/config.yaml", "mode": "ro"},
                os.path.abspath(output_dir): {"bind": "/app/output", "mode": "rw"},
                os.path.abspath(log_dir): {"bind": "/app/logs", "mode": "rw"},
                os.path.abspath(data_dir): {"bind": "/app/data", "mode": "rw"}
            },
            
            # ç‰¹æƒæ¨¡å¼(ç”¨äºç½‘ç»œæ§åˆ¶)
            "privileged": True,
            
            # å¯åŠ¨å‘½ä»¤ - ä½¿ç”¨shellåŒ…è£…ä»¥è®¾ç½®å·¥ä½œç›®å½•å’Œç¯å¢ƒ
            "command": ["sh", "-c", "cd /app && PYTHONPATH=/app python federatedscope/main.py --cfg /app/config.yaml"]
        }
        
        # GPUæ”¯æŒ
        if self.config.get('use_gpu', False):
            container_config["device_requests"] = [
                docker.types.DeviceRequest(count=-1, capabilities=[['gpu']])
            ]
        
        try:
            # å¯åŠ¨å®¹å™¨
            self.container = self.docker_client.containers.run(**container_config)
            
            # åº”ç”¨ç½‘ç»œé™åˆ¶
            if CONFIG.ENABLE_NETWORK_SIMULATION:
                self._apply_network_constraints()
            
            # å¯åŠ¨è®¾å¤‡è¡Œä¸ºä»¿çœŸ
            self._start_device_behavior_simulation()
            
            return True
            
        except Exception as e:
            print(f"å¯åŠ¨å®¢æˆ·ç«¯{self.client_id}å®¹å™¨å¤±è´¥: {e}")
            return False
    
    def _apply_network_constraints(self):
        """åº”ç”¨ç½‘ç»œçº¦æŸä½¿ç”¨tc (traffic control)"""
        if not self.container:
            return
            
        profile = self.device_profile
        
        # è½¬æ¢å¸¦å®½å•ä½
        up_bandwidth = f"{profile.bandwidth_up_kbps}kbit"
        down_bandwidth = f"{profile.bandwidth_down_kbps}kbit"
        delay = f"{profile.latency_ms}ms"
        jitter = f"{profile.jitter_ms}ms" 
        loss = f"{profile.packet_loss_rate * 100}%"
        
        # tcå‘½ä»¤åºåˆ—
        tc_commands = [
            # æ¸…é™¤ç°æœ‰è§„åˆ™
            "tc qdisc del dev eth0 root 2>/dev/null || true",
            
            # è®¾ç½®ä¸Šè¡Œå¸¦å®½é™åˆ¶
            "tc qdisc add dev eth0 root handle 1: htb default 12",
            f"tc class add dev eth0 parent 1: classid 1:1 htb rate {up_bandwidth} ceil {up_bandwidth}",
            
            # æ·»åŠ ç½‘ç»œå»¶è¿Ÿå’Œä¸¢åŒ…
            f"tc qdisc add dev eth0 parent 1:1 handle 10: netem delay {delay} {jitter} loss {loss}",
        ]
        
        # æ‰§è¡Œtcå‘½ä»¤
        for cmd in tc_commands:
            try:
                result = self.container.exec_run(f"sh -c '{cmd}'", privileged=True)
                if result.exit_code != 0:
                    print(f"ç½‘ç»œé…ç½®å‘½ä»¤å¤±è´¥: {cmd}, é”™è¯¯: {result.output.decode()}")
            except Exception as e:
                print(f"æ‰§è¡Œç½‘ç»œå‘½ä»¤å¤±è´¥: {cmd}, é”™è¯¯: {e}")
                
    def _start_device_behavior_simulation(self):
        """å¯åŠ¨è®¾å¤‡è¡Œä¸ºä»¿çœŸï¼ˆç”µæ± ã€ç§»åŠ¨æ€§ç­‰ï¼‰"""
        profile = self.device_profile
        
        if profile.mobility_pattern == "intermittent":
            # é—´æ­‡æ€§è®¾å¤‡ä»¿çœŸ
            threading.Thread(target=self._simulate_intermittent_connectivity, daemon=True).start()
            
        if profile.battery_constraint:
            # ç”µæ± çº¦æŸä»¿çœŸ
            threading.Thread(target=self._simulate_battery_drain, daemon=True).start()
    
    def _simulate_intermittent_connectivity(self):
        """ä»¿çœŸé—´æ­‡æ€§è¿æ¥"""
        if not self.container:
            return
            
        while True:
            try:
                # æ ¹æ®å¯ç”¨æ€§æ¯”ä¾‹å†³å®šè¿æ¥çŠ¶æ€
                if random.random() > self.device_profile.availability_ratio:
                    # è®¾å¤‡ç¦»çº¿
                    offline_duration = random.randint(10, 60)  # 10-60ç§’ç¦»çº¿
                    self.container.pause()
                    print(f"ğŸ“± è®¾å¤‡{self.client_id}ç¦»çº¿ {offline_duration}ç§’")
                    time.sleep(offline_duration)
                    
                    # é‡æ–°ä¸Šçº¿
                    self.container.unpause() 
                    print(f"ğŸ“± è®¾å¤‡{self.client_id}é‡æ–°ä¸Šçº¿")
                    
                # åœ¨çº¿æ—¶é—´
                online_duration = random.randint(60, 300)  # 1-5åˆ†é’Ÿåœ¨çº¿
                time.sleep(online_duration)
                
            except Exception as e:
                print(f"é—´æ­‡æ€§è¿æ¥ä»¿çœŸé”™è¯¯: {e}")
                break
                
    def _simulate_battery_drain(self):
        """ä»¿çœŸç”µæ± æ¶ˆè€—"""
        if not self.container:
            return
            
        # ä»¿çœŸç”µæ± çº§åˆ« (30åˆ†é’Ÿåä½ç”µé‡æ¨¡å¼)
        battery_life = 30 * 60  # 30åˆ†é’Ÿ
        low_battery_threshold = 0.2  # 20%ç”µé‡
        
        time.sleep(battery_life * (1 - low_battery_threshold))
        
        # è¿›å…¥ä½ç”µé‡æ¨¡å¼ï¼ˆé™ä½æ€§èƒ½ï¼‰ 
        print(f"ğŸ”‹ è®¾å¤‡{self.client_id}è¿›å…¥ä½ç”µé‡æ¨¡å¼")
        
        # æ¨¡æ‹Ÿæ€§èƒ½ä¸‹é™ï¼ˆå‡å°‘CPUé™é¢ï¼‰
        try:
            # å°†CPUä½¿ç”¨ç‡é™ä½åˆ°70%
            cpu_quota = int(float(self.device_profile.cpu_limit) * 0.7 * 100000)
            self.container.update(cpu_quota=cpu_quota)
        except Exception as e:
            print(f"æ›´æ–°CPUé™é¢å¤±è´¥: {e}")
            
        # ç­‰å¾…å‰©ä½™ç”µé‡è€—å°½
        time.sleep(battery_life * low_battery_threshold)
        
        # ç”µé‡è€—å°½ï¼Œè®¾å¤‡å…³æœº
        print(f"ğŸ¥ è®¾å¤‡{self.client_id}ç”µé‡è€—å°½ï¼Œè‡ªåŠ¨å…³æœº")
        try:
            self.container.stop()
        except Exception as e:
            print(f"å…³æœºå¤±è´¥: {e}")
    
    def get_status(self) -> Dict:
        """è·å–Dockerå®¹å™¨çŠ¶æ€"""
        if self.container is None:
            return {"status": "not_started"}
        
        try:
            self.container.reload()
            return {
                "status": self.container.status,
                "container_id": self.container.id[:12],
                "client_id": self.client_id,
                "device_type": self.device_profile.device_type,
                "node_ip": self.node_ip,
                "client_port": self.client_port,
                "container_name": self.container_name,
                "cpu_limit": self.device_profile.cpu_limit,
                "memory_limit": self.device_profile.memory_limit,
                "network_profile": {
                    "bandwidth_up": f"{self.device_profile.bandwidth_up_kbps}kbps",
                    "bandwidth_down": f"{self.device_profile.bandwidth_down_kbps}kbps", 
                    "latency": f"{self.device_profile.latency_ms}ms",
                    "packet_loss": f"{self.device_profile.packet_loss_rate*100}%"
                }
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def stop(self):
        """åœæ­¢Dockerå®¹å™¨"""
        if self.container:
            try:
                self.container.stop(timeout=10)
            except Exception as e:
                print(f"åœæ­¢å®¢æˆ·ç«¯{self.client_id}å®¹å™¨å¤±è´¥: {e}")
                
    def simulate_device_failure(self, duration: int = 60):
        """ä»¿çœŸè®¾å¤‡æ•…éšœ"""
        if self.container:
            self.container.pause()
            print(f"ğŸ”´ è®¾å¤‡{self.client_id}å‘ç”Ÿæ•…éšœï¼Œç¦»çº¿{duration}ç§’")
            
            # å®šæ—¶æ¢å¤
            def recover():
                time.sleep(duration)
                try:
                    if self.container.status == "paused":
                        self.container.unpause()
                        print(f"ï¿½ï¸ è®¾å¤‡{self.client_id}æ•…éšœæ¢å¤")
                except Exception as e:
                    print(f"è®¾å¤‡æ¢å¤å¤±è´¥: {e}")
            
            threading.Thread(target=recover, daemon=True).start()

# ============================================================================
# ğŸš€ ä¸»è¦æ‰§è¡Œç±»
# ============================================================================

class RayV2FederatedLearning:
    """Ray V2 è”é‚¦å­¦ä¹ ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.logger = setup_logging()
        self.server_actor = None
        self.client_actors = []
        self.server_info = None
        self.cleanup_performed = False
        
    def initialize_ray_cluster(self):
        """åˆå§‹åŒ–Rayé›†ç¾¤"""
        # æ£€æµ‹ç¡¬ä»¶èµ„æº
        num_cpus = CONFIG.RAY_MAX_CPUS or psutil.cpu_count()
        num_gpus = CONFIG.RAY_MAX_GPUS
        
        if CONFIG.RAY_AUTO_GPU_DETECTION and num_gpus is None:
            try:
                import torch
                num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0
            except ImportError:
                num_gpus = 0
        
        # åˆå§‹åŒ–Ray
        ray_config = {
            "num_cpus": num_cpus,
            "num_gpus": num_gpus or 0,
            "ignore_reinit_error": True
        }
        
        if CONFIG.ENABLE_RAY_DASHBOARD:
            ray_config.update({
                "include_dashboard": True,
                "dashboard_host": "0.0.0.0",
                "dashboard_port": 8265
            })
        
        ray.init(**ray_config)
        
        resources = ray.cluster_resources()
        self.logger.info(f"ğŸš€ Rayé›†ç¾¤åˆå§‹åŒ–å®Œæˆ:")
        self.logger.info(f"   ğŸ“Š èµ„æº: {dict(resources)}")
        
        if CONFIG.ENABLE_RAY_DASHBOARD:
            dashboard_url = f"http://127.0.0.1:8265"
            self.logger.info(f"   ğŸŒ Dashboard: {dashboard_url}")
        
    def generate_base_config(self) -> Dict[str, Any]:
        """ç”ŸæˆåŸºç¡€é…ç½®"""
        return {
            'use_gpu': True,
            'device': 0,  # å°†è¢«åŠ¨æ€è¦†ç›–
            'seed': 12345,  # å°†è¢«åŠ¨æ€è¦†ç›–
            
            'federate': {
                'client_num': CONFIG.CLIENT_NUM,
                'mode': 'distributed',
                'total_round_num': CONFIG.TOTAL_ROUNDS,
                'sample_client_num': CONFIG.CLIENT_NUM
            },
            
            'distribute': {
                'use': True,
                'server_host': '127.0.0.1',  # å°†è¢«åŠ¨æ€è¦†ç›–
                'server_port': 50051,        # å°†è¢«åŠ¨æ€è¦†ç›–
                'client_host': '127.0.0.1',  # å°†è¢«åŠ¨æ€è¦†ç›–
                'client_port': 50052,        # å°†è¢«åŠ¨æ€è¦†ç›–
                'role': 'server',            # å°†è¢«åŠ¨æ€è¦†ç›–
                'data_idx': 0                # å°†è¢«åŠ¨æ€è¦†ç›–
            },
            
            'data': {
                'root': 'data/',
                'type': CONFIG.DATASET,
                'splits': [0.8, 0.1, 0.1],
                'num_workers': 0,
                'transform': [['ToTensor'], ['Normalize', {
                    'mean': [0.4914, 0.4822, 0.4465], 
                    'std': [0.2470, 0.2435, 0.2616]
                }]],
                'test_transform': [['ToTensor'], ['Normalize', {
                    'mean': [0.4914, 0.4822, 0.4465], 
                    'std': [0.2470, 0.2435, 0.2616]
                }]],
                'args': [{'download': True}],
                'splitter': 'lda',
                'splitter_args': [{'alpha': CONFIG.DATA_SPLIT_ALPHA}]
            },
            
            'dataloader': {
                'batch_size': CONFIG.BATCH_SIZE
            },
            
            'model': {
                'type': CONFIG.MODEL_TYPE,
                'hidden': CONFIG.MODEL_HIDDEN,
                'out_channels': CONFIG.MODEL_OUT_CHANNELS,
                'dropout': CONFIG.MODEL_DROPOUT
            },
            
            'train': {
                'local_update_steps': CONFIG.LOCAL_UPDATE_STEPS,
                'batch_or_epoch': 'epoch',
                'optimizer': {
                    'lr': CONFIG.LEARNING_RATE,
                    'type': CONFIG.OPTIMIZER,
                    'weight_decay': CONFIG.WEIGHT_DECAY
                }
            },
            
            'grad': {
                'grad_clip': CONFIG.GRAD_CLIP
            },
            
            'criterion': {
                'type': 'CrossEntropyLoss'
            },
            
            'trainer': {
                'type': 'cvtrainer'
            },
            
            'eval': {
                'freq': 1,
                'metrics': ['acc', 'correct'],
                'best_res_update_round_wise_key': 'test_acc'
            },
            
            'topology': {
                'use': True,
                'type': CONFIG.TOPOLOGY_TYPE,
                'timeout': CONFIG.TOPOLOGY_TIMEOUT,
                'verbose': True
            },
            
            'bittorrent': {
                'enable': True,
                'timeout': CONFIG.BITTORRENT_TIMEOUT,
                'verbose': True,
                'chunk_selection': CONFIG.BT_CHUNK_SELECTION,
                'min_completion_ratio': CONFIG.BT_MIN_COMPLETION_RATIO
            },
            
            'chunk': {
                'num_chunks': CONFIG.CHUNK_NUM,
                'importance_method': CONFIG.IMPORTANCE_METHOD
            },
            
            'chunk_num': CONFIG.CHUNK_NUM,
            'chunk_importance_method': CONFIG.IMPORTANCE_METHOD,
            
            'outdir': f'{CONFIG.OUTPUT_DIR}/server_output'
        }
        
    def allocate_gpu_resources(self) -> List[Optional[int]]:
        """æ™ºèƒ½GPUèµ„æºåˆ†é…ï¼šæœåŠ¡å™¨ä½¿ç”¨CPUï¼Œå®¢æˆ·ç«¯ä½¿ç”¨GPU"""
        cluster_resources = ray.cluster_resources()
        available_gpus = int(cluster_resources.get('GPU', 0))
        
        if available_gpus == 0:
            self.logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œæ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨CPUæ¨¡å¼")
            return [None] * (CONFIG.CLIENT_NUM + 1)
        
        gpu_allocation = []
        
        # ğŸ–¥ï¸ æœåŠ¡å™¨å›ºå®šä½¿ç”¨CPUï¼ˆä¸åˆ†é…GPUï¼‰
        gpu_allocation.append(None)
        
        # ğŸ® å®¢æˆ·ç«¯ä¼˜å…ˆä½¿ç”¨GPUï¼šæŒ‰éœ€åˆ†é…åˆ°æ‰€æœ‰å¯ç”¨GPU
        gpu_capable_clients = 0
        for i in range(CONFIG.CLIENT_NUM):
            # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ”¯æŒGPUï¼ˆé«˜ç«¯æ‰‹æœºå’Œè¾¹ç¼˜æœåŠ¡å™¨ï¼‰
            device_type = list(CONFIG.DEVICE_DISTRIBUTION.keys())[i % len(CONFIG.DEVICE_DISTRIBUTION)]
            if device_type in ["smartphone_high", "edge_server"]:
                if gpu_capable_clients < available_gpus:
                    # ä¸ºæ”¯æŒGPUçš„å®¢æˆ·ç«¯åˆ†é…GPU
                    gpu_id = gpu_capable_clients % available_gpus
                    gpu_allocation.append(gpu_id)
                    gpu_capable_clients += 1
                else:
                    # GPUå·²åˆ†é…å®Œï¼Œä½¿ç”¨CPU
                    gpu_allocation.append(None)
            else:
                # ä½ç«¯è®¾å¤‡ä½¿ç”¨CPU
                gpu_allocation.append(None)
        
        gpu_summary = {
            "total_gpus": available_gpus,
            "server": "CPU",
            "clients_with_gpu": gpu_capable_clients,
            "clients_with_cpu": CONFIG.CLIENT_NUM - gpu_capable_clients
        }
        
        self.logger.info(f"ğŸ¯ GPUèµ„æºåˆ†é…: {gpu_summary}")
        self.logger.info(f"ğŸ“‹ è¯¦ç»†åˆ†é…: Server=CPU, Clients={gpu_allocation[1:]}")
        return gpu_allocation
    
    def _create_diverse_device_fleet(self, num_devices: int) -> List[EdgeDeviceProfile]:
        """åˆ›å»ºå¤šæ ·åŒ–çš„è¾¹ç¼˜è®¾å¤‡é˜Ÿåˆ—"""
        device_assignments = []
        device_types = list(CONFIG.DEVICE_DISTRIBUTION.keys())
        
        # æŒ‰ç…§é…ç½®çš„åˆ†å¸ƒæ¯”ä¾‹åˆ†é…è®¾å¤‡ç±»å‹
        for device_type, ratio in CONFIG.DEVICE_DISTRIBUTION.items():
            count = max(1, int(num_devices * ratio))  # è‡³å°‘ä¿è¯ä¸€ä¸ªè®¾å¤‡
            
            for i in range(count):
                if len(device_assignments) >= num_devices:
                    break
                    
                # è·å–åŸºç¡€è®¾å¤‡æ¡£æ¡ˆå¹¶åˆ›å»ºå˜ä½“
                base_profile = EDGE_DEVICE_PROFILES[device_type]
                device_variant = self._create_device_variant(base_profile, len(device_assignments) + 1)
                device_assignments.append(device_variant)
        
        # å¦‚æœè®¾å¤‡ä¸å¤Ÿï¼Œéšæœºæ·»åŠ 
        while len(device_assignments) < num_devices:
            device_type = random.choice(device_types)
            base_profile = EDGE_DEVICE_PROFILES[device_type]
            device_variant = self._create_device_variant(base_profile, len(device_assignments) + 1)
            device_assignments.append(device_variant)
        
        # è®°å½•è®¾å¤‡åˆ†å¸ƒ
        distribution_summary = {}
        for assignment in device_assignments:
            device_type = assignment.device_type
            distribution_summary[device_type] = distribution_summary.get(device_type, 0) + 1
        
        self.logger.info(f"ğŸ“± è¾¹ç¼˜è®¾å¤‡åˆ†å¸ƒ: {distribution_summary}")
        return device_assignments[:num_devices]
    
    def _create_device_variant(self, base_profile: EdgeDeviceProfile, device_id: int) -> EdgeDeviceProfile:
        """åˆ›å»ºè®¾å¤‡å˜ä½“ï¼ˆå¢åŠ çœŸå®æ€§ï¼‰"""
        import copy
        variant = copy.deepcopy(base_profile)
        
        # è®¾å¤‡IDå”¯ä¸€åŒ–
        variant.device_id = f"{base_profile.device_id}_{device_id}"
        
        # æ·»åŠ éšæœºå˜åŒ–ï¼ˆÂ±20%ï¼‰
        variation_factor = random.uniform(0.8, 1.2)
        
        # CPUå˜åŒ–
        base_cpu = float(variant.cpu_limit)
        variant.cpu_limit = f"{base_cpu * variation_factor:.1f}"
        
        # ç½‘ç»œå˜åŒ–
        variant.bandwidth_up_kbps = int(variant.bandwidth_up_kbps * variation_factor)
        variant.bandwidth_down_kbps = int(variant.bandwidth_down_kbps * variation_factor)
        variant.latency_ms = max(10, int(variant.latency_ms * variation_factor))
        
        # å¯ç”¨æ€§éšæœºåŒ–
        variant.availability_ratio *= random.uniform(0.9, 1.0)
        
        return variant
    
    def _get_ray_resources_for_device(self, device_profile: EdgeDeviceProfile) -> Dict[str, Any]:
        """æ ¹æ®è®¾å¤‡ç±»å‹è·å–Rayèµ„æºåˆ†é…"""
        base_cpu = max(0.1, float(device_profile.cpu_limit))
        
        # æ ¹æ®è®¾å¤‡ç±»å‹è°ƒæ•´èµ„æº
        if device_profile.device_type == "iot":
            return {"num_cpus": 0.2, "memory": 256 * 1024 * 1024}  # 256MB
        elif device_profile.device_type == "smartphone" and "low" in device_profile.device_id:
            return {"num_cpus": 0.5, "memory": 1 * 1024 * 1024 * 1024}  # 1GB
        elif device_profile.device_type == "smartphone":
            return {"num_cpus": 1.0, "memory": 4 * 1024 * 1024 * 1024}  # 4GB
        elif device_profile.device_type == "edge_server":
            return {"num_cpus": 2.0, "memory": 8 * 1024 * 1024 * 1024}  # 8GB
        else:  # raspberry_pi, edge_device
            return {"num_cpus": 0.8, "memory": 2 * 1024 * 1024 * 1024}  # 2GB
    
    def cleanup_environment(self):
        """æ¸…ç†ç¯å¢ƒ"""
        if self.cleanup_performed:
            return
            
        self.logger.info("ğŸ§¹ æ¸…ç†ç¯å¢ƒ...")
        
        # åœæ­¢æ—§è¿›ç¨‹
        subprocess.run(['pkill', '-9', '-f', 'python.*federatedscope'], 
                      capture_output=True, check=False)
        
        # æ¸…ç†æ•°æ®åº“æ–‡ä»¶
        try:
            import glob
            db_files = glob.glob('tmp/client_*/client_*_chunks.db')
            for db_file in db_files:
                if os.path.exists(db_file):
                    os.remove(db_file)
        except Exception as e:
            self.logger.debug(f"æ¸…ç†æ•°æ®åº“æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç†æ—¥å¿—ç›®å½•
        for log_dir in ['connection_logs', 'topology_logs', 'bittorrent_logs']:
            subprocess.run(['rm', '-rf', log_dir], check=False)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(CONFIG.OUTPUT_DIR, exist_ok=True)
        os.makedirs(CONFIG.LOG_DIR, exist_ok=True)
        
        time.sleep(1)
        self.cleanup_performed = True
        self.logger.info("âœ… ç¯å¢ƒæ¸…ç†å®Œæˆ")
    
    def start_federated_learning(self):
        """å¯åŠ¨è”é‚¦å­¦ä¹ """
        self.logger.info(f"ğŸš€ å¯åŠ¨Ray V2è”é‚¦å­¦ä¹ ")
        self.logger.info(f"ğŸ“Š é…ç½®: {CONFIG.CLIENT_NUM}ä¸ªå®¢æˆ·ç«¯, {CONFIG.TOTAL_ROUNDS}è½®è®­ç»ƒ, æ€»èŠ‚ç‚¹æ•°: {CONFIG.CLIENT_NUM + 1}")
        
        # æ¸…ç†ç¯å¢ƒ
        self.cleanup_environment()
        
        # åˆå§‹åŒ–Dockerç¯å¢ƒ (å¦‚æœå¯ç”¨)
        if CONFIG.USE_DOCKER:
            self.docker_manager = DockerManager()
            if not self.docker_manager.docker_available:
                self.logger.warning("âš ï¸  Dockerä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°éå®¹å™¨æ¨¡å¼")
                CONFIG.USE_DOCKER = False
                # ç»§ç»­ä½¿ç”¨éDockeræ¨¡å¼
            else:
                # æ£€æŸ¥å¹¶ç¡®ä¿Dockeré•œåƒå°±ç»ª
                self.logger.info("ğŸ” æ£€æŸ¥Dockeré•œåƒ...")
                if not self.docker_manager.ensure_images_ready():
                    self.logger.warning("âš ï¸  Dockeré•œåƒæœªå°±ç»ªï¼Œåˆ‡æ¢åˆ°éå®¹å™¨æ¨¡å¼")
                    CONFIG.USE_DOCKER = False
                else:
                    # è®¾ç½®Dockerç½‘ç»œç¯å¢ƒ
                    if not self.docker_manager.setup_docker_environment():
                        self.logger.error("âŒ Dockerç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œåˆ‡æ¢åˆ°éå®¹å™¨æ¨¡å¼")
                        CONFIG.USE_DOCKER = False
                    else:
                        self.logger.info("âœ… Dockerç¯å¢ƒå’Œé•œåƒåˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–Ray
        self.initialize_ray_cluster()
        
        # GPUèµ„æºåˆ†é…
        gpu_allocation = self.allocate_gpu_resources()
        server_gpu = gpu_allocation[0]
        client_gpus = gpu_allocation[1:]
        
        # ç”Ÿæˆé…ç½®
        base_config = self.generate_base_config()
        
        # ğŸ–¥ï¸ å¯åŠ¨æœåŠ¡å™¨ï¼ˆå›ºå®šä½¿ç”¨CPUèµ„æºï¼‰
        server_config = base_config.copy()
        server_config['distribute']['role'] = 'server'
        server_config['use_gpu'] = False  # æœåŠ¡å™¨å¼ºåˆ¶ä½¿ç”¨CPU
        
        # æœåŠ¡å™¨èµ„æºé…ç½®ï¼šåªä½¿ç”¨CPUï¼Œä¸å ç”¨GPU
        server_resources = {"num_cpus": 2}
        # æ³¨æ„ï¼šserver_gpuå§‹ç»ˆä¸ºNoneï¼ŒæœåŠ¡å™¨ä¸ä½¿ç”¨GPU
        
        # æ ¹æ®Dockerå¯ç”¨æ€§é€‰æ‹©Actorç±»å‹
        if CONFIG.USE_DOCKER:
            self.server_actor = DockerFederatedScopeServer.options(**server_resources).remote(
                server_config, server_gpu
            )
        else:
            self.server_actor = FallbackFederatedScopeServer.options(**server_resources).remote(
                server_config, server_gpu
            )
        
        server_ip, server_port = ray.get(self.server_actor.start.remote())
        self.server_info = (server_ip, server_port)
        
        self.logger.info(f"âœ… æœåŠ¡å™¨å·²å¯åŠ¨: {server_ip}:{server_port}")
        time.sleep(3)
        
        # åˆ›å»ºå¤šæ ·åŒ–çš„è¾¹ç¼˜è®¾å¤‡
        device_assignments = self._create_diverse_device_fleet(CONFIG.CLIENT_NUM)
        
        # å¯åŠ¨Dockerå®¢æˆ·ç«¯
        successful_clients = 0
        for i, device_profile in enumerate(device_assignments):
            client_id = i + 1
            
            client_config = base_config.copy()
            client_config['distribute']['role'] = 'client'
            
            # Rayèµ„æºåˆ†é…ï¼ˆåŸºäºè®¾å¤‡ç±»å‹å’ŒGPUåˆ†é…ï¼‰
            client_resources = self._get_ray_resources_for_device(device_profile)
            
            # ğŸ® æ·»åŠ GPUèµ„æºåˆ†é…ï¼ˆå¦‚æœå®¢æˆ·ç«¯åº”è¯¥ä½¿ç”¨GPUï¼‰
            client_gpu = client_gpus[i] if i < len(client_gpus) else None
            if client_gpu is not None and device_profile.device_type in ["smartphone_high", "edge_server"]:
                client_resources["num_gpus"] = 1  # ä¸ºGPUå®¢æˆ·ç«¯åˆ†é…1ä¸ªGPU
            
            try:
                # æ ¹æ®Dockerå¯ç”¨æ€§é€‰æ‹©Actorç±»å‹
                if CONFIG.USE_DOCKER:
                    client_actor = DockerFederatedScopeClient.options(**client_resources).remote(
                        client_id, client_config, server_ip, server_port, device_profile
                    )
                else:
                    client_actor = FallbackFederatedScopeClient.options(**client_resources).remote(
                        client_id, client_config, server_ip, server_port, device_profile
                    )
                
                self.client_actors.append(client_actor)
                
                # å¯åŠ¨å®¢æˆ·ç«¯å®¹å™¨
                start_result = ray.get(client_actor.start.remote())
                if start_result:
                    successful_clients += 1
                    self.logger.info(f"âœ… å®¢æˆ·ç«¯{client_id} ({device_profile.device_type}) å¯åŠ¨æˆåŠŸ")
                else:
                    self.logger.error(f"âŒ å®¢æˆ·ç«¯{client_id} ({device_profile.device_type}) å¯åŠ¨å¤±è´¥")
                    
                time.sleep(3)  # ç»™Dockerå®¹å™¨æ›´å¤šå¯åŠ¨æ—¶é—´
                
            except Exception as e:
                self.logger.error(f"âŒ å®¢æˆ·ç«¯{client_id} åˆ›å»ºå¤±è´¥: {e}")
        
        if successful_clients < CONFIG.CLIENT_NUM * 0.7:  # è‡³å°‘70%æˆåŠŸ
            self.logger.error(f"âŒ å®¢æˆ·ç«¯å¯åŠ¨æˆåŠŸç‡è¿‡ä½: {successful_clients}/{CONFIG.CLIENT_NUM}")
            return
            
        self.logger.info(f"âœ… {successful_clients}/{CONFIG.CLIENT_NUM} ä¸ªDockerå®¢æˆ·ç«¯å¯åŠ¨æˆåŠŸ")
        
        self.logger.info(f"âœ… æ‰€æœ‰{CONFIG.CLIENT_NUM}ä¸ªå®¢æˆ·ç«¯å·²å¯åŠ¨å®Œæˆ")
        
        # ç›‘æ§è®­ç»ƒ
        self.monitor_training()
        
    def monitor_training(self):
        """ç›‘æ§è®­ç»ƒè¿›åº¦"""
        self.logger.info(f"ğŸ“Š å¼€å§‹ç›‘æ§è®­ç»ƒï¼ˆ{CONFIG.MONITOR_DURATION}ç§’ï¼‰...")
        
        start_time = time.time()
        
        while True:
            elapsed = int(time.time() - start_time)
            
            if elapsed > CONFIG.MONITOR_DURATION:
                self.logger.info("â° ç›‘æ§æ—¶é—´ç»“æŸ")
                break
            
            # æ£€æŸ¥çŠ¶æ€
            server_status = ray.get(self.server_actor.get_status.remote())
            client_statuses = ray.get([
                actor.get_status.remote() for actor in self.client_actors
            ])
            
            running_clients = sum(1 for s in client_statuses if s["status"] == "running")
            
            # èµ„æºä½¿ç”¨æƒ…å†µ
            cluster_resources = ray.cluster_resources()
            available_resources = ray.available_resources()
            
            # è®¡ç®—å®é™…GPUä½¿ç”¨æƒ…å†µ
            total_gpus = int(cluster_resources.get('GPU', 0))
            available_gpus = int(available_resources.get('GPU', 0))
            gpu_used = total_gpus - available_gpus
            
            # ç»Ÿè®¡å®¢æˆ·ç«¯ç±»å‹
            gpu_clients = 0
            cpu_clients = 0
            for status in client_statuses:
                if status.get("status") == "running":
                    # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜ç«¯è®¾å¤‡ä¼šä½¿ç”¨GPU
                    device_type = status.get("device_type", "unknown")
                    if device_type in ["smartphone_high", "edge_server"] and total_gpus > gpu_clients:
                        gpu_clients += 1
                    else:
                        cpu_clients += 1
            
            self.logger.info(
                f"â° {elapsed}s | æœåŠ¡å™¨: {server_status['status']} | "
                f"å®¢æˆ·ç«¯: GPU={gpu_clients}, CPU={cpu_clients} | "
                f"Ray GPUä½¿ç”¨: {gpu_used}/{total_gpus}"
            )
            
            # æ£€æŸ¥è®­ç»ƒå®Œæˆ
            if server_status["status"] != "running":
                self.logger.info("ğŸ æœåŠ¡å™¨è®­ç»ƒå®Œæˆ")
                break
            
            if running_clients == 0:
                self.logger.info("ğŸ æ‰€æœ‰å®¢æˆ·ç«¯è®­ç»ƒå®Œæˆ")
                break
            
            time.sleep(10)
    
    def stop_all(self):
        """åœæ­¢æ‰€æœ‰è¿›ç¨‹å’ŒDockerå®¹å™¨"""
        self.logger.info("ğŸ›‘ åœæ­¢æ‰€æœ‰è”é‚¦å­¦ä¹ è¿›ç¨‹...")
        
        # åœæ­¢Ray Actors
        try:
            if self.server_actor:
                ray.get(self.server_actor.stop.remote())
            
            if self.client_actors:
                stop_futures = [actor.stop.remote() for actor in self.client_actors]
                ray.get(stop_futures)
        except Exception as e:
            self.logger.warning(f"âš ï¸  Ray Actorsåœæ­¢è­¦å‘Š: {e}")
        
        # æ¸…ç†Dockerç¯å¢ƒ
        if CONFIG.USE_DOCKER and hasattr(self, 'docker_manager'):
            try:
                self.docker_manager.cleanup_docker_environment()
                self.logger.info("âœ… Dockerç¯å¢ƒå·²æ¸…ç†")
            except Exception as e:
                self.logger.warning(f"âš ï¸  Dockeræ¸…ç†è­¦å‘Š: {e}")
        
        self.logger.info("âœ… æ‰€æœ‰èµ„æºå·²åœæ­¢")
        
    def generate_results_summary(self):
        """ç”Ÿæˆç»“æœæ‘˜è¦"""
        self.logger.info("ğŸ“ˆ ç”Ÿæˆç»“æœæ‘˜è¦...")
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
        log_files = {
            'server': f"{CONFIG.LOG_DIR}/server.log",
            'clients': [f"{CONFIG.LOG_DIR}/client_{i}.log" for i in range(1, CONFIG.CLIENT_NUM + 1)]
        }
        
        summary = {
            'configuration': {
                'client_num': CONFIG.CLIENT_NUM,
                'total_rounds': CONFIG.TOTAL_ROUNDS,
                'dataset': CONFIG.DATASET,
                'model': CONFIG.MODEL_TYPE,
                'chunk_num': CONFIG.CHUNK_NUM,
                'importance_method': CONFIG.IMPORTANCE_METHOD
            },
            'log_files': log_files,
            'output_directories': {
                'server': f"{CONFIG.OUTPUT_DIR}/server_output",
                'clients': [f"{CONFIG.OUTPUT_DIR}/client_{i}_output" for i in range(1, CONFIG.CLIENT_NUM + 1)]
            }
        }
        
        # ä¿å­˜æ‘˜è¦
        summary_file = f"{CONFIG.OUTPUT_DIR}/results_summary.yaml"
        with open(summary_file, 'w') as f:
            yaml.safe_dump(summary, f)
        
        self.logger.info(f"ğŸ“„ ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_file}")
        
        return summary

# ============================================================================
# ğŸ¬ ä¸»ç¨‹åºå…¥å£
# ============================================================================

def display_banner():
    """æ˜¾ç¤ºå¯åŠ¨æ¨ªå¹…"""
    docker_status = "âœ… å¯ç”¨" if CONFIG.USE_DOCKER else "âŒ ç¦ç”¨"
    network_sim_status = "âœ… å¯ç”¨" if CONFIG.ENABLE_NETWORK_SIMULATION else "âŒ ç¦ç”¨"
    
    banner = f"""
{'='*80}
ğŸš€ Ray-Powered FederatedScope V2 Script (Docker Edition)
{'='*80}
ğŸ“Š é…ç½®ä¿¡æ¯:
   â€¢ å®¢æˆ·ç«¯æ•°é‡: {CONFIG.CLIENT_NUM}
   â€¢ è®­ç»ƒè½®æ•°: {CONFIG.TOTAL_ROUNDS}
   â€¢ æ•°æ®é›†: {CONFIG.DATASET}
   â€¢ æ¨¡å‹: {CONFIG.MODEL_TYPE}
   â€¢ Chunkæ•°: {CONFIG.CHUNK_NUM}
   â€¢ é‡è¦åº¦æ–¹æ³•: {CONFIG.IMPORTANCE_METHOD}
   â€¢ ç›‘æ§æ—¶é•¿: {CONFIG.MONITOR_DURATION}s

ğŸ³ Dockeræ¨¡å¼: {docker_status}
ğŸŒ ç½‘ç»œä»¿çœŸ: {network_sim_status}
ğŸ“± è®¾å¤‡åˆ†å¸ƒ: {dict(CONFIG.DEVICE_DISTRIBUTION)}

ğŸ’¡ è¾“å‡ºç›®å½•: {CONFIG.OUTPUT_DIR}
ğŸ“ æ—¥å¿—ç›®å½•: {CONFIG.LOG_DIR}
{'='*80}
"""
    print(banner)

def main():
    """ä¸»å‡½æ•°"""
    display_banner()
    
    ray_fl = RayV2FederatedLearning()
    
    try:
        # å¯åŠ¨è”é‚¦å­¦ä¹ 
        ray_fl.start_federated_learning()
        
        # ç”Ÿæˆç»“æœæ‘˜è¦
        summary = ray_fl.generate_results_summary()
        
        print("\nğŸ‰ Ray V2 è”é‚¦å­¦ä¹ å®Œæˆï¼")
        print(f"ğŸ“„ ç»“æœæ‘˜è¦: {CONFIG.OUTPUT_DIR}/results_summary.yaml")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {CONFIG.LOG_DIR}/")
        
        if CONFIG.ENABLE_RAY_DASHBOARD:
            print(f"ğŸŒ Ray Dashboard: http://127.0.0.1:8265")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†...")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        ray_fl.stop_all()
        ray.shutdown()
        print("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")

if __name__ == "__main__":
    main()