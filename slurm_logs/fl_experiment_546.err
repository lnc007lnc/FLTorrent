2025-12-25 21:28:19,230 - __main__ - INFO - ðŸš€ Start Ray V2 federated learning
2025-12-25 21:28:19,231 - __main__ - INFO - ðŸ“Š Configuration: 50 clients, 100 rounds training, total nodes: 51
2025-12-25 21:28:19,231 - __main__ - INFO - ðŸ§¹ Clean environment...
2025-12-25 21:28:22,761 - __main__ - INFO - ðŸ—‘ï¸  Cleaned tmpfs chunk directory: /tmp/fl_chunks
2025-12-25 21:28:23,221 - __main__ - DEBUG - ðŸ—‘ï¸  Cleaned mount directory (simple): /home/naicheng_li/FLTorrent/docker_data/tmp
2025-12-25 21:28:23,228 - __main__ - DEBUG - ðŸ—‘ï¸  Cleaned mount directory (simple): /home/naicheng_li/FLTorrent/docker_data/app_tmp
2025-12-25 21:28:24,238 - __main__ - INFO - âœ… Environment cleanup completed
2025-12-25 21:28:24,238 - __main__ - INFO - ðŸš€ Applying host network optimizations for ultra-high concurrency...
2025-12-25 21:28:24,352 - __main__ - WARNING - âš ï¸  22 network optimizations could not be applied (may need sudo access)
2025-12-25 21:28:24,352 - __main__ - DEBUG -    Failed: net.core.somaxconn - sudo: you do not exist in the passwd database
2025-12-25 21:28:24,352 - __main__ - DEBUG -    Failed: net.core.netdev_max_backlog - sudo: you do not exist in the passwd database
2025-12-25 21:28:24,352 - __main__ - DEBUG -    Failed: net.core.rmem_default - sudo: you do not exist in the passwd database
2025-12-25 21:28:24,352 - __main__ - WARNING - âš ï¸  No host network optimizations applied! High-concurrency FL may experience issues.
2025-12-25 21:28:24,352 - __main__ - WARNING -    Consider running with sudo or contacting HPC admin to apply these settings.
2025-12-25 21:28:24,353 - __main__ - INFO - ðŸ¦­ Initializing Podman rootless environment...
2025-12-25 21:28:24,357 - __main__ - WARNING - âš ï¸  Podman unavailable, trying Docker...
2025-12-25 21:28:24,357 - __main__ - INFO - ðŸ“¦ Using non-container mode (Fallback)
2025-12-25 21:28:26,332 - __main__ - INFO - ðŸ” Found available port for Ray dashboard: 8265
2025-12-25 21:28:26,411 - filelock - DEBUG - Attempting to acquire lock 140389606697824 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/node_ip_address.json.lock
2025-12-25 21:28:26,414 - filelock - DEBUG - Lock 140389606697824 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/node_ip_address.json.lock
2025-12-25 21:28:26,417 - filelock - DEBUG - Attempting to release lock 140389606697824 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/node_ip_address.json.lock
2025-12-25 21:28:26,417 - filelock - DEBUG - Lock 140389606697824 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/node_ip_address.json.lock
2025-12-25 21:28:26,418 - filelock - DEBUG - Attempting to acquire lock 140389606692016 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,419 - filelock - DEBUG - Lock 140389606692016 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,422 - filelock - DEBUG - Attempting to release lock 140389606692016 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,422 - filelock - DEBUG - Lock 140389606692016 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,422 - filelock - DEBUG - Attempting to acquire lock 140389606692064 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,423 - filelock - DEBUG - Lock 140389606692064 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,424 - filelock - DEBUG - Attempting to release lock 140389606692064 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,424 - filelock - DEBUG - Lock 140389606692064 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,424 - filelock - DEBUG - Attempting to acquire lock 140389606697680 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,425 - filelock - DEBUG - Lock 140389606697680 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,426 - filelock - DEBUG - Attempting to release lock 140389606697680 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,426 - filelock - DEBUG - Lock 140389606697680 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,426 - filelock - DEBUG - Attempting to acquire lock 140389606692496 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,427 - filelock - DEBUG - Lock 140389606692496 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,428 - filelock - DEBUG - Attempting to release lock 140389606692496 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,428 - filelock - DEBUG - Lock 140389606692496 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,428 - filelock - DEBUG - Attempting to acquire lock 140389606691248 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,429 - filelock - DEBUG - Lock 140389606691248 acquired on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,430 - filelock - DEBUG - Attempting to release lock 140389606691248 on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:26,431 - filelock - DEBUG - Lock 140389606691248 released on /home/naicheng_li/ray/session_2025-12-25_21-28-26_402180_1964068/ports_by_node.json.lock
2025-12-25 21:28:29,037	INFO worker.py:1998 -- Started a local Ray instance. View the dashboard at [1m[32m10.0.0.2:8265 [39m[22m
/home/naicheng_li/.conda/envs/flv2/lib/python3.10/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
2025-12-25 21:28:30,008 - __main__ - INFO - ðŸš€ Ray cluster initialization completed:
2025-12-25 21:28:30,008 - __main__ - INFO -    ðŸ“Š Resources: {'CPU': 64.0, 'accelerator_type:A100': 1.0, 'object_store_memory': 145967201280.0, 'node:__internal_head__': 1.0, 'GPU': 4.0, 'node:10.0.0.2': 1.0, 'memory': 376179995648.0}
2025-12-25 21:28:30,008 - __main__ - INFO -    ðŸŒ Dashboard: http://127.0.0.1:8265
2025-12-25 21:28:30,008 - __main__ - DEBUG - Found node: 0974e7f97032... IP: 10.0.0.2, Resources: {'memory': 376179995648.0, 'CPU': 64.0, 'GPU': 4.0, 'node:10.0.0.2': 1.0, 'accelerator_type:A100': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 145967201280.0}
2025-12-25 21:28:30,009 - __main__ - INFO - ðŸŒ Ray Cluster Topology:
2025-12-25 21:28:30,009 - __main__ - INFO -    ðŸ“ Head node: 0974e7f97032... (Server will run here)
2025-12-25 21:28:30,009 - __main__ - WARNING -    âš ï¸ No worker nodes found! Clients will run on head node (not recommended)
2025-12-25 21:28:30,009 - __main__ - INFO - ðŸŽ® Detected GPU type on node 0974e7f97032...: A100 -> 40.0GB per GPU
2025-12-25 21:28:30,009 - __main__ - INFO - ðŸ“ Head node (0974e7f97032...): 4.0 GPUs, 160.0GB total memory
2025-12-25 21:28:30,009 - __main__ - INFO - ðŸ“Š Total GPU memory across all nodes: 160.0GB
2025-12-25 21:28:30,009 - __main__ - INFO - ðŸ“Š Memory per client: 3.0GB â†’ Max capacity: 53 clients
2025-12-25 21:28:30,010 - __main__ - INFO -    Node 0974e7f97032...: 50 clients (160.0GB / 50 = 3.2GB/client)
2025-12-25 21:28:30,010 - __main__ - INFO -    Node 0974e7f97032...: 4.0 GPU, 50 clients, max 13 clients/GPU -> 0.0731 GPU/client
2025-12-25 21:28:30,010 - __main__ - INFO - ðŸŽ¯ GPU allocation summary: {'total_available_gpus': 4.0, 'total_allocated_gpus': 3.655, 'utilization_rate': '91.38%', 'server': 'CPU only', 'per_node_allocation': {'0974e7f97032': {'count': 50, 'total_gpu': 3.6550000000000025}}, 'gpu_clients': 50, 'cpu_clients': 0}
2025-12-25 21:28:30,010 - __main__ - INFO - ðŸ“‹ Client distribution: 50 GPU clients, 0 CPU clients
2025-12-25 21:28:30,011 - __main__ - INFO - ðŸ”Œ Single-node mode detected - UDS can be enabled
2025-12-25 21:28:30,011 - __main__ - INFO - ðŸ“ Server scheduled to head node: 0974e7f97032...
2025-12-25 21:28:30,135 - __main__ - INFO - ðŸ“¦ Using Fallback (no container) for Server
2025-12-25 21:28:30,211 - __main__ - INFO - âœ… Server started: unix:///tmp/federatedscope_uds/server_37205.sock:37205
2025-12-25 21:28:45,223 - __main__ - INFO - ðŸ“± Edge device distribution: {'smartphone': 50}
2025-12-25 21:28:45,223 - __main__ - INFO - ðŸ“Š Client distribution plan:
2025-12-25 21:28:45,224 - __main__ - INFO -    Client 1 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,224 - __main__ - INFO -    Client 2 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,225 - __main__ - INFO -    Client 3 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,225 - __main__ - INFO -    Client 4 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,226 - __main__ - INFO -    Client 5 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,226 - __main__ - INFO -    Client 6 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,226 - __main__ - INFO -    Client 7 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,227 - __main__ - INFO -    Client 8 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,227 - __main__ - INFO -    Client 9 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,228 - __main__ - INFO -    Client 10 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,228 - __main__ - INFO -    Client 11 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,229 - __main__ - INFO -    Client 12 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,229 - __main__ - INFO -    Client 13 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,229 - __main__ - INFO -    Client 14 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,230 - __main__ - INFO -    Client 15 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,230 - __main__ - INFO -    Client 16 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,231 - __main__ - INFO -    Client 17 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,231 - __main__ - INFO -    Client 18 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,231 - __main__ - INFO -    Client 19 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,232 - __main__ - INFO -    Client 20 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,232 - __main__ - INFO -    Client 21 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,233 - __main__ - INFO -    Client 22 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,233 - __main__ - INFO -    Client 23 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,233 - __main__ - INFO -    Client 24 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,234 - __main__ - INFO -    Client 25 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,234 - __main__ - INFO -    Client 26 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,234 - __main__ - INFO -    Client 27 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,235 - __main__ - INFO -    Client 28 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,235 - __main__ - INFO -    Client 29 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,236 - __main__ - INFO -    Client 30 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,236 - __main__ - INFO -    Client 31 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,236 - __main__ - INFO -    Client 32 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,237 - __main__ - INFO -    Client 33 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,237 - __main__ - INFO -    Client 34 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,237 - __main__ - INFO -    Client 35 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,238 - __main__ - INFO -    Client 36 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,238 - __main__ - INFO -    Client 37 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,239 - __main__ - INFO -    Client 38 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,239 - __main__ - INFO -    Client 39 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,239 - __main__ - INFO -    Client 40 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,240 - __main__ - INFO -    Client 41 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,240 - __main__ - INFO -    Client 42 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,241 - __main__ - INFO -    Client 43 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,241 - __main__ - INFO -    Client 44 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,241 - __main__ - INFO -    Client 45 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,242 - __main__ - INFO -    Client 46 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,242 - __main__ - INFO -    Client 47 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,242 - __main__ - INFO -    Client 48 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,243 - __main__ - INFO -    Client 49 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,243 - __main__ - INFO -    Client 50 -> head (0974e7f97032...), Node CPUs: 64.0, Clients on node: 50
2025-12-25 21:28:45,244 - __main__ - INFO - ðŸ”§ Client 1 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:28:45,327 - __main__ - INFO - âœ… Client 1 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:28:48,331 - __main__ - INFO - ðŸ”§ Client 2 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:28:48,414 - __main__ - INFO - âœ… Client 2 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:28:51,418 - __main__ - INFO - ðŸ”§ Client 3 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:28:51,497 - __main__ - INFO - âœ… Client 3 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:28:54,501 - __main__ - INFO - ðŸ”§ Client 4 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:28:54,587 - __main__ - INFO - âœ… Client 4 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:28:57,591 - __main__ - INFO - ðŸ”§ Client 5 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:28:57,677 - __main__ - INFO - âœ… Client 5 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:00,681 - __main__ - INFO - ðŸ”§ Client 6 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:00,763 - __main__ - INFO - âœ… Client 6 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:03,767 - __main__ - INFO - ðŸ”§ Client 7 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:03,841 - __main__ - INFO - âœ… Client 7 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:06,844 - __main__ - INFO - ðŸ”§ Client 8 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:06,920 - __main__ - INFO - âœ… Client 8 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:09,923 - __main__ - INFO - ðŸ”§ Client 9 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:09,997 - __main__ - INFO - âœ… Client 9 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:13,001 - __main__ - INFO - ðŸ”§ Client 10 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:13,091 - __main__ - INFO - âœ… Client 10 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:16,095 - __main__ - INFO - ðŸ”§ Client 11 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:16,181 - __main__ - INFO - âœ… Client 11 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:19,184 - __main__ - INFO - ðŸ”§ Client 12 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:19,274 - __main__ - INFO - âœ… Client 12 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:22,277 - __main__ - INFO - ðŸ”§ Client 13 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:22,349 - __main__ - INFO - âœ… Client 13 (smartphone) started on head node (0974e7f97032...)
2025-12-25 21:29:25,353 - __main__ - INFO - ðŸ”§ Client 14 resources: num_cpus=1.1120, num_gpus=0.0731, memory=2.00GB
2025-12-25 21:29:25,443 - __main__ - INFO - âœ… Client 14 (smartphone) started on head node (0974e7f97032...)
slurmstepd-srv-it-node02: error: *** JOB 546 ON srv-it-node02 CANCELLED AT 2025-12-25T21:29:27 ***
