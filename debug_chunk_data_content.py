#!/usr/bin/env python3
"""
æ£€æŸ¥chunk_dataçš„å®é™…å†…å®¹å’Œé•¿åº¦
"""

import sqlite3
import pickle
import numpy as np

def check_chunk_data_content():
    """æ£€æŸ¥chunkæ•°æ®çš„å®é™…å†…å®¹"""
    
    db_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp/client_1/client_1_chunks.db"
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    try:
        # æµ‹è¯•å…·ä½“çš„chunkæŸ¥è¯¢
        test_cases = [2, 3, 4, 8, 0, 1]  # æ—¥å¿—ä¸­æŠ¥é”™çš„chunk_id
        
        for chunk_id in test_cases:
            print(f"\nğŸ” æ£€æŸ¥chunk_id={chunk_id}:")
            
            cursor.execute('''
                SELECT cd.data FROM chunk_metadata cm
                JOIN chunk_data cd ON cm.chunk_hash = cd.chunk_hash
                WHERE cm.round_num = ? AND cm.chunk_id = ?
            ''', (0, chunk_id))
            
            result = cursor.fetchone()
            if result:
                raw_data = result[0]
                print(f"  åŸå§‹æ•°æ®å¤§å°: {len(raw_data)} bytes")
                
                try:
                    chunk_data = pickle.loads(raw_data)
                    print(f"  ååºåˆ—åŒ–åç±»å‹: {type(chunk_data)}")
                    
                    if isinstance(chunk_data, np.ndarray):
                        print(f"  numpyæ•°ç»„å½¢çŠ¶: {chunk_data.shape}")
                        print(f"  numpyæ•°ç»„å¤§å°: {chunk_data.size}")
                        print(f"  numpyæ•°ç»„dtype: {chunk_data.dtype}")
                        print(f"  numpyæ•°ç»„å†…å®¹é¢„è§ˆ: {chunk_data}")
                        
                        # å…³é”®æ£€æŸ¥: len(chunk_data)
                        print(f"  len(chunk_data): {len(chunk_data)}")
                        print(f"  len(chunk_data) > 0: {len(chunk_data) > 0}")
                        
                        # æ¨¡æ‹Ÿbittorrent_manager.pyçš„æ£€æŸ¥
                        condition_result = chunk_data is not None and len(chunk_data) > 0
                        print(f"  BitTorrentæ¡ä»¶æ£€æŸ¥ç»“æœ: {condition_result}")
                        
                        if not condition_result:
                            print(f"  âš ï¸ è¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨! chunk_dataé•¿åº¦ä¸º0!")
                        else:
                            print(f"  âœ… æ¡ä»¶æ£€æŸ¥é€šè¿‡")
                            
                    else:
                        print(f"  len(chunk_data): {len(chunk_data) if hasattr(chunk_data, '__len__') else 'N/A'}")
                        
                except Exception as e:
                    print(f"  âŒ ååºåˆ—åŒ–å¤±è´¥: {e}")
            else:
                print(f"  âŒ æŸ¥è¯¢æ— ç»“æœ")
        
        # é¢å¤–æ£€æŸ¥: çœ‹çœ‹æ‰€æœ‰chunkçš„é•¿åº¦åˆ†å¸ƒ
        print(f"\nğŸ” æ‰€æœ‰chunkçš„é•¿åº¦åˆ†å¸ƒ:")
        cursor.execute('''
            SELECT cm.chunk_id, cd.data FROM chunk_metadata cm
            JOIN chunk_data cd ON cm.chunk_hash = cd.chunk_hash
            WHERE cm.round_num = 0
            ORDER BY cm.chunk_id
        ''')
        
        for row in cursor.fetchall():
            chunk_id, raw_data = row
            try:
                chunk_data = pickle.loads(raw_data)
                if isinstance(chunk_data, np.ndarray):
                    print(f"  chunk_{chunk_id}: shape={chunk_data.shape}, size={chunk_data.size}, len={len(chunk_data)}")
            except:
                print(f"  chunk_{chunk_id}: è§£æå¤±è´¥")
                
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    check_chunk_data_content()