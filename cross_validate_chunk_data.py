#!/usr/bin/env python3
"""
äº¤å‰éªŒè¯3ä¸ªå®¢æˆ·ç«¯çš„chunkæ•°æ®
åŒºåˆ†åˆæ³•çš„ç©ºchunk vs ä¸¢å¤±çš„æ•°æ®
"""

import sqlite3
import os
import hashlib
import pickle
from collections import defaultdict, Counter

def collect_all_chunk_info():
    """æ”¶é›†æ‰€æœ‰å®¢æˆ·ç«¯çš„chunkä¿¡æ¯"""
    print("ğŸ” æ”¶é›†æ‰€æœ‰å®¢æˆ·ç«¯çš„chunkä¿¡æ¯")
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    client_dbs = {
        1: os.path.join(base_path, "client_1", "client_1_chunks.db"),
        2: os.path.join(base_path, "client_2", "client_2_chunks.db"), 
        3: os.path.join(base_path, "client_3", "client_3_chunks.db")
    }
    
    # æ•°æ®ç»“æ„ï¼š{(round_num, source_client_id, chunk_id): {client_id: chunk_info}}
    all_chunks = defaultdict(dict)
    all_chunk_data = {}  # {client_id: {chunk_hash: data_info}}
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    for client_id, db_path in client_dbs.items():
        if not os.path.exists(db_path):
            continue
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        print(f"ğŸ“‹ å®¢æˆ·ç«¯ {client_id}:")
        
        # æ”¶é›†bt_chunksä¿¡æ¯
        cursor.execute("""
            SELECT round_num, source_client_id, chunk_id, chunk_hash, is_verified
            FROM bt_chunks 
            ORDER BY round_num, source_client_id, chunk_id
        """)
        
        bt_records = cursor.fetchall()
        print(f"   bt_chunksè®°å½•æ•°: {len(bt_records)}")
        
        for round_num, source_client_id, chunk_id, chunk_hash, is_verified in bt_records:
            chunk_key = (round_num, source_client_id, chunk_id)
            all_chunks[chunk_key][client_id] = {
                'hash': chunk_hash,
                'verified': is_verified,
                'is_empty': chunk_hash == empty_hash
            }
        
        # æ”¶é›†chunk_dataä¿¡æ¯
        cursor.execute("""
            SELECT chunk_hash, LENGTH(data), data
            FROM chunk_data
        """)
        
        data_records = cursor.fetchall()
        print(f"   chunk_dataè®°å½•æ•°: {len(data_records)}")
        
        client_data = {}
        for chunk_hash, data_length, data_blob in data_records:
            try:
                unpickled_data = pickle.loads(data_blob)
                client_data[chunk_hash] = {
                    'length': data_length,
                    'type': str(type(unpickled_data)),
                    'shape': getattr(unpickled_data, 'shape', None),
                    'size': getattr(unpickled_data, 'size', None) if hasattr(unpickled_data, 'size') else len(unpickled_data) if hasattr(unpickled_data, '__len__') else None
                }
            except Exception as e:
                client_data[chunk_hash] = {
                    'length': data_length,
                    'error': str(e)
                }
        
        all_chunk_data[client_id] = client_data
        conn.close()
    
    return all_chunks, all_chunk_data

def analyze_chunk_consistency(all_chunks):
    """åˆ†æchunkä¸€è‡´æ€§"""
    print(f"\nğŸ” åˆ†æchunkä¸€è‡´æ€§")
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_chunks = len(all_chunks)
    consistent_chunks = 0
    empty_chunks = 0
    non_empty_chunks = 0
    hash_mismatches = 0
    
    print(f"æ€»chunkæ•°é‡: {total_chunks}")
    
    # æŒ‰è½®æ¬¡åˆ†æ
    rounds_analysis = defaultdict(lambda: {'total': 0, 'empty': 0, 'non_empty': 0, 'consistent': 0})
    
    for chunk_key, client_data in all_chunks.items():
        round_num, source_client_id, chunk_id = chunk_key
        rounds_analysis[round_num]['total'] += 1
        
        # æ£€æŸ¥æ‰€æœ‰å®¢æˆ·ç«¯æ˜¯å¦å¯¹è¿™ä¸ªchunkæœ‰ä¸€è‡´çš„å“ˆå¸Œ
        hashes = set(info['hash'] for info in client_data.values())
        
        if len(hashes) == 1:
            # å“ˆå¸Œä¸€è‡´
            consistent_chunks += 1
            rounds_analysis[round_num]['consistent'] += 1
            
            chunk_hash = list(hashes)[0]
            if chunk_hash == empty_hash:
                empty_chunks += 1
                rounds_analysis[round_num]['empty'] += 1
            else:
                non_empty_chunks += 1
                rounds_analysis[round_num]['non_empty'] += 1
        else:
            # å“ˆå¸Œä¸ä¸€è‡´
            hash_mismatches += 1
            print(f"   âŒ å“ˆå¸Œä¸ä¸€è‡´: {chunk_key}")
            for client_id, info in client_data.items():
                print(f"      å®¢æˆ·ç«¯{client_id}: {info['hash'][:16]}...")
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   ä¸€è‡´çš„chunk: {consistent_chunks}/{total_chunks} ({consistent_chunks/total_chunks*100:.1f}%)")
    print(f"   ç©ºchunk: {empty_chunks} ({empty_chunks/total_chunks*100:.1f}%)")
    print(f"   éç©ºchunk: {non_empty_chunks} ({non_empty_chunks/total_chunks*100:.1f}%)")
    print(f"   å“ˆå¸Œä¸ä¸€è‡´: {hash_mismatches}")
    
    print(f"\nğŸ“ˆ æŒ‰è½®æ¬¡åˆ†æ:")
    for round_num in sorted(rounds_analysis.keys()):
        stats = rounds_analysis[round_num]
        print(f"   è½®æ¬¡ {round_num}: æ€»è®¡={stats['total']}, ç©º={stats['empty']}, éç©º={stats['non_empty']}, ä¸€è‡´={stats['consistent']}")

def analyze_data_availability(all_chunks, all_chunk_data):
    """åˆ†ææ•°æ®å¯ç”¨æ€§"""
    print(f"\nğŸ” åˆ†ææ•°æ®å¯ç”¨æ€§")
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    # ç»Ÿè®¡æ¯ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®è¦†ç›–ç‡
    for client_id, client_data in all_chunk_data.items():
        print(f"\nğŸ“Š å®¢æˆ·ç«¯ {client_id} æ•°æ®åˆ†æ:")
        print(f"   chunk_dataè¡¨è®°å½•æ•°: {len(client_data)}")
        
        # åˆ†ææ¯ä¸ªå­˜å‚¨çš„chunk
        for chunk_hash, data_info in client_data.items():
            if chunk_hash == empty_hash:
                print(f"   ğŸ”´ ç©ºchunkæ•°æ®: é•¿åº¦={data_info['length']}")
            else:
                print(f"   ğŸŸ¢ éç©ºchunkæ•°æ®: å“ˆå¸Œ={chunk_hash[:16]}..., é•¿åº¦={data_info['length']}")
                if 'shape' in data_info and data_info['shape'] is not None:
                    print(f"      å½¢çŠ¶: {data_info['shape']}")
                if 'size' in data_info and data_info['size'] is not None:
                    print(f"      å…ƒç´ æ•°: {data_info['size']}")
                if 'error' in data_info:
                    print(f"      âŒ ååºåˆ—åŒ–é”™è¯¯: {data_info['error']}")
    
    # äº¤å‰éªŒè¯ï¼šæ£€æŸ¥å“ªäº›éç©ºchunkåœ¨æ‰€æœ‰å®¢æˆ·ç«¯éƒ½ç¼ºå¤±æ•°æ®
    print(f"\nğŸ”— äº¤å‰éªŒè¯æ•°æ®å¯ç”¨æ€§:")
    
    # æ”¶é›†æ‰€æœ‰éç©ºchunkçš„å“ˆå¸Œ
    all_non_empty_hashes = set()
    for chunk_key, client_data in all_chunks.items():
        for client_id, info in client_data.items():
            if not info['is_empty']:
                all_non_empty_hashes.add(info['hash'])
    
    print(f"   å‘ç° {len(all_non_empty_hashes)} ä¸ªå”¯ä¸€çš„éç©ºchunkå“ˆå¸Œ")
    
    # æ£€æŸ¥æ¯ä¸ªéç©ºå“ˆå¸Œåœ¨chunk_dataä¸­çš„å¯ç”¨æ€§
    available_hashes = set()
    missing_hashes = set()
    
    for chunk_hash in all_non_empty_hashes:
        found_in_any_client = False
        found_in_clients = []
        
        for client_id, client_data in all_chunk_data.items():
            if chunk_hash in client_data:
                found_in_any_client = True
                found_in_clients.append(client_id)
        
        if found_in_any_client:
            available_hashes.add(chunk_hash)
            print(f"   âœ… å“ˆå¸Œ {chunk_hash[:16]}... åœ¨å®¢æˆ·ç«¯ {found_in_clients} ä¸­æœ‰æ•°æ®")
        else:
            missing_hashes.add(chunk_hash)
            print(f"   âŒ å“ˆå¸Œ {chunk_hash[:16]}... åœ¨æ‰€æœ‰å®¢æˆ·ç«¯ä¸­éƒ½ç¼ºå¤±æ•°æ®")
    
    print(f"\nğŸ“‹ æ•°æ®å¯ç”¨æ€§æ€»ç»“:")
    print(f"   æœ‰æ•°æ®çš„éç©ºchunk: {len(available_hashes)}/{len(all_non_empty_hashes)} ({len(available_hashes)/len(all_non_empty_hashes)*100:.1f}%)")
    print(f"   ç¼ºå¤±æ•°æ®çš„éç©ºchunk: {len(missing_hashes)}")

def analyze_chunk_patterns(all_chunks):
    """åˆ†æchunkæ¨¡å¼"""
    print(f"\nğŸ” åˆ†æchunkæ¨¡å¼")
    
    # æŒ‰æºå®¢æˆ·ç«¯å’Œchunk_idåˆ†æ
    source_patterns = defaultdict(lambda: defaultdict(list))
    
    for chunk_key, client_data in all_chunks.items():
        round_num, source_client_id, chunk_id = chunk_key
        
        # è·å–è¿™ä¸ªchunkçš„å“ˆå¸Œï¼ˆå‡è®¾ä¸€è‡´ï¼‰
        hashes = set(info['hash'] for info in client_data.values())
        if len(hashes) == 1:
            chunk_hash = list(hashes)[0]
            is_empty = list(client_data.values())[0]['is_empty']
            source_patterns[source_client_id][chunk_id].append({
                'round': round_num,
                'hash': chunk_hash,
                'is_empty': is_empty
            })
    
    print(f"\nğŸ“Š æ¯ä¸ªæºå®¢æˆ·ç«¯çš„chunkæ¨¡å¼:")
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    for source_client_id in sorted(source_patterns.keys()):
        print(f"\n   æºå®¢æˆ·ç«¯ {source_client_id}:")
        chunk_patterns = source_patterns[source_client_id]
        
        for chunk_id in sorted(chunk_patterns.keys()):
            chunk_history = chunk_patterns[chunk_id]
            empty_count = sum(1 for c in chunk_history if c['is_empty'])
            non_empty_count = len(chunk_history) - empty_count
            
            print(f"     Chunk {chunk_id}: {len(chunk_history)}è½®, ç©º={empty_count}, éç©º={non_empty_count}")
            
            if non_empty_count > 0:
                # æ˜¾ç¤ºéç©ºchunkçš„è¯¦æƒ…
                non_empty_chunks = [c for c in chunk_history if not c['is_empty']]
                unique_hashes = set(c['hash'] for c in non_empty_chunks)
                print(f"       éç©ºè½®æ¬¡: {[c['round'] for c in non_empty_chunks]}")
                print(f"       å”¯ä¸€å“ˆå¸Œæ•°: {len(unique_hashes)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” äº¤å‰éªŒè¯BitTorrent chunkæ•°æ®")
    print("=" * 80)
    
    # æ”¶é›†æ‰€æœ‰æ•°æ®
    all_chunks, all_chunk_data = collect_all_chunk_info()
    
    # åˆ†æä¸€è‡´æ€§
    analyze_chunk_consistency(all_chunks)
    
    # åˆ†ææ•°æ®å¯ç”¨æ€§
    analyze_data_availability(all_chunks, all_chunk_data)
    
    # åˆ†æchunkæ¨¡å¼
    analyze_chunk_patterns(all_chunks)
    
    print(f"\n{'='*80}")
    print("ğŸ¯ äº¤å‰éªŒè¯ç»“è®º:")
    print("1. éªŒè¯chunkå“ˆå¸Œåœ¨æ‰€æœ‰å®¢æˆ·ç«¯é—´çš„ä¸€è‡´æ€§")
    print("2. åŒºåˆ†åˆæ³•çš„ç©ºchunk vs åº”è¯¥æœ‰æ•°æ®ä½†ä¸¢å¤±çš„chunk")
    print("3. ç¡®å®šBitTorrentæ•°æ®å­˜å‚¨çš„çœŸå®çŠ¶å†µ")

if __name__ == "__main__":
    main()