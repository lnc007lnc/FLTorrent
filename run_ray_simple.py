#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆRayè”é‚¦å­¦ä¹ æµ‹è¯•è„šæœ¬
ä¸“æ³¨æµ‹è¯•Rayå’ŒGPUèµ„æºåˆ†é…ï¼Œä¸ä½¿ç”¨Docker
"""

import ray
import os
import sys
import time
import yaml
import logging
import psutil
from typing import Dict, List, Optional, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç®€åŒ–é…ç½®
class SimpleConfig:
    CLIENT_NUM = 3
    TOTAL_ROUNDS = 2
    MONITOR_DURATION = 60
    OUTPUT_DIR = "ray_simple_output"
    
CONFIG = SimpleConfig()

@ray.remote
class SimpleServer:
    """ç®€åŒ–çš„æœåŠ¡å™¨Actorï¼ˆCPUæ¨¡å¼ï¼‰"""
    
    def __init__(self, server_id: int):
        self.server_id = server_id
        self.node_ip = ray.util.get_node_ip_address()
        
    def start(self):
        """æ¨¡æ‹ŸæœåŠ¡å™¨å¯åŠ¨"""
        logger.info(f"ğŸ–¥ï¸ æœåŠ¡å™¨{self.server_id}å¯åŠ¨ - CPUæ¨¡å¼")
        time.sleep(2)  # æ¨¡æ‹Ÿåˆå§‹åŒ–æ—¶é—´
        return {"status": "started", "node_ip": self.node_ip}
        
    def get_status(self):
        """è·å–æœåŠ¡å™¨çŠ¶æ€"""
        return {
            "status": "running",
            "server_id": self.server_id,
            "node_ip": self.node_ip,
            "mode": "CPU"
        }
    
    def stop(self):
        """åœæ­¢æœåŠ¡å™¨"""
        logger.info(f"ğŸ–¥ï¸ æœåŠ¡å™¨{self.server_id}åœæ­¢")

@ray.remote
class SimpleClient:
    """ç®€åŒ–çš„å®¢æˆ·ç«¯Actor"""
    
    def __init__(self, client_id: int, gpu_assigned: bool):
        self.client_id = client_id
        self.gpu_assigned = gpu_assigned
        self.node_ip = ray.util.get_node_ip_address()
        
    def start(self):
        """æ¨¡æ‹Ÿå®¢æˆ·ç«¯å¯åŠ¨"""
        mode = "GPU" if self.gpu_assigned else "CPU"
        logger.info(f"ğŸ“± å®¢æˆ·ç«¯{self.client_id}å¯åŠ¨ - {mode}æ¨¡å¼")
        
        # æ£€æŸ¥GPUè®¿é—®
        gpu_info = self._check_gpu_access()
        time.sleep(1)  # æ¨¡æ‹Ÿåˆå§‹åŒ–æ—¶é—´
        
        return {
            "status": "started", 
            "client_id": self.client_id,
            "mode": mode,
            "gpu_info": gpu_info
        }
    
    def _check_gpu_access(self):
        """æ£€æŸ¥GPUè®¿é—®æƒ…å†µ"""
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                return {
                    "available": True,
                    "count": gpu_count,
                    "current_device": torch.cuda.current_device() if gpu_count > 0 else None
                }
        except:
            pass
        return {"available": False}
        
    def get_status(self):
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€"""
        return {
            "status": "running",
            "client_id": self.client_id,
            "node_ip": self.node_ip,
            "gpu_assigned": self.gpu_assigned
        }
    
    def stop(self):
        """åœæ­¢å®¢æˆ·ç«¯"""
        logger.info(f"ğŸ“± å®¢æˆ·ç«¯{self.client_id}åœæ­¢")

class SimpleRayFL:
    """ç®€åŒ–çš„Rayè”é‚¦å­¦ä¹ æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.server_actor = None
        self.client_actors = []
        
    def initialize_ray(self):
        """åˆå§‹åŒ–Rayé›†ç¾¤"""
        # æ£€æµ‹ç¡¬ä»¶èµ„æº
        num_cpus = psutil.cpu_count()
        num_gpus = 0
        
        try:
            import torch
            if torch.cuda.is_available():
                num_gpus = torch.cuda.device_count()
        except ImportError:
            pass
        
        # åˆå§‹åŒ–Ray
        ray.init(
            num_cpus=num_cpus,
            num_gpus=num_gpus,
            ignore_reinit_error=True,
            include_dashboard=True,
            dashboard_host="0.0.0.0",
            dashboard_port=8265
        )
        
        resources = ray.cluster_resources()
        logger.info(f"ğŸš€ Rayé›†ç¾¤èµ„æº: {dict(resources)}")
        
        return num_gpus
    
    def allocate_gpu_resources(self, total_gpus: int):
        """åˆ†é…GPUèµ„æº"""
        # æœåŠ¡å™¨ï¼šå¼ºåˆ¶CPU
        server_gpu = None
        
        # å®¢æˆ·ç«¯ï¼šæŒ‰éœ€åˆ†é…GPU
        client_gpus = []
        gpu_assigned = 0
        
        for i in range(CONFIG.CLIENT_NUM):
            # å‰é¢çš„å®¢æˆ·ç«¯ä¼˜å…ˆåˆ†é…GPU
            if gpu_assigned < total_gpus:
                client_gpus.append(gpu_assigned)
                gpu_assigned += 1
            else:
                client_gpus.append(None)
        
        logger.info(f"ğŸ¯ GPUåˆ†é… - æœåŠ¡å™¨:CPU, å®¢æˆ·ç«¯:{client_gpus}")
        return server_gpu, client_gpus
    
    def start_federated_learning(self):
        """å¯åŠ¨è”é‚¦å­¦ä¹ """
        logger.info(f"ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆRayè”é‚¦å­¦ä¹ ")
        logger.info(f"ğŸ“Š é…ç½®: {CONFIG.CLIENT_NUM}ä¸ªå®¢æˆ·ç«¯, {CONFIG.TOTAL_ROUNDS}è½®è®­ç»ƒ")
        
        # åˆå§‹åŒ–Ray
        total_gpus = self.initialize_ray()
        
        # GPUèµ„æºåˆ†é…
        server_gpu, client_gpus = self.allocate_gpu_resources(total_gpus)
        
        # å¯åŠ¨æœåŠ¡å™¨ï¼ˆCPUæ¨¡å¼ï¼‰
        server_resources = {"num_cpus": 1}
        self.server_actor = SimpleServer.options(**server_resources).remote(0)
        
        server_result = ray.get(self.server_actor.start.remote())
        logger.info(f"âœ… æœåŠ¡å™¨å¯åŠ¨ç»“æœ: {server_result}")
        
        # å¯åŠ¨å®¢æˆ·ç«¯
        successful_clients = 0
        for i in range(CONFIG.CLIENT_NUM):
            client_id = i + 1
            gpu_assigned = client_gpus[i] is not None
            
            # å®¢æˆ·ç«¯èµ„æºé…ç½®
            client_resources = {"num_cpus": 0.5}
            if gpu_assigned:
                client_resources["num_gpus"] = 1
            
            try:
                client_actor = SimpleClient.options(**client_resources).remote(
                    client_id, gpu_assigned
                )
                self.client_actors.append(client_actor)
                
                client_result = ray.get(client_actor.start.remote())
                logger.info(f"âœ… å®¢æˆ·ç«¯{client_id}å¯åŠ¨ç»“æœ: {client_result}")
                successful_clients += 1
                
            except Exception as e:
                logger.error(f"âŒ å®¢æˆ·ç«¯{client_id}å¯åŠ¨å¤±è´¥: {e}")
        
        logger.info(f"âœ… æˆåŠŸå¯åŠ¨ {successful_clients}/{CONFIG.CLIENT_NUM} ä¸ªå®¢æˆ·ç«¯")
        
        # ç›‘æ§è®­ç»ƒ
        self.monitor_training()
        
    def monitor_training(self):
        """ç›‘æ§è®­ç»ƒè¿›åº¦"""
        logger.info(f"ğŸ“Š å¼€å§‹ç›‘æ§è®­ç»ƒï¼ˆ{CONFIG.MONITOR_DURATION}ç§’ï¼‰...")
        
        start_time = time.time()
        
        while time.time() - start_time < CONFIG.MONITOR_DURATION:
            elapsed = int(time.time() - start_time)
            
            # æ£€æŸ¥çŠ¶æ€
            server_status = ray.get(self.server_actor.get_status.remote())
            client_statuses = ray.get([
                actor.get_status.remote() for actor in self.client_actors
            ])
            
            running_clients = len([s for s in client_statuses if s["status"] == "running"])
            gpu_clients = len([s for s in client_statuses if s["gpu_assigned"]])
            cpu_clients = running_clients - gpu_clients
            
            # èµ„æºä½¿ç”¨æƒ…å†µ
            cluster_resources = ray.cluster_resources()
            available_resources = ray.available_resources()
            
            logger.info(
                f"â° {elapsed}s | æœåŠ¡å™¨:è¿è¡Œä¸­ | "
                f"å®¢æˆ·ç«¯: GPU={gpu_clients}, CPU={cpu_clients} | "
                f"æ€»èµ„æº: CPU={cluster_resources.get('CPU', 0):.1f}, "
                f"GPU={cluster_resources.get('GPU', 0)}"
            )
            
            time.sleep(10)
    
    def stop_all(self):
        """åœæ­¢æ‰€æœ‰Actor"""
        logger.info("ğŸ›‘ åœæ­¢æ‰€æœ‰Actor...")
        
        try:
            if self.server_actor:
                ray.get(self.server_actor.stop.remote())
            
            if self.client_actors:
                stop_futures = [actor.stop.remote() for actor in self.client_actors]
                ray.get(stop_futures)
        except Exception as e:
            logger.warning(f"âš ï¸ Actoråœæ­¢è­¦å‘Š: {e}")
        
        logger.info("âœ… æ‰€æœ‰Actorå·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    print(f"""
==============================================================
ğŸš€ ç®€åŒ–ç‰ˆRayè”é‚¦å­¦ä¹ æµ‹è¯•
==============================================================
ğŸ“Š é…ç½®:
   â€¢ å®¢æˆ·ç«¯æ•°é‡: {CONFIG.CLIENT_NUM}
   â€¢ è®­ç»ƒè½®æ•°: {CONFIG.TOTAL_ROUNDS}
   â€¢ ç›‘æ§æ—¶é•¿: {CONFIG.MONITOR_DURATION}s

ğŸ’¡ ç›®æ ‡: éªŒè¯Rayå’ŒGPUèµ„æºåˆ†é…åŠŸèƒ½
ğŸ“ æ¨¡å¼: çº¯CPU/GPUæ¨¡æ‹Ÿï¼Œæ— Dockerï¼Œæ— FederatedScopeä¾èµ–
==============================================================
""")
    
    ray_fl = SimpleRayFL()
    
    try:
        ray_fl.start_federated_learning()
        print("\nğŸ‰ ç®€åŒ–ç‰ˆRayè”é‚¦å­¦ä¹ æµ‹è¯•å®Œæˆï¼")
        print("ğŸŒ Ray Dashboard: http://127.0.0.1:8265")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†...")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        ray_fl.stop_all()
        ray.shutdown()
        print("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")

if __name__ == "__main__":
    main()