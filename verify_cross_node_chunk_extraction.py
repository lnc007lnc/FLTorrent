#!/usr/bin/env python3
"""
éªŒè¯è·¨èŠ‚ç‚¹chunkæ•°æ®æå–
å‡è®¾ä¸€ä¸ªèŠ‚ç‚¹è¦æå–å…¶ä»–èŠ‚ç‚¹çš„chunkæ•°æ®ï¼ˆè€ƒè™‘ç”Ÿå­˜æœŸé™åˆ¶ï¼Œåªæœ‰3/4è½®å¯ç”¨ï¼‰
"""

import sqlite3
import os
import hashlib
import pickle
import numpy as np
from collections import defaultdict

def simulate_chunk_extraction():
    """æ¨¡æ‹Ÿè·¨èŠ‚ç‚¹chunkæ•°æ®æå–è¿‡ç¨‹"""
    print("ğŸ” æ¨¡æ‹Ÿè·¨èŠ‚ç‚¹chunkæ•°æ®æå–ï¼ˆè€ƒè™‘ç”Ÿå­˜æœŸé™åˆ¶ï¼‰")
    print("=" * 80)
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    client_dbs = {
        1: os.path.join(base_path, "client_1", "client_1_chunks.db"),
        2: os.path.join(base_path, "client_2", "client_2_chunks.db"), 
        3: os.path.join(base_path, "client_3", "client_3_chunks.db")
    }
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    # é’ˆå¯¹æ¯ä¸ªå®¢æˆ·ç«¯ï¼Œæ¨¡æ‹Ÿæå–å…¶ä»–èŠ‚ç‚¹çš„chunkæ•°æ®
    for target_client in [1, 2, 3]:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ å®¢æˆ·ç«¯ {target_client} æå–å…¶ä»–èŠ‚ç‚¹çš„chunkæ•°æ®")
        print(f"   çº¦æŸæ¡ä»¶ï¼šåªèƒ½è®¿é—®è½®æ¬¡3-4çš„æ•°æ®ï¼ˆç”Ÿå­˜æœŸé™åˆ¶ï¼‰")
        
        target_db_path = client_dbs[target_client]
        if not os.path.exists(target_db_path):
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        conn = sqlite3.connect(target_db_path)
        cursor = conn.cursor()
        
        try:
            # è·å–è½®æ¬¡3-4ä¸­å…¶ä»–èŠ‚ç‚¹çš„éç©ºchunkè®°å½•
            other_clients = [c for c in [1, 2, 3] if c != target_client]
            
            print(f"\nğŸ“‹ ç›®æ ‡ï¼šæå–æ¥è‡ªå®¢æˆ·ç«¯ {other_clients} åœ¨è½®æ¬¡3-4çš„chunkæ•°æ®")
            
            extraction_results = {}
            
            for round_num in [3, 4]:
                print(f"\nğŸ”„ è½®æ¬¡ {round_num}:")
                round_results = {}
                
                for source_client in other_clients:
                    # æŸ¥æ‰¾è¯¥æºå®¢æˆ·ç«¯åœ¨è¯¥è½®æ¬¡çš„æ‰€æœ‰éç©ºchunk
                    cursor.execute("""
                        SELECT chunk_id, chunk_hash, is_verified
                        FROM bt_chunks 
                        WHERE round_num = ? AND source_client_id = ? AND chunk_hash != ?
                        ORDER BY chunk_id
                    """, (round_num, source_client, empty_hash))
                    
                    non_empty_chunks = cursor.fetchall()
                    print(f"   ğŸ“Š æºå®¢æˆ·ç«¯{source_client}: å‘ç°{len(non_empty_chunks)}ä¸ªéç©ºchunk")
                    
                    client_extraction = {
                        'expected': len(non_empty_chunks),
                        'extracted': 0,
                        'failed': 0,
                        'chunks': []
                    }
                    
                    for chunk_id, chunk_hash, is_verified in non_empty_chunks:
                        # å°è¯•ä»chunk_dataè¡¨ä¸­æå–å®é™…æ•°æ®
                        cursor.execute("SELECT data FROM chunk_data WHERE chunk_hash = ?", (chunk_hash,))
                        data_result = cursor.fetchone()
                        
                        chunk_info = {
                            'chunk_id': chunk_id,
                            'hash': chunk_hash[:16] + '...',
                            'verified': bool(is_verified),
                            'data_available': data_result is not None
                        }
                        
                        if data_result:
                            try:
                                # å°è¯•ååºåˆ—åŒ–æ•°æ®
                                unpickled_data = pickle.loads(data_result[0])
                                chunk_info['data_type'] = str(type(unpickled_data))
                                chunk_info['extraction_success'] = True
                                
                                if hasattr(unpickled_data, 'shape'):
                                    chunk_info['data_shape'] = unpickled_data.shape
                                elif hasattr(unpickled_data, '__len__'):
                                    chunk_info['data_size'] = len(unpickled_data)
                                
                                client_extraction['extracted'] += 1
                                print(f"      âœ… å—{chunk_id}: æ•°æ®æå–æˆåŠŸ ({chunk_info['data_type']})")
                                
                            except Exception as e:
                                chunk_info['extraction_success'] = False
                                chunk_info['error'] = str(e)
                                client_extraction['failed'] += 1
                                print(f"      âŒ å—{chunk_id}: ååºåˆ—åŒ–å¤±è´¥ - {e}")
                        else:
                            chunk_info['extraction_success'] = False
                            chunk_info['error'] = "æ•°æ®ä¸å­˜åœ¨"
                            client_extraction['failed'] += 1
                            print(f"      âŒ å—{chunk_id}: chunk_dataä¸­æ— å¯¹åº”æ•°æ®")
                        
                        client_extraction['chunks'].append(chunk_info)
                    
                    round_results[source_client] = client_extraction
                
                extraction_results[round_num] = round_results
            
            # ç»Ÿè®¡æå–æˆåŠŸç‡
            print(f"\nğŸ“ˆ å®¢æˆ·ç«¯{target_client}çš„æå–ç»Ÿè®¡:")
            total_expected = 0
            total_extracted = 0
            total_failed = 0
            
            for round_num, round_data in extraction_results.items():
                round_expected = sum(client_data['expected'] for client_data in round_data.values())
                round_extracted = sum(client_data['extracted'] for client_data in round_data.values())
                round_failed = sum(client_data['failed'] for client_data in round_data.values())
                
                success_rate = (round_extracted / round_expected * 100) if round_expected > 0 else 0
                print(f"   è½®æ¬¡{round_num}: æœŸæœ›{round_expected}, æˆåŠŸ{round_extracted}, å¤±è´¥{round_failed} (æˆåŠŸç‡: {success_rate:.1f}%)")
                
                total_expected += round_expected
                total_extracted += round_extracted
                total_failed += round_failed
            
            overall_success_rate = (total_extracted / total_expected * 100) if total_expected > 0 else 0
            print(f"   ğŸ¯ æ€»ä½“: æœŸæœ›{total_expected}, æˆåŠŸ{total_extracted}, å¤±è´¥{total_failed} (æˆåŠŸç‡: {overall_success_rate:.1f}%)")
            
            # åˆ†ææå–å¤±è´¥çš„åŸå› 
            if total_failed > 0:
                print(f"\nğŸ” æå–å¤±è´¥åŸå› åˆ†æ:")
                failure_reasons = defaultdict(int)
                
                for round_data in extraction_results.values():
                    for client_data in round_data.values():
                        for chunk in client_data['chunks']:
                            if not chunk['extraction_success']:
                                failure_reasons[chunk.get('error', 'æœªçŸ¥é”™è¯¯')] += 1
                
                for reason, count in failure_reasons.items():
                    print(f"   - {reason}: {count} æ¬¡")
        
        finally:
            conn.close()

def analyze_data_availability_pattern():
    """åˆ†ææ•°æ®å¯ç”¨æ€§æ¨¡å¼"""
    print(f"\n{'='*80}")
    print("ğŸ” åˆ†æchunkæ•°æ®å¯ç”¨æ€§æ¨¡å¼")
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    
    # æ”¶é›†æ‰€æœ‰chunk_dataè®°å½•çš„åˆ›å»ºæ—¶é—´æ¨¡å¼
    print(f"\nğŸ“Š chunk_dataåˆ›å»ºæ—¶é—´æ¨¡å¼:")
    
    for client_id in [1, 2, 3]:
        db_path = os.path.join(base_path, f"client_{client_id}", f"client_{client_id}_chunks.db")
        print(f"\n   å®¢æˆ·ç«¯{client_id}:")
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºæŸ¥çœ‹chunk_data
        cursor.execute("""
            SELECT chunk_hash, created_at, LENGTH(data)
            FROM chunk_data
            ORDER BY created_at
        """)
        
        data_records = cursor.fetchall()
        empty_hash = hashlib.sha256(b'').hexdigest()
        
        for i, (chunk_hash, created_at, data_length) in enumerate(data_records, 1):
            chunk_type = "ç©ºchunk" if chunk_hash == empty_hash else "éç©ºchunk"
            print(f"      {i}. {chunk_type}: {created_at} (å¤§å°: {data_length})")
        
        conn.close()

def simulate_chunk_request_scenario():
    """æ¨¡æ‹Ÿå…·ä½“çš„chunkè¯·æ±‚åœºæ™¯"""
    print(f"\n{'='*80}")
    print("ğŸ¯ æ¨¡æ‹Ÿå…·ä½“çš„chunkè¯·æ±‚åœºæ™¯")
    
    # åœºæ™¯ï¼šå®¢æˆ·ç«¯1éœ€è¦å®¢æˆ·ç«¯2åœ¨è½®æ¬¡4çš„æ‰€æœ‰æ¨¡å‹å‚æ•°chunk
    print(f"\nğŸ“‹ åœºæ™¯æè¿°ï¼š")
    print(f"   - è¯·æ±‚æ–¹ï¼šå®¢æˆ·ç«¯1")
    print(f"   - ç›®æ ‡ï¼šè·å–å®¢æˆ·ç«¯2åœ¨è½®æ¬¡4çš„æ‰€æœ‰éç©ºchunkæ•°æ®")
    print(f"   - çº¦æŸï¼šåªèƒ½ä»å®¢æˆ·ç«¯1çš„æ•°æ®åº“ä¸­æŸ¥æ‰¾")
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    client_1_db = os.path.join(base_path, "client_1", "client_1_chunks.db")
    
    conn = sqlite3.connect(client_1_db)
    cursor = conn.cursor()
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    try:
        # æŸ¥æ‰¾å®¢æˆ·ç«¯2åœ¨è½®æ¬¡4çš„æ‰€æœ‰chunkè®°å½•
        cursor.execute("""
            SELECT chunk_id, chunk_hash, is_verified
            FROM bt_chunks 
            WHERE round_num = 4 AND source_client_id = 2
            ORDER BY chunk_id
        """, )
        
        all_chunks = cursor.fetchall()
        non_empty_chunks = [(cid, hash, verified) for cid, hash, verified in all_chunks if hash != empty_hash]
        
        print(f"\nğŸ“Š æŸ¥è¯¢ç»“æœ:")
        print(f"   - å®¢æˆ·ç«¯2è½®æ¬¡4æ€»chunkæ•°: {len(all_chunks)}")
        print(f"   - éç©ºchunkæ•°: {len(non_empty_chunks)}")
        print(f"   - ç©ºchunkæ•°: {len(all_chunks) - len(non_empty_chunks)}")
        
        print(f"\nğŸ” éç©ºchunkæå–è¯¦æƒ…:")
        extraction_success = 0
        
        for chunk_id, chunk_hash, is_verified in non_empty_chunks:
            print(f"   Chunk {chunk_id} (å“ˆå¸Œ: {chunk_hash[:16]}...):")
            print(f"     éªŒè¯çŠ¶æ€: {'âœ…å·²éªŒè¯' if is_verified else 'âŒæœªéªŒè¯'}")
            
            # å°è¯•è·å–æ•°æ®
            cursor.execute("SELECT data, created_at FROM chunk_data WHERE chunk_hash = ?", (chunk_hash,))
            data_result = cursor.fetchone()
            
            if data_result:
                data_blob, created_at = data_result
                print(f"     æ•°æ®çŠ¶æ€: âœ…å¯ç”¨ (åˆ›å»ºæ—¶é—´: {created_at})")
                print(f"     æ•°æ®å¤§å°: {len(data_blob)} bytes")
                
                try:
                    unpickled_data = pickle.loads(data_blob)
                    print(f"     æ•°æ®ç±»å‹: {type(unpickled_data)}")
                    if hasattr(unpickled_data, 'shape'):
                        print(f"     æ•°æ®å½¢çŠ¶: {unpickled_data.shape}")
                    extraction_success += 1
                    print(f"     æå–ç»“æœ: âœ…æˆåŠŸ")
                except Exception as e:
                    print(f"     æå–ç»“æœ: âŒå¤±è´¥ ({e})")
            else:
                print(f"     æ•°æ®çŠ¶æ€: âŒä¸å¯ç”¨")
                print(f"     æå–ç»“æœ: âŒå¤±è´¥ (æ•°æ®ä¸å­˜åœ¨)")
        
        success_rate = (extraction_success / len(non_empty_chunks) * 100) if non_empty_chunks else 0
        print(f"\nğŸ¯ åœºæ™¯æå–ç»“æœ:")
        print(f"   æˆåŠŸæå–: {extraction_success}/{len(non_empty_chunks)} ({success_rate:.1f}%)")
        
        if success_rate == 100.0:
            print(f"   âœ… å®Œå…¨æˆåŠŸï¼å®¢æˆ·ç«¯1å¯ä»¥å®Œæ•´è·å–å®¢æˆ·ç«¯2è½®æ¬¡4çš„æ‰€æœ‰æ¨¡å‹å‚æ•°")
        elif success_rate > 0:
            print(f"   âš ï¸ éƒ¨åˆ†æˆåŠŸï¼Œå­˜åœ¨ä¸€äº›æ•°æ®ç¼ºå¤±")
        else:
            print(f"   âŒ å®Œå…¨å¤±è´¥ï¼Œæ— æ³•è·å–ä»»ä½•æ•°æ®")
    
    finally:
        conn.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” éªŒè¯è·¨èŠ‚ç‚¹chunkæ•°æ®æå–èƒ½åŠ›")
    print("è€ƒè™‘æ•°æ®ç”Ÿå­˜æœŸé™åˆ¶ï¼ˆè½®æ¬¡3-4å¯ç”¨ï¼‰")
    
    # æ¨¡æ‹Ÿè·¨èŠ‚ç‚¹æå–
    simulate_chunk_extraction()
    
    # åˆ†ææ•°æ®å¯ç”¨æ€§æ¨¡å¼
    analyze_data_availability_pattern()
    
    # æ¨¡æ‹Ÿå…·ä½“åœºæ™¯
    simulate_chunk_request_scenario()
    
    print(f"\n{'='*80}")
    print("ğŸ¯ éªŒè¯ç»“è®º:")
    print("1. è·¨èŠ‚ç‚¹chunkæ•°æ®æå–çš„å¯è¡Œæ€§")
    print("2. æ•°æ®ç”Ÿå­˜æœŸé™åˆ¶å¯¹æå–æˆåŠŸç‡çš„å½±å“")
    print("3. BitTorrent chunk exchangeç³»ç»Ÿçš„å®é™…æ•ˆæœ")
    print("4. åœ¨ä¿ç•™æœŸå†…ï¼Œå…¶ä»–èŠ‚ç‚¹çš„chunkæ•°æ®æ˜¯å¦å¯å®Œæ•´æå–")

if __name__ == "__main__":
    main()