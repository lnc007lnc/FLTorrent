#!/usr/bin/env python3
"""
éªŒè¯æœ¬åœ°tmpæ•°æ®åº“ä¸­chunkæ•°æ®çš„å®Œæ•´æ€§å’Œå¯è¯»æ€§ (æ›´æ–°ç‰ˆæœ¬)
åŸºäºå®é™…çš„æ•°æ®åº“ç»“æ„ï¼šchunk_metadata, chunk_data, bt_chunks, bt_exchange_status, bt_sessions
"""

import sqlite3
import os
import json
from collections import defaultdict, Counter
from datetime import datetime

def connect_to_database(db_path):
    """è¿æ¥åˆ°SQLiteæ•°æ®åº“"""
    try:
        conn = sqlite3.connect(db_path)
        return conn
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æ•°æ®åº“ {db_path}: {e}")
        return None

def analyze_chunk_metadata(conn, client_id):
    """åˆ†æchunk_metadataè¡¨"""
    try:
        cursor = conn.cursor()
        
        # è·å–chunkå…ƒæ•°æ®
        cursor.execute("""
            SELECT round_num, chunk_id, chunk_hash, parts_info, flat_size, created_at
            FROM chunk_metadata 
            ORDER BY round_num, chunk_id
        """)
        
        records = cursor.fetchall()
        print(f"\nğŸ“Š å®¢æˆ·ç«¯ {client_id} chunk_metadata åˆ†æ:")
        print(f"   æ€»è®°å½•æ•°: {len(records)}")
        
        if not records:
            print("   âš ï¸ chunk_metadataè¡¨ä¸ºç©º")
            return {}
        
        # æŒ‰è½®æ¬¡ç»Ÿè®¡
        round_stats = defaultdict(lambda: {'chunks': [], 'total_size': 0})
        
        for record in records:
            round_num, chunk_id, chunk_hash, parts_info, flat_size, created_at = record
            
            round_stats[round_num]['chunks'].append({
                'chunk_id': chunk_id,
                'chunk_hash': chunk_hash,
                'flat_size': flat_size,
                'created_at': created_at
            })
            round_stats[round_num]['total_size'] += flat_size if flat_size else 0
        
        for round_num in sorted(round_stats.keys()):
            stats = round_stats[round_num]
            print(f"   è½®æ¬¡ {round_num}: {len(stats['chunks'])} chunks, æ€»å¤§å°: {stats['total_size']} bytes")
        
        return round_stats
        
    except Exception as e:
        print(f"âŒ åˆ†æchunk_metadataå¤±è´¥: {e}")
        return {}

def analyze_chunk_data(conn, client_id):
    """åˆ†æchunk_dataè¡¨"""
    try:
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT chunk_hash, LENGTH(data) as data_length, created_at
            FROM chunk_data 
            ORDER BY created_at
        """)
        
        records = cursor.fetchall()
        print(f"\nğŸ’¾ å®¢æˆ·ç«¯ {client_id} chunk_data åˆ†æ:")
        print(f"   å­˜å‚¨çš„chunkæ•°æ®æ¡æ•°: {len(records)}")
        
        if records:
            total_size = sum(record[1] for record in records)
            print(f"   æ€»å­˜å‚¨æ•°æ®å¤§å°: {total_size} bytes")
            print(f"   å¹³å‡chunkå¤§å°: {total_size/len(records):.2f} bytes")
        
        return records
        
    except Exception as e:
        print(f"âŒ åˆ†æchunk_dataå¤±è´¥: {e}")
        return []

def analyze_bt_chunks(conn, client_id):
    """åˆ†æbt_chunksè¡¨ - è¿™æ˜¯å…³é”®çš„BitTorrentäº¤æ¢è®°å½•"""
    try:
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT round_num, source_client_id, chunk_id, chunk_hash, 
                   holder_client_id, received_time, is_verified
            FROM bt_chunks 
            ORDER BY round_num, source_client_id, chunk_id
        """)
        
        records = cursor.fetchall()
        print(f"\nğŸ”„ å®¢æˆ·ç«¯ {client_id} bt_chunks åˆ†æ (BitTorrentäº¤æ¢è®°å½•):")
        print(f"   äº¤æ¢è®°å½•æ€»æ•°: {len(records)}")
        
        if not records:
            print("   âš ï¸ æ²¡æœ‰BitTorrentäº¤æ¢è®°å½•")
            return {}
        
        # æŒ‰è½®æ¬¡å’Œæºå®¢æˆ·ç«¯ç»Ÿè®¡
        round_data = defaultdict(lambda: defaultdict(list))
        source_distribution = defaultdict(Counter)
        
        for record in records:
            round_num, source_client_id, chunk_id, chunk_hash, holder_client_id, received_time, is_verified = record
            
            round_data[round_num][source_client_id].append({
                'chunk_id': chunk_id,
                'chunk_hash': chunk_hash,
                'holder_client_id': holder_client_id,
                'received_time': received_time,
                'is_verified': is_verified
            })
            
            source_distribution[round_num][source_client_id] += 1
        
        print(f"   æ¶‰åŠè½®æ¬¡: {sorted(round_data.keys())}")
        
        for round_num in sorted(round_data.keys()):
            round_chunks = round_data[round_num]
            total_chunks = sum(len(chunks) for chunks in round_chunks.values())
            source_clients = sorted(round_chunks.keys())
            
            print(f"\n   è½®æ¬¡ {round_num}:")
            print(f"     - äº¤æ¢çš„chunkæ€»æ•°: {total_chunks}")
            print(f"     - æ¥æºå®¢æˆ·ç«¯: {source_clients}")
            print(f"     - å„æºåˆ†å¸ƒ: {dict(source_distribution[round_num])}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªå…¶ä»–å®¢æˆ·ç«¯çš„æ•°æ®
            other_sources = [src for src in source_clients if src != client_id]
            if other_sources:
                print(f"     âœ… æˆåŠŸæ¥æ”¶æ¥è‡ªå…¶ä»–å®¢æˆ·ç«¯çš„æ•°æ®: {other_sources}")
            else:
                print(f"     âš ï¸ åªæœ‰æœ¬å®¢æˆ·ç«¯({client_id})è‡ªå·±çš„æ•°æ®ï¼Œå¯èƒ½æ²¡æœ‰è¿›è¡ŒBitTorrentäº¤æ¢")
        
        return round_data
        
    except Exception as e:
        print(f"âŒ åˆ†æbt_chunkså¤±è´¥: {e}")
        return {}

def analyze_bt_exchange_status(conn, client_id):
    """åˆ†æbt_exchange_statusè¡¨"""
    try:
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT round_num, peer_id, chunk_key, status, 
                   request_time, complete_time, retry_count, size
            FROM bt_exchange_status 
            ORDER BY round_num, peer_id, request_time
        """)
        
        records = cursor.fetchall()
        print(f"\nğŸ“Š å®¢æˆ·ç«¯ {client_id} bt_exchange_status åˆ†æ:")
        print(f"   äº¤æ¢çŠ¶æ€è®°å½•æ•°: {len(records)}")
        
        if records:
            status_counts = Counter()
            for record in records:
                status_counts[record[3]] += 1
            
            print(f"   çŠ¶æ€åˆ†å¸ƒ: {dict(status_counts)}")
        
        return records
        
    except Exception as e:
        print(f"âŒ åˆ†æbt_exchange_statuså¤±è´¥: {e}")
        return []

def analyze_bt_sessions(conn, client_id):
    """åˆ†æbt_sessionsè¡¨"""
    try:
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT round_num, start_time, end_time, status, 
                   total_chunks_expected, total_chunks_received, 
                   bytes_uploaded, bytes_downloaded
            FROM bt_sessions 
            ORDER BY round_num
        """)
        
        records = cursor.fetchall()
        print(f"\nğŸ¯ å®¢æˆ·ç«¯ {client_id} bt_sessions åˆ†æ:")
        print(f"   BitTorrentä¼šè¯æ•°: {len(records)}")
        
        for record in records:
            round_num, start_time, end_time, status, expected, received, uploaded, downloaded = record
            print(f"   è½®æ¬¡ {round_num}: çŠ¶æ€={status}, æœŸæœ›={expected}, æ¥æ”¶={received}, ä¸Šä¼ ={uploaded}B, ä¸‹è½½={downloaded}B")
        
        return records
        
    except Exception as e:
        print(f"âŒ åˆ†æbt_sessionså¤±è´¥: {e}")
        return []

def cross_client_bt_analysis(all_bt_data):
    """è·¨å®¢æˆ·ç«¯BitTorrentæ•°æ®åˆ†æ"""
    print(f"\nğŸŒ è·¨å®¢æˆ·ç«¯BitTorrentæ•°æ®åˆ†æ:")
    
    # æ”¶é›†æ‰€æœ‰è½®æ¬¡
    all_rounds = set()
    for client_data in all_bt_data.values():
        all_rounds.update(client_data.keys())
    
    if not all_rounds:
        print("   âš ï¸ æ²¡æœ‰å‘ç°ä»»ä½•BitTorrentäº¤æ¢æ•°æ®")
        return
    
    print(f"   å‘ç°çš„è½®æ¬¡: {sorted(all_rounds)}")
    
    for round_num in sorted(all_rounds):
        print(f"\n   è½®æ¬¡ {round_num} è·¨å®¢æˆ·ç«¯æ•°æ®éªŒè¯:")
        
        # æ£€æŸ¥æ¯ä¸ªå®¢æˆ·ç«¯åœ¨è¿™è½®æ˜¯å¦éƒ½æœ‰æ¥è‡ªå…¶ä»–å®¢æˆ·ç«¯çš„æ•°æ®
        expected_clients = set(all_bt_data.keys())
        
        for client_id, client_data in all_bt_data.items():
            if round_num in client_data:
                round_sources = set(client_data[round_num].keys())
                other_sources = round_sources - {client_id}
                missing_sources = expected_clients - round_sources
                
                print(f"     å®¢æˆ·ç«¯ {client_id}:")
                print(f"       - æ‹¥æœ‰æ¥æº: {sorted(round_sources)}")
                if other_sources:
                    print(f"       âœ… æˆåŠŸä»å…¶ä»–å®¢æˆ·ç«¯è·å–æ•°æ®: {sorted(other_sources)}")
                else:
                    print(f"       âš ï¸ æ²¡æœ‰æ¥è‡ªå…¶ä»–å®¢æˆ·ç«¯çš„æ•°æ®")
                    
                if missing_sources:
                    print(f"       âš ï¸ ç¼ºå°‘æ¥è‡ªå®¢æˆ·ç«¯çš„æ•°æ®: {sorted(missing_sources)}")
            else:
                print(f"     å®¢æˆ·ç«¯ {client_id}: âŒ è¯¥è½®æ¬¡æ— æ•°æ®")

def verify_data_consistency(conn, client_id):
    """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
    try:
        cursor = conn.cursor()
        print(f"\nğŸ”§ å®¢æˆ·ç«¯ {client_id} æ•°æ®ä¸€è‡´æ€§éªŒè¯:")
        
        # 1. æ£€æŸ¥chunk_metadataå’Œchunk_dataçš„ä¸€è‡´æ€§
        cursor.execute("""
            SELECT COUNT(*) FROM chunk_metadata cm
            LEFT JOIN chunk_data cd ON cm.chunk_hash = cd.chunk_hash
            WHERE cd.chunk_hash IS NULL
        """)
        missing_data = cursor.fetchone()[0]
        print(f"   metadataä¸­æœ‰ä½†dataä¸­ç¼ºå¤±çš„chunks: {missing_data}")
        
        # 2. æ£€æŸ¥bt_chunkså’Œchunk_metadataçš„ä¸€è‡´æ€§
        cursor.execute("""
            SELECT COUNT(*) FROM bt_chunks bc
            LEFT JOIN chunk_metadata cm ON bc.chunk_hash = cm.chunk_hash
            WHERE cm.chunk_hash IS NULL
        """)
        inconsistent_bt = cursor.fetchone()[0]
        print(f"   bt_chunksä¸­æœ‰ä½†metadataä¸­ç¼ºå¤±çš„chunks: {inconsistent_bt}")
        
        # 3. æ£€æŸ¥verificationçŠ¶æ€
        cursor.execute("SELECT COUNT(*), SUM(is_verified) FROM bt_chunks")
        total_bt, verified_bt = cursor.fetchone()
        if total_bt > 0:
            print(f"   BitTorrent chunkséªŒè¯çŠ¶æ€: {verified_bt}/{total_bt} ({verified_bt/total_bt*100:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹éªŒè¯chunkæ•°æ®åº“å®Œæ•´æ€§å’Œå¯è¯»æ€§ (æ›´æ–°ç‰ˆæœ¬)")
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    client_dbs = {
        1: os.path.join(base_path, "client_1", "client_1_chunks.db"),
        2: os.path.join(base_path, "client_2", "client_2_chunks.db"), 
        3: os.path.join(base_path, "client_3", "client_3_chunks.db")
    }
    
    all_bt_data = {}
    
    # åˆ†ææ¯ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®åº“
    for client_id, db_path in client_dbs.items():
        print(f"\n{'='*60}")
        print(f"ğŸ” åˆ†æå®¢æˆ·ç«¯ {client_id} æ•°æ®åº“: {db_path}")
        
        if not os.path.exists(db_path):
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            continue
        
        conn = connect_to_database(db_path)
        if not conn:
            continue
        
        try:
            # åˆ†æå„ä¸ªè¡¨
            analyze_chunk_metadata(conn, client_id)
            analyze_chunk_data(conn, client_id)
            bt_data = analyze_bt_chunks(conn, client_id)  # è¿™æ˜¯æœ€å…³é”®çš„è¡¨
            all_bt_data[client_id] = bt_data
            analyze_bt_exchange_status(conn, client_id)
            analyze_bt_sessions(conn, client_id)
            
            # éªŒè¯æ•°æ®ä¸€è‡´æ€§
            verify_data_consistency(conn, client_id)
            
        finally:
            conn.close()
    
    # è·¨å®¢æˆ·ç«¯BitTorrentåˆ†æ
    if all_bt_data:
        cross_client_bt_analysis(all_bt_data)
    
    print(f"\n{'='*60}")
    print("âœ… æ›´æ–°ç‰ˆchunkæ•°æ®åº“éªŒè¯å®Œæˆ!")

if __name__ == "__main__":
    main()