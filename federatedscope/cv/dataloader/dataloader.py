import logging
from federatedscope.cv.dataset.leaf_cv import LEAF_CV, load_leaf_cv_lazy, LazyLoadDataset
from federatedscope.core.auxiliaries.transform_builder import get_transform
from federatedscope.core.data.utils import (get_num_users_to_load,
                                            should_load_all_leaf_users)

logger = logging.getLogger(__name__)


def load_cv_dataset(config=None):
    """
    Return the dataset of ``femnist`` or ``celeba``.

    Args:
        config: configurations for FL, see ``federatedscope.core.configs``

    Returns:
        FL dataset dict, with ``client_id`` as key.

    Note:
      ``load_cv_dataset()`` will return a dict as shown below:
        ```
        {'client_id': {'train': dataset, 'test': dataset, 'val': dataset}}
        ```
    """
    splits = config.data.splits

    path = config.data.root
    name = config.data.type.lower()
    transforms_funcs, val_transforms_funcs, test_transforms_funcs = \
        get_transform(config, 'torchvision')

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å»¶è¿ŸåŠ è½½æ¨¡å¼ (merge_leaf_before_split=True æ—¶è‡ªåŠ¨å¯ç”¨)
    use_lazy_load = should_load_all_leaf_users(config)

    if name in ['femnist', 'celeba']:
        if use_lazy_load:
            # å»¶è¿ŸåŠ è½½æ¨¡å¼ï¼šåªåŠ è½½æ ‡ç­¾ï¼Œä¸åŠ è½½å›¾åƒæ•°æ®
            # å†…å­˜ä½¿ç”¨ï¼š~1MB vs ~9GB
            logger.info("ğŸš€ Using lazy-load mode for LEAF dataset (memory efficient)")
            lazy_data = load_leaf_cv_lazy(
                root=path,
                name=name,
                transform=transforms_funcs.get('transform'),
                target_transform=transforms_funcs.get('target_transform')
            )
            # è¿”å›åˆå¹¶åçš„æ•°æ®é›†ï¼Œç”¨äº MergedLeafTranslator
            # è¿™é‡Œè¿”å›ä¸€ä¸ªç‰¹æ®Šæ ¼å¼ï¼Œè¡¨ç¤ºå·²ç»æ˜¯åˆå¹¶åçš„å»¶è¿ŸåŠ è½½æ•°æ®
            return {'__lazy_merged__': lazy_data}, config
        else:
            # åŸå§‹æ¨¡å¼ï¼šåŠ è½½å…¨éƒ¨æ•°æ®
            dataset = LEAF_CV(root=path,
                              name=name,
                              s_frac=config.data.subsample,
                              tr_frac=splits[0],
                              val_frac=splits[1],
                              seed=1234,
                              **transforms_funcs)
    else:
        raise ValueError(f'No dataset named: {name}!')

    # åŸå§‹æ¨¡å¼çš„å¤„ç†é€»è¾‘
    # Determine how many users to load (use utility function)
    num_users_to_load = get_num_users_to_load(dataset, config)

    # Update client_num for original mode only
    if not should_load_all_leaf_users(config):
        config.merge_from_list(['federate.client_num', num_users_to_load])

    # Convert list to dict
    data_dict = dict()
    for user_idx in range(1, num_users_to_load + 1):
        data_dict[user_idx] = dataset[user_idx - 1]

    return data_dict, config
