"""
ğŸš€ gRPC Streaming Channel Manager for BitTorrent
åœ¨æ‹“æ‰‘æ„å»ºæ—¶åˆ›å»ºä¸“ç”¨streamingé€šé“ï¼Œæä¾›é«˜æ•ˆçš„chunkä¼ è¾“
"""

import grpc
import threading
import time
import logging
from typing import Dict, Optional, List, Tuple
from collections import defaultdict
import queue

from federatedscope.core.proto import gRPC_comm_manager_pb2_grpc
from federatedscope.core.proto import gRPC_comm_manager_pb2

logger = logging.getLogger(__name__)


class StreamingChannel:
    """å•ä¸ªstreamingé€šé“å°è£…"""
    
    def __init__(self, peer_id: int, channel: grpc.Channel, stub, stream_type='bidirectional', client_id: int = -1, client_instance=None):
        self.peer_id = peer_id
        self.channel = channel
        self.stub = stub
        self.stream_type = stream_type
        self.client_id = client_id  # æ·»åŠ client_idæ”¯æŒ
        self.client_instance = client_instance  # æ·»åŠ å®¢æˆ·ç«¯å®ä¾‹å¼•ç”¨ï¼Œç”¨äºè°ƒç”¨å›è°ƒå‡½æ•°
        
        # Streamingå¯¹è±¡
        self.request_stream = None
        self.response_stream = None
        self.request_queue = queue.Queue()
        
        # çŠ¶æ€ç®¡ç†
        self.is_active = False
        self.last_activity = time.time()
        self.bytes_sent = 0
        self.bytes_received = 0
        self.chunks_sent = 0
        self.chunks_received = 0
        
        # çº¿ç¨‹ç®¡ç†
        self.sender_thread = None
        self.receiver_thread = None
        self.upload_sender_thread = None
        
    def start_streaming(self):
        """å¯åŠ¨streamingï¼ˆè‡ªåŠ¨å›é€€å…¼å®¹ï¼‰"""
        if self.is_active:
            return
            
        try:
            # ğŸš€ å°è¯•å¯åŠ¨å¤šæµstreaming
            self._start_multi_streaming()
            
        except Exception as e:
            # ğŸ”§ Streamingå¤±è´¥ï¼Œæ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä½†ä¸æŠ›å‡ºé”™è¯¯
            logger.warning(f"[StreamChannel] Multi-streaming not supported for peer {self.peer_id}, will use traditional messaging: {e}")
            self.is_active = False  # æ ‡è®°streamingä¸å¯ç”¨
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚ä»£ç ç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
            
    def _start_multi_streaming(self):
        """å†…éƒ¨æ–¹æ³•ï¼šå¯åŠ¨å¤šæµå¹¶å‘streaming"""
        # ğŸš€ å¤šæµå¹¶å‘ä¼˜åŒ–ï¼šåˆ›å»ºä¸“ç”¨æµ
        
        # ğŸ”§ CRITICAL FIX: å…ˆè®¾ç½®is_active=Trueï¼Œå†åˆ›å»ºgenerators
        self.is_active = True
        logger.info(f"[StreamChannel] Activating streaming channels to peer {self.peer_id}")
        
        # 1. åŒå‘é€šç”¨streaming (ç”¨äºæ§åˆ¶æ¶ˆæ¯)
        self.control_stream = self.stub.streamChunks(self._control_request_generator())
        
        # 2. ä¸“ç”¨ä¸Šä¼ æµ (chunkå‘é€) - å®¢æˆ·ç«¯æµï¼Œè¿”å›å•ä¸ªå“åº”
        self.upload_request_queue = queue.Queue()
        # ä¸åœ¨ä¸»çº¿ç¨‹åˆ›å»ºupload_streamï¼Œæ”¹ä¸ºåœ¨ä¸“ç”¨çº¿ç¨‹ä¸­åˆ›å»º
        
        # 3. ä¸“ç”¨ä¸‹è½½æµ (chunkè¯·æ±‚)
        self.download_request_queue = queue.Queue()
        
        # å¯åŠ¨æ¥æ”¶çº¿ç¨‹ (æ³¨æ„ï¼šuploadChunksè¿”å›å•ä¸ªå“åº”ï¼Œä¸éœ€è¦å“åº”å¤„ç†çº¿ç¨‹)
        self.control_receiver_thread = threading.Thread(
            target=self._control_response_handler,
            daemon=True,
            name=f"ControlReceiver-{self.peer_id}"
        )
        
        self.download_sender_thread = threading.Thread(
            target=self._download_request_sender,
            daemon=True,
            name=f"DownloadSender-{self.peer_id}"
        )
        
        self.upload_sender_thread = threading.Thread(
            target=self._run_upload_stream,
            daemon=True,
            name=f"UploadSender-{self.peer_id}"
        )
        
        # å¯åŠ¨çº¿ç¨‹
        self.control_receiver_thread.start()
        self.download_sender_thread.start()
        self.upload_sender_thread.start()
        
        logger.info(f"[StreamChannel] Started multi-stream channels to peer {self.peer_id}")
            
    def _control_request_generator(self):
        """æ§åˆ¶æ¶ˆæ¯æµç”Ÿæˆå™¨"""
        while self.is_active:
            try:
                request = self.request_queue.get(timeout=1.0)
                if request is None:  # Sentinel for shutdown
                    break
                # åªå¤„ç†æ§åˆ¶æ¶ˆæ¯ (HAVE, BITFIELD, INTERESTEDç­‰)
                if request.chunk_type in [gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE, 
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD]:
                    yield request
                    self.request_queue.task_done()
                else:
                    # éæ§åˆ¶æ¶ˆæ¯æ”¾å›é˜Ÿåˆ—æˆ–è½¬å‘åˆ°ä¸“ç”¨æµ
                    self.request_queue.put(request)
                    break
            except queue.Empty:
                continue
                
    def _upload_request_generator(self):
        """ğŸš€ ä¸“ç”¨ä¸Šä¼ æµï¼šåªå¤„ç†chunkæ•°æ®ä¼ è¾“ - ä¿®å¤Generatorè¿‡æ—©ç»ˆæ­¢é—®é¢˜"""
        logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Upload stream generator started for peer {self.peer_id}")
        
        # ğŸ”§ FIX: æ·»åŠ ç­‰å¾…æœºåˆ¶å‚æ•°
        empty_queue_wait = 0.01  # 10msç­‰å¾…æ—¶é—´
        max_idle_time = 1.0     # æœ€å¤§ç©ºé—²æ—¶é—´1ç§’
        last_activity = time.time()
        
        while self.is_active:
            try:
                # ğŸ”§ CRITICAL FIX: ä½¿ç”¨å¸¦è¶…æ—¶çš„getæ›¿ä»£get_nowaitï¼Œå¹¶ç»§ç»­å¾ªç¯è€Œä¸æ˜¯return
                try:
                    request = self.upload_request_queue.get(timeout=empty_queue_wait)
                    last_activity = time.time()  # æ›´æ–°æ´»åŠ¨æ—¶é—´
                    
                except queue.Empty:
                    # ğŸš€ FIX: é˜Ÿåˆ—ä¸ºç©ºæ—¶ç»§ç»­ç­‰å¾…ï¼Œè€Œä¸æ˜¯ç»ˆæ­¢generator
                    current_time = time.time()
                    idle_time = current_time - last_activity
                    
                    # å®šæœŸè¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼Œä½†ä¸è¦å¤ªé¢‘ç¹
                    if idle_time > max_idle_time and int(current_time) % 5 == 0:  # æ¯5ç§’è¾“å‡ºä¸€æ¬¡
                        logger.debug(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Waiting for data, idle for {idle_time:.1f}s")
                        last_activity = current_time  # é‡ç½®è®¡æ—¶å™¨é¿å…é‡å¤æ—¥å¿—
                    
                    continue  # ğŸš€ å…³é”®ä¿®å¤ï¼šç»§ç»­å¾ªç¯è€Œä¸æ˜¯returnç»ˆæ­¢generator
                    
                if request is None:  # Sentinel for shutdown
                    logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Received shutdown sentinel for peer {self.peer_id}")
                    break
                
                # ğŸš€ å¤„ç†æ­£å¸¸çš„chunkè¯·æ±‚
                logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Yielding chunk request for peer {self.peer_id}")
                logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Request details - round={request.round_num}, source={request.source_client_id}, chunk={request.chunk_id}, size={len(request.chunk_data)}")
                
                yield request
                self.upload_request_queue.task_done()
                
                logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Successfully yielded chunk request for peer {self.peer_id}")
                
            except Exception as e:
                logger.error(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Unexpected error: {e}")
                if not self.is_active:
                    break
                # ğŸ”§ FIX: é‡åˆ°å¼‚å¸¸æ—¶çŸ­æš‚ç­‰å¾…åç»§ç»­ï¼Œé¿å…ç´§å¯†å¾ªç¯
                time.sleep(0.1)
                
        logger.info(f"[ğŸš€ UploadGenerator] Client {self.client_id}: Upload stream generator ended for peer {self.peer_id}")
    
    def _run_upload_stream(self):
        """ğŸ”§ FIX: åœ¨ä¸“ç”¨çº¿ç¨‹ä¸­è¿è¡Œä¸Šä¼ æµï¼Œå¹¶æ­£ç¡®æ¶ˆè´¹å“åº”"""
        try:
            logger.info(f"[ğŸš€ UploadStream] Client {self.client_id}: Starting upload stream to peer {self.peer_id}")
            
            # åˆ›å»ºä¸Šä¼ æµå¹¶æ¶ˆè´¹æœ€ç»ˆå“åº”
            upload_response = self.stub.uploadChunks(self._upload_request_generator())
            
            # ğŸ”§ CRITICAL FIX: å¿…é¡»æ¶ˆè´¹å“åº”æ‰èƒ½å®ŒæˆgRPCå®¢æˆ·ç«¯æµ
            logger.info(f"[ğŸš€ UploadStream] Client {self.client_id}: Upload stream response: {upload_response}")
            logger.info(f"[ğŸš€ UploadStream] Client {self.client_id}: Upload stream completed for peer {self.peer_id}")
            
        except Exception as e:
            logger.error(f"[ğŸš€ UploadStream] Client {self.client_id}: Upload stream error for peer {self.peer_id}: {e}")
            self.is_active = False
                
    def _control_response_handler(self):
        """æ§åˆ¶æ¶ˆæ¯å“åº”å¤„ç†å™¨"""
        try:
            for response in self.control_stream:
                if not self.is_active:
                    break
                self._handle_control_response(response)
                self.last_activity = time.time()
        except Exception as e:
            logger.error(f"[StreamChannel] Control response handler error for peer {self.peer_id}: {e}")
            
    def _download_request_sender(self):
        """ğŸš€ ä¸‹è½½è¯·æ±‚å‘é€å™¨ï¼šæ‰¹é‡å¤„ç†chunkè¯·æ±‚"""
        batch_requests = []
        batch_timeout = 0.1  # 100msæ‰¹å¤„ç†è¶…æ—¶
        
        while self.is_active:
            try:
                # æ”¶é›†æ‰¹é‡è¯·æ±‚
                end_time = time.time() + batch_timeout
                while time.time() < end_time and len(batch_requests) < 10:  # æœ€å¤š10ä¸ªä¸€æ‰¹
                    try:
                        request = self.download_request_queue.get(timeout=0.01)
                        if request is None:  # Shutdown signal
                            break
                        batch_requests.append(request)
                    except queue.Empty:
                        break
                
                # å‘é€æ‰¹é‡è¯·æ±‚
                if batch_requests:
                    batch_request = gRPC_comm_manager_pb2.ChunkBatchRequest(
                        client_id=self.peer_id,
                        round_num=batch_requests[0].round_num,
                        chunk_requests=[
                            gRPC_comm_manager_pb2.ChunkRequest(
                                source_client_id=req.source_client_id,
                                chunk_id=req.chunk_id,
                                importance_score=req.importance_score
                            ) for req in batch_requests
                        ]
                    )
                    
                    # å‘é€æ‰¹é‡ä¸‹è½½è¯·æ±‚
                    download_stream = self.stub.downloadChunks(batch_request)
                    for chunk_response in download_stream:
                        self._handle_download_response(chunk_response)
                    
                    logger.info(f"[StreamChannel] Sent batch download request with {len(batch_requests)} chunks to peer {self.peer_id}")
                    batch_requests.clear()
                    
            except Exception as e:
                logger.error(f"[StreamChannel] Download request sender error for peer {self.peer_id}: {e}")
                batch_requests.clear()
            
    def _handle_control_response(self, response):
        """å¤„ç†æ§åˆ¶æ¶ˆæ¯å“åº” (HAVE, BITFIELDç­‰)"""
        logger.info(f"[StreamChannel] Received control response from peer {self.peer_id}: {response.response_type}")
        # TODO: é›†æˆåˆ°BitTorrentManagerçš„bitfieldæ›´æ–°
        
    def _handle_download_response(self, response):
        """ğŸš€ å¤„ç†chunkä¸‹è½½å“åº”"""
        self.chunks_received += 1
        self.bytes_received += len(response.response_data) if response.response_data else 0
        logger.info(f"[StreamChannel] Received chunk download from peer {self.peer_id}, chunk_id: {response.chunk_id}")
        # TODO: é›†æˆåˆ°BitTorrentManagerçš„chunkå¤„ç†
        
    def _handle_chunk_response(self, response):
        """å…¼å®¹æ€§æ–¹æ³•ï¼šå¤„ç†æ”¶åˆ°çš„chunkå“åº”"""
        self.chunks_received += 1
        self.bytes_received += len(response.response_data) if response.response_data else 0
        logger.info(f"[StreamChannel] Received chunk response from peer {self.peer_id}")
        
    def send_chunk_request(self, round_num: int, source_client_id: int, chunk_id: int, 
                          importance_score: float = 0.0):
        """ğŸš€ å‘é€chunkè¯·æ±‚ - ä½¿ç”¨æ‰¹é‡ä¸‹è½½é˜Ÿåˆ—"""
        if not self.is_active:
            logger.warning(f"[StreamChannel] Cannot send to inactive channel for peer {self.peer_id}")
            return False
            
        request = gRPC_comm_manager_pb2.ChunkStreamRequest(
            sender_id=self.client_id,  # ğŸ”§ FIX: æ­£ç¡®çš„å‘é€æ–¹ID
            receiver_id=self.peer_id,  # ğŸ”§ FIX: æ­£ç¡®çš„æ¥æ”¶æ–¹ID
            round_num=round_num,
            source_client_id=source_client_id,
            chunk_id=chunk_id,
            chunk_type=gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
            importance_score=importance_score,
            timestamp=int(time.time() * 1000)
        )
        
        try:
            # ğŸš€ ä½¿ç”¨ä¸“ç”¨ä¸‹è½½è¯·æ±‚é˜Ÿåˆ—ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†
            self.download_request_queue.put(request, timeout=1.0)
            logger.info(f"[StreamChannel] Queued chunk request {source_client_id}:{chunk_id} to peer {self.peer_id} for batch download")
            return True
        except queue.Full:
            logger.error(f"[StreamChannel] Download request queue full for peer {self.peer_id}")
            return False
            
    def send_chunk_data(self, round_num: int, source_client_id: int, chunk_id: int,
                       chunk_data: bytes, checksum: str, importance_score: float = 0.0):
        """ğŸš€ å‘é€chunkæ•°æ® - ä½¿ç”¨ä¸“ç”¨ä¸Šä¼ æµ"""
        if not self.is_active:
            logger.warning(f"[StreamChannel] Cannot send to inactive channel for peer {self.peer_id}")
            return False
            
        # ğŸ”§ CRITICAL FIX: æ­£ç¡®è®¾ç½®sender_idå’Œreceiver_id
        # sender_idåº”è¯¥æ˜¯å‘é€æ–¹çš„client_idï¼Œreceiver_idåº”è¯¥æ˜¯æ¥æ”¶æ–¹çš„peer_id
        request = gRPC_comm_manager_pb2.ChunkStreamRequest(
            sender_id=self.client_id,  # å‘é€æ–¹client_id
            receiver_id=self.peer_id,   # æ¥æ”¶æ–¹peer_id
            round_num=round_num,
            source_client_id=source_client_id,
            chunk_id=chunk_id,
            chunk_data=chunk_data,
            checksum=checksum,
            chunk_type=gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE,
            importance_score=importance_score,
            timestamp=int(time.time() * 1000)
        )
        
        try:
            # ğŸš€ ä½¿ç”¨ä¸“ç”¨ä¸Šä¼ é˜Ÿåˆ—ï¼Œæé«˜chunkæ•°æ®ä¼ è¾“æ•ˆç‡
            logger.info(f"[ğŸš€ StreamChannel] Client {self.client_id}: Queueing chunk data {source_client_id}:{chunk_id} to peer {self.peer_id}")
            logger.info(f"[ğŸš€ StreamChannel] Client {self.client_id}: Chunk data size: {len(chunk_data)}, queue size before: {self.upload_request_queue.qsize()}")
            
            self.upload_request_queue.put(request, timeout=1.0)
            self.chunks_sent += 1
            self.bytes_sent += len(chunk_data)
            
            logger.info(f"[ğŸš€ StreamChannel] Client {self.client_id}: Successfully queued chunk data {source_client_id}:{chunk_id} to peer {self.peer_id}")
            logger.info(f"[ğŸš€ StreamChannel] Client {self.client_id}: Queue size after: {self.upload_request_queue.qsize()}")
            return True
        except queue.Full:
            logger.error(f"[StreamChannel] Upload queue full for peer {self.peer_id}")
            return False
    
    def send_control_message(self, msg_type: str, round_num: int, **kwargs) -> bool:
        """ğŸš€ å‘é€BitTorrentæ§åˆ¶æ¶ˆæ¯ (bitfield, have, interested, cancel)"""
        if not self.is_active:
            logger.warning(f"[StreamChannel] Cannot send to inactive channel for peer {self.peer_id}")
            return False
        
        # æ˜ å°„æ¶ˆæ¯ç±»å‹åˆ°protobuf ChunkType
        chunk_type_map = {
            'bitfield': gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD,
            'have': gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE,
            'cancel': gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL,
            'request': gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
            'piece': gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE
        }
        
        if msg_type not in chunk_type_map:
            logger.error(f"[StreamChannel] Unsupported control message type: {msg_type}")
            return False
        
        # æ„å»ºæ§åˆ¶æ¶ˆæ¯è¯·æ±‚
        request = gRPC_comm_manager_pb2.ChunkStreamRequest(
            sender_id=self.client_id,
            receiver_id=self.peer_id,
            round_num=round_num,
            chunk_type=chunk_type_map[msg_type],
            timestamp=int(time.time() * 1000)
        )
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹è®¾ç½®ç‰¹å®šå­—æ®µ
        if msg_type == 'bitfield':
            # bitfieldæ¶ˆæ¯ï¼šä½¿ç”¨chunk_dataä¼ è¾“bitfieldæ•°æ®
            import json
            bitfield_data = kwargs.get('bitfield', [])
            request.chunk_data = json.dumps(bitfield_data).encode('utf-8')
            logger.info(f"[StreamChannel] Client {self.client_id}: Sending BITFIELD to peer {self.peer_id}, chunks: {len(bitfield_data)}")
            
        elif msg_type == 'have':
            # haveæ¶ˆæ¯ï¼šæ ‡è¯†æ‹¥æœ‰çš„chunk
            request.source_client_id = kwargs.get('source_client_id', 0)
            request.chunk_id = kwargs.get('chunk_id', 0)
            request.importance_score = kwargs.get('importance_score', 0.0)
            logger.info(f"[StreamChannel] Client {self.client_id}: Sending HAVE to peer {self.peer_id}, chunk: {request.source_client_id}:{request.chunk_id}")
            
        elif msg_type == 'cancel':
            # cancelæ¶ˆæ¯ï¼šå–æ¶ˆchunkè¯·æ±‚
            request.source_client_id = kwargs.get('source_client_id', 0)
            request.chunk_id = kwargs.get('chunk_id', 0)
            logger.info(f"[StreamChannel] Client {self.client_id}: Sending CANCEL to peer {self.peer_id}, chunk: {request.source_client_id}:{request.chunk_id}")
        
        try:
            # ä½¿ç”¨æ§åˆ¶æµé˜Ÿåˆ—å‘é€
            self.request_queue.put(request, timeout=1.0)
            logger.info(f"[StreamChannel] Client {self.client_id}: Successfully queued {msg_type.upper()} message to peer {self.peer_id}")
            return True
        except queue.Full:
            logger.error(f"[StreamChannel] Control queue full for peer {self.peer_id}")
            return False
            
    def close(self):
        """å…³é—­streamingé€šé“"""
        if not self.is_active:
            return
            
        self.is_active = False
        
        # å‘é€å…³é—­ä¿¡å·åˆ°å„ä¸ªé˜Ÿåˆ—
        try:
            self.request_queue.put(None)
            self.upload_request_queue.put(None)
            self.download_request_queue.put(None)
        except:
            pass
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        threads = [
            self.control_receiver_thread,
            self.download_sender_thread,
            self.upload_sender_thread,
        ]
        
        for thread in threads:
            if thread and thread.is_alive():
                thread.join(timeout=1.0)
            
        # å…³é—­gRPCé€šé“
        try:
            self.channel.close()
            logger.info(f"[StreamChannel] Closed streaming to peer {self.peer_id}")
        except:
            pass
            
    def get_stats(self):
        """è·å–é€šé“ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'peer_id': self.peer_id,
            'is_active': self.is_active,
            'bytes_sent': self.bytes_sent,
            'bytes_received': self.bytes_received,
            'chunks_sent': self.chunks_sent,
            'chunks_received': self.chunks_received,
            'last_activity': self.last_activity
        }


class StreamingChannelManager:
    """ğŸš€ gRPC Streamingé€šé“ç®¡ç†å™¨ - åœ¨æ‹“æ‰‘æ„å»ºæ—¶åˆ›å»ºä¸“ç”¨é€šé“"""
    
    def __init__(self, client_id: int):
        self.client_id = client_id
        self.channels: Dict[int, StreamingChannel] = {}  # peer_id -> StreamingChannel
        self.server_stubs: Dict[str, gRPC_comm_manager_pb2_grpc.gRPCComServeFuncStub] = {}
        
        # æ€§èƒ½ç»Ÿè®¡
        self.total_bytes_sent = 0
        self.total_bytes_received = 0
        self.total_chunks_sent = 0
        self.total_chunks_received = 0
        
        logger.info(f"[StreamingManager] Initialized for client {client_id}")
        
    def create_channels_for_topology(self, neighbor_addresses: Dict[int, Tuple[str, int]]):
        """
        ğŸš€ åœ¨æ‹“æ‰‘æ„å»ºæ—¶ä¸ºæ‰€æœ‰é‚»å±…åˆ›å»ºä¸“ç”¨streamingé€šé“
        Args:
            neighbor_addresses: {peer_id: (host, port)}
        """
        logger.info(f"[StreamingManager] Client {self.client_id}: Creating streaming channels for topology")
        logger.info(f"[StreamingManager] Neighbor addresses: {neighbor_addresses}")
        
        for peer_id, (host, port) in neighbor_addresses.items():
            if peer_id == self.client_id:
                continue  # è·³è¿‡è‡ªå·±
                
            try:
                # åˆ›å»ºgRPCé€šé“
                address = f"{host}:{port}"
                channel = grpc.insecure_channel(address)
                
                # åˆ›å»ºstub
                stub = gRPC_comm_manager_pb2_grpc.gRPCComServeFuncStub(channel)
                
                # åˆ›å»ºstreamingé€šé“å°è£…
                stream_channel = StreamingChannel(peer_id, channel, stub, client_id=self.client_id)
                
                # å¯åŠ¨streaming (å¦‚æœå¤±è´¥ä¼šè‡ªåŠ¨å›é€€)
                stream_channel.start_streaming()
                
                # æ€»æ˜¯ä¿å­˜é€šé“ï¼Œå³ä½¿streamingå¤±è´¥ä¹Ÿå¯ä»¥ç”¨äºä¼ ç»Ÿæ¶ˆæ¯
                self.channels[peer_id] = stream_channel
                self.server_stubs[address] = stub
                
                if stream_channel.is_active:
                    logger.info(f"[StreamingManager] âœ… Created multi-stream channel: Client {self.client_id} -> Peer {peer_id} ({address})")
                else:
                    logger.info(f"[StreamingManager] ğŸ”§ Created traditional channel: Client {self.client_id} -> Peer {peer_id} ({address}) - streaming not available")
                
            except Exception as e:
                logger.error(f"[StreamingManager] Failed to create any channel to peer {peer_id} at {host}:{port}: {e}")
                
        logger.info(f"[StreamingManager] Client {self.client_id}: Created {len(self.channels)} streaming channels")
        logger.info(f"[StreamingManager] ğŸš€ STREAMING OPTIMIZATION: BitTorrent messages now support high-performance streaming:")
        logger.info(f"[StreamingManager]   ğŸ“¦ CHUNK_PIECE: Large chunk data via dedicated upload streams") 
        logger.info(f"[StreamingManager]   ğŸ“¤ CHUNK_REQUEST: Chunk requests via control streams")
        logger.info(f"[StreamingManager]   ğŸ¯ CHUNK_HAVE: Have notifications via control streams") 
        logger.info(f"[StreamingManager]   ğŸ“‹ CHUNK_BITFIELD: Bitfield updates via control streams")
        logger.info(f"[StreamingManager]   âŒ CHUNK_CANCEL: Cancel requests via control streams")
        logger.info(f"[StreamingManager]   ğŸ”„ Auto fallback to traditional messaging if streaming fails")
        
    def send_chunk_request(self, peer_id: int, round_num: int, source_client_id: int, 
                          chunk_id: int, importance_score: float = 0.0) -> bool:
        """é€šè¿‡streamingé€šé“å‘é€chunkè¯·æ±‚"""
        if peer_id not in self.channels:
            logger.warning(f"[StreamingManager] No streaming channel to peer {peer_id}")
            return False
            
        return self.channels[peer_id].send_chunk_request(
            round_num, source_client_id, chunk_id, importance_score)
            
    def send_bittorrent_message(self, peer_id: int, msg_type: str, **kwargs) -> bool:
        """ğŸš€ ç»Ÿä¸€çš„BitTorrentæ¶ˆæ¯å‘é€æ¥å£ - æ”¯æŒæ‰€æœ‰æ¶ˆæ¯ç±»å‹"""
        if peer_id not in self.channels:
            logger.warning(f"[StreamingManager] No streaming channel to peer {peer_id}")
            return False
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ„å»ºä¸åŒçš„è¯·æ±‚
        if msg_type == 'piece':
            return self.channels[peer_id].send_chunk_data(**kwargs)
        elif msg_type == 'request':
            return self.channels[peer_id].send_chunk_request(**kwargs)
        elif msg_type in ['bitfield', 'have', 'cancel']:
            return self.channels[peer_id].send_control_message(msg_type, **kwargs)
        else:
            logger.error(f"[StreamingManager] Unknown BitTorrent message type: {msg_type}")
            return False
    
    def send_chunk_data(self, peer_id: int, round_num: int, source_client_id: int,
                       chunk_id: int, chunk_data: bytes, checksum: str, 
                       importance_score: float = 0.0) -> bool:
        """é€šè¿‡streamingé€šé“å‘é€chunkæ•°æ®"""
        if peer_id not in self.channels:
            logger.warning(f"[StreamingManager] No streaming channel to peer {peer_id}")
            return False
            
        success = self.channels[peer_id].send_chunk_data(
            round_num, source_client_id, chunk_id, chunk_data, checksum, importance_score)
            
        if success:
            self.total_chunks_sent += 1
            self.total_bytes_sent += len(chunk_data)
            
        return success
        
    def get_active_peers(self) -> List[int]:
        """è·å–æ‰€æœ‰æ´»è·ƒçš„peeråˆ—è¡¨"""
        return [peer_id for peer_id, channel in self.channels.items() if channel.is_active]
        
    def close_all_channels(self):
        """å…³é—­æ‰€æœ‰streamingé€šé“"""
        logger.info(f"[StreamingManager] Client {self.client_id}: Closing all streaming channels")
        
        for peer_id, channel in self.channels.items():
            channel.close()
            
        self.channels.clear()
        self.server_stubs.clear()
        
        logger.info(f"[StreamingManager] Client {self.client_id}: All streaming channels closed")
        
    def get_channel_stats(self):
        """è·å–æ‰€æœ‰é€šé“çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'client_id': self.client_id,
            'total_channels': len(self.channels),
            'active_channels': len([c for c in self.channels.values() if c.is_active]),
            'total_bytes_sent': self.total_bytes_sent,
            'total_bytes_received': self.total_bytes_received,
            'total_chunks_sent': self.total_chunks_sent,
            'total_chunks_received': self.total_chunks_received,
            'channels': {peer_id: channel.get_stats() for peer_id, channel in self.channels.items()}
        }
        return stats