"""
ðŸš€ High-Performance Chunk Data Cache System
Two-tier storage: RAM Cache + Disk Spool for chunk data

Replaces database storage with direct file I/O for maximum performance
File naming: client_{source_client_id}_chunk_{chunk_id}_r{round_num}.dat
"""

import os
import time
import hashlib
import threading
import logging
import tempfile
from typing import Dict, Optional, Tuple, Any
from collections import OrderedDict
from concurrent.futures import ThreadPoolExecutor
# pickle removed - no automatic serialization for security

logger = logging.getLogger(__name__)

class ChunkDataCache:
    """
    ðŸš€ Two-tier chunk data cache system
    
    Tier 1: RAM Cache - Fast in-memory access for recently accessed chunks
    Tier 2: Disk Spool - Direct file storage for persistent data
    
    Features:
    - Zero database overhead
    - Direct bytes storage/retrieval
    - LRU eviction policy for RAM
    - Thread-safe operations
    - Async disk spooling
    """
    
    def __init__(self, client_id: int, cache_dir: str = None, max_ram_chunks: int = 100, max_ram_size_mb: int = 256):
        """
        Initialize chunk data cache system
        
        Args:
            client_id: Client identifier
            cache_dir: Directory for disk spool (defaults to tmp/client_X/chunks/)
            max_ram_chunks: Maximum chunks in RAM cache
            max_ram_size_mb: Maximum RAM cache size in MB
        """
        self.client_id = client_id
        
        # Setup cache directory
        if cache_dir is None:
            cache_dir = os.path.join(os.getcwd(), "tmp", f"client_{client_id}", "chunks")
        self.cache_dir = cache_dir
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # RAM Cache configuration
        self.max_ram_chunks = max_ram_chunks
        self.max_ram_size = max_ram_size_mb * 1024 * 1024  # Convert to bytes
        
        # RAM Cache: LRU ordered dictionary {chunk_key: (data_bytes, size, timestamp)}
        self.ram_cache: OrderedDict[str, Tuple[bytes, int, float]] = OrderedDict()
        self.ram_cache_size = 0
        self.cache_lock = threading.RLock()
        
        # Async disk spooling
        self.spool_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix=f"ChunkSpool-{client_id}")
        
        # Statistics
        self.stats = {
            'ram_hits': 0,
            'disk_hits': 0,
            'misses': 0,
            'saves': 0,
            'evictions': 0
        }
        
        logger.info(f"[ChunkCache] Client {client_id}: Initialized cache - RAM: {max_ram_chunks} chunks/{max_ram_size_mb}MB, Disk: {cache_dir}")
    
    def _get_chunk_key(self, round_num: int, source_client_id: int, chunk_id: int) -> str:
        """Generate unique chunk key"""
        return f"{round_num}_{source_client_id}_{chunk_id}"
    
    def _get_chunk_filepath(self, round_num: int, source_client_id: int, chunk_id: int) -> str:
        """Generate chunk file path for disk spool"""
        filename = f"client_{source_client_id}_chunk_{chunk_id}_r{round_num}.dat"
        return os.path.join(self.cache_dir, filename)
    
    def _evict_lru_chunks(self, target_size: int):
        """Evict least recently used chunks from RAM to make space"""
        with self.cache_lock:
            while self.ram_cache_size > target_size and self.ram_cache:
                # Remove oldest item (LRU)
                chunk_key, (data_bytes, size, timestamp) = self.ram_cache.popitem(last=False)
                self.ram_cache_size -= size
                self.stats['evictions'] += 1
                logger.debug(f"[ChunkCache] Client {self.client_id}: Evicted chunk {chunk_key} ({size} bytes)")
    
    def save_chunk_data(self, round_num: int, source_client_id: int, chunk_id: int, chunk_data: bytes):
        """
        ðŸš€ Save chunk data to cache system
        
        Args:
            round_num: Round number
            source_client_id: Source client ID
            chunk_id: Chunk identifier
            chunk_data: Raw chunk data as bytes (no automatic serialization for security)
        """
        # ðŸ”§ SECURITY: Only accept bytes, no automatic pickling
        if not isinstance(chunk_data, bytes):
            raise TypeError(f"chunk_data must be bytes, got {type(chunk_data)}. Caller should serialize manually.")
        
        data_bytes = chunk_data
        
        chunk_key = self._get_chunk_key(round_num, source_client_id, chunk_id)
        data_size = len(data_bytes)
        current_time = time.time()
        
        # Add to RAM cache with LRU eviction
        with self.cache_lock:
            # Remove if already exists to update position
            if chunk_key in self.ram_cache:
                old_data, old_size, old_time = self.ram_cache.pop(chunk_key)
                self.ram_cache_size -= old_size
            
            # ðŸ”§ CLARITY: Check if we need to evict to make space
            # Evict until: ram_cache_size + data_size <= max_ram_size
            if self.ram_cache_size + data_size > self.max_ram_size:
                target_size = self.max_ram_size - data_size
                self._evict_lru_chunks(target_size)
            
            # Add new chunk to RAM cache (if it fits)
            if data_size <= self.max_ram_size and len(self.ram_cache) < self.max_ram_chunks:
                self.ram_cache[chunk_key] = (data_bytes, data_size, current_time)
                self.ram_cache_size += data_size
                logger.debug(f"[ChunkCache] Client {self.client_id}: Cached chunk {chunk_key} in RAM ({data_size} bytes)")
        
        # Async spool to disk
        self.spool_executor.submit(self._spool_to_disk, round_num, source_client_id, chunk_id, data_bytes)
        
        self.stats['saves'] += 1
        logger.debug(f"[ChunkCache] Client {self.client_id}: Saved chunk {source_client_id}:{chunk_id} r{round_num}")
    
    def _spool_to_disk(self, round_num: int, source_client_id: int, chunk_id: int, data_bytes: bytes):
        """Internal method: Spool chunk data to disk file with atomic writes"""
        filepath = self._get_chunk_filepath(round_num, source_client_id, chunk_id)
        temp_fd = None
        temp_filepath = None
        
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # ðŸ”§ CONCURRENCY FIX: Use mkstemp for unique temporary file (no race conditions)
            temp_fd, temp_filepath = tempfile.mkstemp(
                suffix='.tmp',
                prefix=f'chunk_{source_client_id}_{chunk_id}_r{round_num}_',
                dir=os.path.dirname(filepath)
            )
            
            # Write to unique temporary file
            with os.fdopen(temp_fd, 'wb') as f:
                temp_fd = None  # fdopen takes ownership of file descriptor
                f.write(data_bytes)
                f.flush()  # Flush to OS buffer
                os.fsync(f.fileno())  # Force sync to disk
            
            # Atomic replace: unique temp file -> final file
            os.replace(temp_filepath, filepath)
            temp_filepath = None  # Successfully moved, don't clean up
            
            logger.debug(f"[ChunkCache] Client {self.client_id}: Atomically spooled chunk {source_client_id}:{chunk_id} r{round_num} to disk ({len(data_bytes)} bytes)")
            
        except Exception as e:
            # Clean up temp file/fd on error
            if temp_fd is not None:
                try:
                    os.close(temp_fd)
                except:
                    pass
            
            if temp_filepath and os.path.exists(temp_filepath):
                try:
                    os.remove(temp_filepath)
                except:
                    pass
                    
            logger.error(f"[ChunkCache] Client {self.client_id}: Failed to spool chunk {source_client_id}:{chunk_id} r{round_num}: {e}")
    
    def get_chunk_data_bytes(self, round_num: int, source_client_id: int, chunk_id: int) -> Optional[bytes]:
        """
        ðŸš€ Get chunk data from cache system as raw bytes (default method)
        
        Returns:
            Raw chunk data bytes or None if not found
            
        Note: Renamed from get_chunk_data for clarity - only returns bytes, no deserialization
        """
        chunk_key = self._get_chunk_key(round_num, source_client_id, chunk_id)
        
        # Try RAM cache first (fastest)
        with self.cache_lock:
            if chunk_key in self.ram_cache:
                data_bytes, size, _ = self.ram_cache.pop(chunk_key)
                # Move to end (most recently used)
                self.ram_cache[chunk_key] = (data_bytes, size, time.time())
                
                self.stats['ram_hits'] += 1
                logger.debug(f"[ChunkCache] Client {self.client_id}: RAM cache hit for {chunk_key}")
                return data_bytes
        
        # Try disk spool (slower but persistent)
        filepath = self._get_chunk_filepath(round_num, source_client_id, chunk_id)
        if os.path.exists(filepath):
            try:
                with open(filepath, 'rb') as f:
                    data_bytes = f.read()
                
                # Add back to RAM cache for future hits
                data_size = len(data_bytes)
                current_time = time.time()
                
                with self.cache_lock:
                    # ðŸ”§ CONCURRENCY FIX: Check if chunk was already added by another thread
                    if chunk_key in self.ram_cache:
                        # Another thread already loaded this chunk, just update LRU position
                        existing_data, existing_size, _ = self.ram_cache.pop(chunk_key)
                        self.ram_cache[chunk_key] = (existing_data, existing_size, time.time())
                        logger.debug(f"[ChunkCache] Client {self.client_id}: Chunk {chunk_key} already in RAM (concurrent load)")
                    else:
                        # Make space if needed - clearer boundary check
                        if self.ram_cache_size + data_size > self.max_ram_size:
                            target_size = self.max_ram_size - data_size
                            self._evict_lru_chunks(target_size)
                        
                        # Add to RAM cache if fits
                        if data_size <= self.max_ram_size and len(self.ram_cache) < self.max_ram_chunks:
                            self.ram_cache[chunk_key] = (data_bytes, data_size, current_time)
                            self.ram_cache_size += data_size
                            logger.debug(f"[ChunkCache] Client {self.client_id}: Added disk chunk {chunk_key} back to RAM ({data_size} bytes)")
                        else:
                            logger.debug(f"[ChunkCache] Client {self.client_id}: Disk chunk {chunk_key} too large for RAM ({data_size} bytes)")
                
                self.stats['disk_hits'] += 1
                logger.debug(f"[ChunkCache] Client {self.client_id}: Disk cache hit for {chunk_key}")
                return data_bytes
                
            except Exception as e:
                logger.error(f"[ChunkCache] Client {self.client_id}: Failed to read disk chunk {chunk_key}: {e}")
                return None
        
        # Not found in either cache
        self.stats['misses'] += 1
        logger.debug(f"[ChunkCache] Client {self.client_id}: Cache miss for {chunk_key}")
        return None
    
    def get_chunk_data(self, round_num: int, source_client_id: int, chunk_id: int) -> Optional[bytes]:
        """
        ðŸš€ Get chunk data from cache system (alias for get_chunk_data_bytes)
        
        Returns raw bytes - caller is responsible for deserialization if needed
        """
        return self.get_chunk_data_bytes(round_num, source_client_id, chunk_id)
    
    def has_chunk(self, round_num: int, source_client_id: int, chunk_id: int) -> bool:
        """Check if chunk exists in cache system"""
        chunk_key = self._get_chunk_key(round_num, source_client_id, chunk_id)
        
        # Check RAM cache
        with self.cache_lock:
            if chunk_key in self.ram_cache:
                return True
        
        # Check disk spool
        filepath = self._get_chunk_filepath(round_num, source_client_id, chunk_id)
        return os.path.exists(filepath)
    
    def cleanup_round(self, current_round: int, keep_rounds: int = 2):
        """Clean up old round data from disk"""
        try:
            # ðŸ”§ CLEANUP FIX: Process all .dat files and extract their rounds
            cutoff_round = current_round - keep_rounds
            removed_files = 0
            
            for filename in os.listdir(self.cache_dir):
                if filename.endswith('.dat'):
                    # Extract round from filename format: client_X_chunk_Y_rZ.dat
                    try:
                        if '_r' in filename:
                            round_part = filename.split('_r')[1].split('.')[0]
                            file_round = int(round_part)
                            
                            # Remove files from rounds older than cutoff
                            if file_round < cutoff_round:
                                filepath = os.path.join(self.cache_dir, filename)
                                os.remove(filepath)
                                removed_files += 1
                                logger.debug(f"[ChunkCache] Client {self.client_id}: Removed old round {file_round} file: {filename}")
                    except (ValueError, IndexError) as e:
                        logger.debug(f"[ChunkCache] Client {self.client_id}: Couldn't parse round from filename {filename}: {e}")
                        continue
            
            if removed_files > 0:
                logger.info(f"[ChunkCache] Client {self.client_id}: Cleaned up {removed_files} old chunk files (rounds < {cutoff_round})")
            
            # Clean RAM cache for old rounds
            with self.cache_lock:
                keys_to_remove = []
                for chunk_key in self.ram_cache:
                    try:
                        key_round = int(chunk_key.split('_')[0])
                        if key_round < cutoff_round:
                            keys_to_remove.append(chunk_key)
                    except (ValueError, IndexError):
                        continue
                
                for key in keys_to_remove:
                    _, size, _ = self.ram_cache.pop(key)
                    self.ram_cache_size -= size
                    logger.debug(f"[ChunkCache] Client {self.client_id}: Cleaned up RAM chunk {key}")
        
        except Exception as e:
            logger.error(f"[ChunkCache] Client {self.client_id}: Error during cleanup: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        with self.cache_lock:
            ram_chunks = len(self.ram_cache)
            ram_size_mb = self.ram_cache_size / (1024 * 1024)
        
        # Count disk files
        disk_files = 0
        try:
            disk_files = len([f for f in os.listdir(self.cache_dir) if f.endswith('.dat')])
        except:
            pass
        
        hit_rate = 0.0
        total_requests = sum([self.stats['ram_hits'], self.stats['disk_hits'], self.stats['misses']])
        if total_requests > 0:
            hit_rate = (self.stats['ram_hits'] + self.stats['disk_hits']) / total_requests * 100
        
        return {
            'client_id': self.client_id,
            'ram_chunks': ram_chunks,
            'ram_size_mb': round(ram_size_mb, 2),
            'disk_files': disk_files,
            'hit_rate_percent': round(hit_rate, 1),
            **self.stats
        }
    
    def close(self):
        """Shutdown cache system"""
        logger.info(f"[ChunkCache] Client {self.client_id}: Shutting down cache system...")
        
        # Shutdown async spool executor
        self.spool_executor.shutdown(wait=True)
        
        # Log final statistics
        stats = self.get_stats()
        logger.info(f"[ChunkCache] Client {self.client_id}: Final stats: {stats}")