"""
BitTorrentåè®®ç®¡ç†å™¨
å®ç°ç»å…¸BitTorrentåè®®ç”¨äºFederatedScopeä¸­çš„chunkäº¤æ¢
"""

import time
import hashlib
import random
import logging
from typing import Dict, Set, List, Tuple, Optional, Any

logger = logging.getLogger(__name__)


class BitTorrentManager:
    """ç®¡ç†BitTorrentåè®®çš„æ ¸å¿ƒé€»è¾‘ï¼ˆåŒ…å«å…³é”®Bugä¿®å¤ï¼‰"""
    
    def __init__(self, client_id: int, round_num: int, chunk_manager, comm_manager, neighbors: List[int]):
        self.client_id = client_id
        self.round_num = round_num  # ğŸ”´ å…³é”®ï¼šå½“å‰è½®æ¬¡
        self.chunk_manager = chunk_manager
        self.comm_manager = comm_manager
        self.neighbors = neighbors  # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä¼ å…¥é‚»å±…åˆ—è¡¨
        
        # BitTorrentçŠ¶æ€
        self.peer_bitfields: Dict[int, Dict] = {}  # {peer_id: bitfield}
        self.interested_in: Set[int] = set()  # æ„Ÿå…´è¶£çš„peers
        self.interested_by: Set[int] = set()  # å¯¹æˆ‘æ„Ÿå…´è¶£çš„peers
        self.choked_peers: Set[int] = set()  # è¢«chokeçš„peers
        self.unchoked_peers: Set[int] = set()  # unchokedçš„peersï¼ˆå¯ä»¥ä¸‹è½½ï¼‰
        
        # æ€§èƒ½ç®¡ç†
        self.download_rate: Dict[int, float] = {}  # {peer_id: bytes/sec}
        self.upload_rate: Dict[int, float] = {}  # {peer_id: bytes/sec}
        self.last_unchoke_time = 0
        self.optimistic_unchoke_peer = None
        
        # ğŸ”§ ä¿®å¤ï¼šç®€åŒ–çŠ¶æ€ç®¡ç†ï¼Œé¿å…å¤æ‚çš„é”æœºåˆ¶
        # FederatedScopeæ˜¯å•çº¿ç¨‹æ¶ˆæ¯é©±åŠ¨ï¼Œä¸éœ€è¦é”
        
        # ğŸ”§ Bugä¿®å¤2: é˜²æ­»é”æœºåˆ¶
        self.ever_unchoked: Set[int] = set()  # è®°å½•æ›¾ç»unchokeè¿‡çš„peers
        self.last_activity: Dict[int, float] = {}  # {peer_id: timestamp} æœ€åæ´»åŠ¨æ—¶é—´
        self.stalled_threshold = 30.0  # 30ç§’æ— æ´»åŠ¨è§†ä¸ºstalled
        
        # ğŸ”§ Bugä¿®å¤3: æ¶ˆæ¯é‡ä¼ æœºåˆ¶
        self.pending_requests: Dict[Tuple, Tuple[int, float]] = {}  # {(source_id, chunk_id): (peer_id, timestamp)}
        self.request_timeout = 5.0  # 5ç§’è¯·æ±‚è¶…æ—¶
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_count: Dict[Tuple, int] = {}  # {(source_id, chunk_id): count}
        
        # ğŸ”§ Bugä¿®å¤4: ç¡®ä¿æœ€å°unchokeæ•°é‡
        self.MIN_UNCHOKE_SLOTS = 1  # è‡³å°‘ä¿æŒ1ä¸ªunchokeï¼Œé˜²æ­¢å®Œå…¨æ­»é”
        self.MAX_UPLOAD_SLOTS = 4
        
        # ğŸ”§ ä¿®å¤ï¼šä¸ä½¿ç”¨åå°çº¿ç¨‹ï¼Œé€šè¿‡æ¶ˆæ¯å›è°ƒæ£€æŸ¥è¶…æ—¶
        self.last_timeout_check = time.time()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_downloaded = 0
        self.total_uploaded = 0
        self.chunks_per_client = 10  # é»˜è®¤å€¼ï¼Œå¯é…ç½®
        
        logger.info(f"[BT] BitTorrentManager initialized for client {client_id}, round {round_num}")
        
    def start_exchange(self):
        """å¯åŠ¨BitTorrent chunkäº¤æ¢æµç¨‹ï¼ˆæ— éœ€Trackerï¼‰"""
        logger.info(f"[BT] Client {self.client_id}: Starting BitTorrent exchange")
        logger.info(f"[BT] Client {self.client_id}: Neighbors: {self.neighbors}")
        
        # 1. ç›´æ¥å‘æ‰€æœ‰æ‹“æ‰‘é‚»å±…å‘é€bitfield
        for neighbor_id in self.neighbors:
            logger.info(f"[BT] Client {self.client_id}: Sending bitfield to neighbor {neighbor_id}")
            self._send_bitfield(neighbor_id)
        
        # 2. å¯åŠ¨å®šæœŸunchokeç®—æ³•ï¼ˆæ¯10ç§’ï¼‰
        self._schedule_regular_unchoke()
        
        # 3. å¯åŠ¨optimistic unchokeï¼ˆæ¯30ç§’ï¼‰
        self._schedule_optimistic_unchoke()
        
    def handle_bitfield(self, sender_id: int, bitfield: Dict):
        """å¤„ç†æ¥æ”¶åˆ°çš„bitfieldæ¶ˆæ¯"""
        self.peer_bitfields[sender_id] = bitfield
        logger.debug(f"[BT] Client {self.client_id}: Received bitfield from peer {sender_id} with {len(bitfield)} chunks")
        
        # ğŸ”§ è°ƒè¯•ï¼šè¾“å‡ºè¯¦ç»†çš„bitfieldåˆ†æ
        logger.debug(f"[BT] Client {self.client_id}: BitTorrent Manager received bitfield from peer {sender_id}:")
        if bitfield:
            for chunk_key, has_chunk in bitfield.items():
                round_num, source_id, chunk_id = chunk_key
                logger.debug(f"[BT] Client {self.client_id}: - Round {round_num}, Source {source_id}, Chunk {chunk_id}: {has_chunk}")
        else:
            logger.warning(f"[BT] Client {self.client_id}: âš ï¸ BitTorrent Manager got EMPTY bitfield from peer {sender_id}!")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æˆ‘éœ€è¦çš„chunks
        if self._has_interesting_chunks(sender_id):
            logger.debug(f"[BT] Client {self.client_id}: Peer {sender_id} has interesting chunks, sending interested")
            self._send_interested(sender_id)
        else:
            logger.info(f"[BT] Client {self.client_id}: Peer {sender_id} has no interesting chunks")
            
    def handle_interested(self, sender_id: int):
        """å¤„ç†interestedæ¶ˆæ¯"""
        self.interested_by.add(sender_id)
        logger.debug(f"[BT] Client {self.client_id}: Peer {sender_id} is interested")
        # æ ¹æ®å½“å‰upload slotså†³å®šæ˜¯å¦unchoke
        self._evaluate_unchoke(sender_id)
        
    def handle_request(self, sender_id: int, round_num: int, source_client_id: int, chunk_id: int):
        """å¤„ç†chunkè¯·æ±‚"""
        logger.debug(f"[BT-HANDLE] Client {self.client_id}: Handling request from {sender_id} for chunk {source_client_id}:{chunk_id}")
        
        # ğŸ”´ éªŒè¯è½®æ¬¡åŒ¹é…
        if round_num != self.round_num:
            logger.warning(f"[BT-HANDLE] Client {self.client_id}: Round mismatch - Request round {round_num} vs BitTorrent round {self.round_num}")
            logger.warning(f"[BT-HANDLE] Client {self.client_id}: Skipping request due to round mismatch")
            return
            
        if sender_id not in self.choked_peers:
            logger.debug(f"[BT-HANDLE] Client {self.client_id}: Peer {sender_id} is not choked, processing request")
            # å‘é€chunkæ•°æ®
            # ğŸ”´ æ·»åŠ round_numå‚æ•°åˆ°get_chunk_data
            logger.debug(f"[BT-HANDLE] Client {self.client_id}: Querying chunk_data with params (round={round_num}, source_client={source_client_id}, chunk_id={chunk_id})")
            chunk_data = self.chunk_manager.get_chunk_data(round_num, source_client_id, chunk_id)
            if chunk_data is not None:
                # å‘é€chunkæ•°æ®ï¼Œå³ä½¿æ˜¯ç©ºçš„chunkä¹Ÿè¦å‘é€
                chunk_size = len(chunk_data) if hasattr(chunk_data, '__len__') else 0
                if chunk_size > 0:
                    logger.debug(f"[BT-HANDLE] Client {self.client_id}: Found non-empty chunk data (size={chunk_size}), sending piece to {sender_id}")
                else:
                    logger.debug(f"[BT-HANDLE] Client {self.client_id}: Found empty chunk data (size={chunk_size}), sending empty piece to {sender_id}")
                
                self._send_piece(sender_id, round_num, source_client_id, chunk_id, chunk_data)
                logger.debug(f"[BT-HANDLE] Client {self.client_id}: Successfully sent chunk {source_client_id}:{chunk_id} to peer {sender_id}")
            else:
                logger.warning(f"[BT-HANDLE] Client {self.client_id}: Chunk {source_client_id}:{chunk_id} not found in database (round={round_num})")
                logger.warning(f"[BT-HANDLE] Client {self.client_id}: Database query returned: {chunk_data}")
        else:
            logger.info(f"[BT-HANDLE] Client {self.client_id}: Peer {sender_id} is choked, ignoring request")
            
    def handle_piece(self, sender_id: int, round_num: int, source_client_id: int, chunk_id: int, chunk_data: bytes, checksum: str):
        """
        å¤„ç†æ¥æ”¶åˆ°çš„chunkæ•°æ®ï¼ˆåŒ…å«å®Œæ•´æ€§æ ¡éªŒï¼‰
        ğŸ”´ å…³é”®ä¿®æ”¹ï¼šéªŒè¯round_numåŒ¹é…
        """
        logger.debug(f"[BT-PIECE] Client {self.client_id}: Received piece from {sender_id} for chunk {source_client_id}:{chunk_id} (piece_round={round_num}, bt_round={self.round_num}, timestamp={time.time():.3f})")
        
        # ğŸ”´ éªŒè¯è½®æ¬¡æ˜¯å¦åŒ¹é…
        if round_num != self.round_num:
            logger.warning(f"[BT-PIECE] Client {self.client_id}: Round mismatch - Piece round {round_num} vs BitTorrent round {self.round_num}")
            logger.warning(f"[BT-PIECE] Client {self.client_id}: Rejecting piece due to round mismatch")
            return False
            
        # ğŸ”§ ä¿®å¤ï¼šchunk_dataç°åœ¨æ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£ç åæ ¡éªŒ
        logger.debug(f"[BT-PIECE] Client {self.client_id}: Received encoded chunk data, type={type(chunk_data)}, size={len(chunk_data)}")
        
        # è§£ç base64æ•°æ®
        try:
            import base64
            import pickle
            decoded_data = base64.b64decode(chunk_data.encode('utf-8'))
            logger.debug(f"[BT-PIECE] Client {self.client_id}: Decoded base64 data, size={len(decoded_data)}")
        except Exception as e:
            logger.error(f"[BT-PIECE] Client {self.client_id}: Failed to decode base64 data: {e}")
            return False
        
        # å¯¹è§£ç åçš„åºåˆ—åŒ–æ•°æ®è®¡ç®—å“ˆå¸Œ
        calculated_checksum = hashlib.sha256(decoded_data).hexdigest()
        logger.debug(f"[BT-PIECE] Client {self.client_id}: Checksum verification - calculated={calculated_checksum[:8]}..., received={checksum[:8]}..., size={len(decoded_data)}")
        
        if calculated_checksum != checksum:
            logger.error(f"[BT-PIECE] Client {self.client_id}: Chunk integrity check failed for {source_client_id}:{chunk_id}")
            logger.error(f"[BT-PIECE] Client {self.client_id}: Expected={checksum}, Got={calculated_checksum}")
            # é‡æ–°è¯·æ±‚è¿™ä¸ªchunk
            chunk_key = (round_num, source_client_id, chunk_id)
            self.retry_count[chunk_key] = self.retry_count.get(chunk_key, 0) + 1
            logger.warning(f"[BT-PIECE] Client {self.client_id}: Retry count for chunk {chunk_key}: {self.retry_count[chunk_key]}")
            return False
        
        # ğŸ”§ ååºåˆ—åŒ–å¾—åˆ°åŸå§‹chunkæ•°æ®
        try:
            deserialized_data = pickle.loads(decoded_data)
            logger.debug(f"[BT-PIECE] Client {self.client_id}: Successfully deserialized chunk data, type={type(deserialized_data)}")
        except Exception as e:
            logger.error(f"[BT-PIECE] Client {self.client_id}: Failed to deserialize chunk data: {e}")
            return False
        
        # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
        # ğŸ”´ ä¼ é€’round_numåˆ°saveæ–¹æ³•ï¼Œä½¿ç”¨ååºåˆ—åŒ–åçš„æ•°æ®
        logger.debug(f"[BT-PIECE] Client {self.client_id}: Saving chunk {source_client_id}:{chunk_id} to database (round={round_num})")
        self.chunk_manager.save_remote_chunk(round_num, source_client_id, chunk_id, deserialized_data)
        
        # æ¸…é™¤pendingè¯·æ±‚
        chunk_key = (round_num, source_client_id, chunk_id)
        if chunk_key in self.pending_requests:
            logger.debug(f"[BT-PIECE] Client {self.client_id}: Clearing pending request for chunk {chunk_key}")
            del self.pending_requests[chunk_key]
        else:
            logger.debug(f"[BT-PIECE] Client {self.client_id}: No pending request found for chunk {chunk_key}")
        
        # å‘æ‰€æœ‰é‚»å±…å‘é€haveæ¶ˆæ¯
        # ğŸ”´ ä¼ é€’round_numä¿¡æ¯
        logger.debug(f"[BT-PIECE] Client {self.client_id}: Broadcasting have message for chunk {source_client_id}:{chunk_id}")
        self._broadcast_have(round_num, source_client_id, chunk_id)
        
        # æ›´æ–°ä¸‹è½½é€Ÿç‡å’Œæ´»åŠ¨æ—¶é—´
        self._update_download_rate(sender_id, len(decoded_data))
        self.last_activity[sender_id] = time.time()
        self.total_downloaded += len(decoded_data)
        
        logger.debug(f"[BT] Client {self.client_id}: Received chunk {source_client_id}:{chunk_id} from peer {sender_id}")
        return True
        
    def handle_have(self, sender_id: int, round_num: int, source_client_id: int, chunk_id: int):
        """å¤„ç†haveæ¶ˆæ¯"""
        if round_num != self.round_num:
            return
            
        chunk_key = (round_num, source_client_id, chunk_id)
        if sender_id not in self.peer_bitfields:
            self.peer_bitfields[sender_id] = {}
        self.peer_bitfields[sender_id][chunk_key] = True
        
        logger.debug(f"[BT] Client {self.client_id}: Peer {sender_id} has chunk {source_client_id}:{chunk_id}")
        
    def handle_choke(self, sender_id: int):
        """å¤„ç†chokeæ¶ˆæ¯"""
        self.choked_peers.add(sender_id)
        logger.debug(f"[BT] Client {self.client_id}: Choked by peer {sender_id}")
        
    def handle_unchoke(self, sender_id: int):
        """å¤„ç†unchokeæ¶ˆæ¯"""
        self.choked_peers.discard(sender_id)
        logger.debug(f"[BT] Client {self.client_id}: Unchoked by peer {sender_id}")
        
    def _rarest_first_selection(self) -> Optional[Tuple]:
        """Rarest First chunké€‰æ‹©ç®—æ³•"""
        # ç»Ÿè®¡æ¯ä¸ªchunkçš„ç¨€æœ‰åº¦
        chunk_availability = {}
        for peer_id, bitfield in self.peer_bitfields.items():
            for chunk_key, has_chunk in bitfield.items():
                # ğŸ”´ åªè€ƒè™‘å½“å‰è½®æ¬¡çš„chunks
                if has_chunk and chunk_key[0] == self.round_num:
                    chunk_availability[chunk_key] = chunk_availability.get(chunk_key, 0) + 1
                    
        # é€‰æ‹©æœ€ç¨€æœ‰ä½†å¯è·å¾—çš„chunk
        # ğŸ”´ ä¼ é€’round_numå‚æ•°åˆ°get_global_bitfield
        my_bitfield = self.chunk_manager.get_global_bitfield(self.round_num)
        needed_chunks = [(k, v) for k, v in chunk_availability.items() 
                        if k not in my_bitfield]
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if not chunk_availability:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è®°å½•è°ƒè¯•ä¿¡æ¯
            if not hasattr(self, '_logged_no_chunks'):
                logger.info(f"[BT] Client {self.client_id}: No chunks available from peers. Peer count: {len(self.peer_bitfields)}")
                for peer_id, bitfield in self.peer_bitfields.items():
                    logger.info(f"[BT] Client {self.client_id}: Peer {peer_id} bitfield size: {len(bitfield)}")
                self._logged_no_chunks = True
        elif not needed_chunks:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è®°å½•è°ƒè¯•ä¿¡æ¯
            if not hasattr(self, '_logged_all_chunks'):
                logger.info(f"[BT] Client {self.client_id}: Already have all available chunks. My chunks: {len(my_bitfield)}, Available: {len(chunk_availability)}")
                self._logged_all_chunks = True
        
        if needed_chunks:
            # æŒ‰ç¨€æœ‰åº¦æ’åºï¼ˆæ‹¥æœ‰peeræ•°æœ€å°‘çš„ä¼˜å…ˆï¼‰
            needed_chunks.sort(key=lambda x: (x[1], random.random()))
            return needed_chunks[0][0]  # è¿”å›æœ€ç¨€æœ‰çš„chunk
        return None
        
    def _regular_unchoke_algorithm(self):
        """ç»å…¸çš„Reciprocal Unchokeç®—æ³•ï¼ˆåŒ…å«é˜²æ­»é”æ”¹è¿›ï¼‰"""
        # ğŸ”§ Bugä¿®å¤6: åŠ¨æ€è°ƒæ•´upload slots
        # Staræ‹“æ‰‘ä¸­å¿ƒèŠ‚ç‚¹éœ€è¦æ›´å¤šslots
        if self._is_central_node():
            self.MAX_UPLOAD_SLOTS = 8
        
        # æ ¹æ®ä¸‹è½½é€Ÿç‡æ’åºinterested peers
        interested_peers = list(self.interested_by)
        interested_peers.sort(key=lambda p: self.download_rate.get(p, 0), reverse=True)
        
        # é€‰æ‹©å‰Nä¸ªpeersè¿›è¡Œregular unchokeï¼ˆé¢„ç•™1ä¸ªç»™optimisticï¼‰
        regular_slots = self.MAX_UPLOAD_SLOTS - 1
        new_unchoked = set(interested_peers[:regular_slots])
        
        # ğŸ”§ Bugä¿®å¤7: å…¬å¹³æ€§ä¿è¯ - ç¡®ä¿æ¯ä¸ªpeerè‡³å°‘è¢«unchokeè¿‡ä¸€æ¬¡
        for peer_id in self.interested_by:
            if peer_id not in self.ever_unchoked and len(new_unchoked) < self.MAX_UPLOAD_SLOTS:
                new_unchoked.add(peer_id)
                self.ever_unchoked.add(peer_id)
                logger.debug(f"[BT] Fairness unchoke for peer {peer_id}")
        
        # ğŸ”§ Bugä¿®å¤8: ç¡®ä¿è‡³å°‘æœ‰MIN_UNCHOKE_SLOTSä¸ªunchoke
        if len(new_unchoked) == 0 and len(self.interested_by) > 0:
            # éšæœºé€‰æ‹©ä¸€ä¸ªpeerè¿›è¡Œunchokeï¼Œé˜²æ­¢å®Œå…¨æ­»é”
            emergency_peer = random.choice(list(self.interested_by))
            new_unchoked.add(emergency_peer)
            logger.warning(f"[BT] Emergency unchoke for peer {emergency_peer}")
        
        # æ›´æ–°choke/unchokeçŠ¶æ€
        for peer_id in self.unchoked_peers - new_unchoked:
            self._send_choke(peer_id)
        for peer_id in new_unchoked - self.unchoked_peers:
            self._send_unchoke(peer_id)
            
        self.unchoked_peers = new_unchoked
        
    def _optimistic_unchoke(self):
        """Optimistic unchokeæœºåˆ¶ï¼ˆé˜²æ­»é”çš„å…³é”®ï¼‰"""
        # ä»è¢«chokeçš„interested peersä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
        choked_interested = self.interested_by - self.unchoked_peers
        if choked_interested:
            # ğŸ”§ Bugä¿®å¤9: ä¼˜å…ˆé€‰æ‹©ä»æœªunchokeè¿‡çš„peer
            never_unchoked = choked_interested - self.ever_unchoked
            if never_unchoked:
                self.optimistic_unchoke_peer = random.choice(list(never_unchoked))
            else:
                self.optimistic_unchoke_peer = random.choice(list(choked_interested))
            
            self._send_unchoke(self.optimistic_unchoke_peer)
            self.unchoked_peers.add(self.optimistic_unchoke_peer)
            self.ever_unchoked.add(self.optimistic_unchoke_peer)
            logger.info(f"[BT] Optimistic unchoke for peer {self.optimistic_unchoke_peer}")
            
    def _is_central_node(self) -> bool:
        """ğŸ› Bugä¿®å¤27: åˆ¤æ–­æ˜¯å¦ä¸ºstaræ‹“æ‰‘çš„ä¸­å¿ƒèŠ‚ç‚¹"""
        # ç®€å•åˆ¤æ–­ï¼šå¦‚æœè¿æ¥çš„é‚»å±…æ•°é‡è¶…è¿‡æ€»èŠ‚ç‚¹æ•°çš„ä¸€åŠï¼Œå¯èƒ½æ˜¯ä¸­å¿ƒèŠ‚ç‚¹
        if len(self.neighbors) > 2:  # å‡è®¾3ä¸ªä»¥ä¸Šè¿æ¥ä¸ºä¸­å¿ƒèŠ‚ç‚¹
            return True
        return False
        
    def _find_alternative_peers(self, chunk_key: Tuple, exclude: int = None) -> List[int]:
        """ğŸ› Bugä¿®å¤28: æŸ¥æ‰¾æ‹¥æœ‰æŒ‡å®šchunkçš„æ›¿ä»£peers"""
        alternatives = []
        for peer_id, bitfield in self.peer_bitfields.items():
            if peer_id != exclude and chunk_key in bitfield and bitfield[chunk_key]:
                alternatives.append(peer_id)
        return alternatives
        
    def _find_peer_with_chunk(self, chunk_key: Tuple) -> Optional[int]:
        """æŸ¥æ‰¾æ‹¥æœ‰æŒ‡å®šchunkçš„peer"""
        for peer_id, bitfield in self.peer_bitfields.items():
            if chunk_key in bitfield and bitfield[chunk_key]:
                return peer_id
        return None
        
    def _send_bitfield(self, peer_id: int):
        """å‘æŒ‡å®špeerå‘é€bitfield"""
        from federatedscope.core.message import Message
        
        # ğŸ”§ ä¿®å¤ï¼šå°†bitfieldè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        my_bitfield = self.chunk_manager.get_global_bitfield(self.round_num)
        logger.info(f"[BT] Client {self.client_id}: My bitfield for round {self.round_num}: {len(my_bitfield)} chunks")
        
        # ğŸ”§ è°ƒè¯•ï¼šè¯¦ç»†è¾“å‡ºæˆ‘æ‹¥æœ‰çš„chunks
        if my_bitfield:
            logger.info(f"[BT] Client {self.client_id}: My chunks for round {self.round_num}:")
            for chunk_key, has_chunk in my_bitfield.items():
                if has_chunk:
                    round_num, source_id, chunk_id = chunk_key
                    # é™é»˜è®°å½•æ‹¥æœ‰çš„chunks
                    pass
        else:
            logger.warning(f"[BT] Client {self.client_id}: âš ï¸ I have NO chunks for round {self.round_num}!")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        bitfield_list = []
        for (round_num, source_id, chunk_id), has_chunk in my_bitfield.items():
            if has_chunk:
                bitfield_list.append({
                    'round': round_num,
                    'source': source_id,
                    'chunk': chunk_id
                })
        
        logger.info(f"[BT] Client {self.client_id}: Sending {len(bitfield_list)} chunks in bitfield to peer {peer_id}")
        
        self.comm_manager.send(
            Message(msg_type='bitfield',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=self.round_num,
                   content={
                       'round_num': self.round_num,
                       'bitfield': bitfield_list
                   })
        )
        
    def _send_interested(self, peer_id: int):
        """å‘é€interestedæ¶ˆæ¯"""
        self.interested_in.add(peer_id)
        from federatedscope.core.message import Message
        self.comm_manager.send(
            Message(msg_type='interested',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=self.round_num,
                   content={})
        )
        
    def _send_unchoke(self, peer_id: int):
        """å‘é€unchokeæ¶ˆæ¯"""
        from federatedscope.core.message import Message
        self.comm_manager.send(
            Message(msg_type='unchoke',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=self.round_num,
                   content={})
        )
        
    def _send_choke(self, peer_id: int):
        """å‘é€chokeæ¶ˆæ¯"""
        from federatedscope.core.message import Message
        self.comm_manager.send(
            Message(msg_type='choke',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=self.round_num,
                   content={})
        )
    
    def _broadcast_have(self, round_num: int, source_client_id: int, chunk_id: int):
        """å‘æ‰€æœ‰é‚»å±…å‘é€haveæ¶ˆæ¯"""
        # ğŸ”´ haveæ¶ˆæ¯åŒ…å«è½®æ¬¡ä¿¡æ¯
        from federatedscope.core.message import Message
        for neighbor_id in self.neighbors:
            self.comm_manager.send(
                Message(msg_type='have',
                       sender=self.client_id,
                       receiver=[neighbor_id],
                       state=round_num,
                       content={
                           'round_num': round_num,
                           'source_client_id': source_client_id,
                           'chunk_id': chunk_id
                       })
            )
                
    def check_timeouts(self):
        """ğŸ”§ ä¿®å¤ï¼šéé˜»å¡è¶…æ—¶æ£€æŸ¥ï¼Œåœ¨æ¶ˆæ¯å¤„ç†ä¸­è°ƒç”¨"""
        current_time = time.time()
        
        # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        if current_time - self.last_timeout_check < 1.0:
            return
        
        self.last_timeout_check = current_time
        timeout_requests = []
        
        # æŸ¥æ‰¾è¶…æ—¶çš„è¯·æ±‚
        for chunk_key, (peer_id, timestamp) in self.pending_requests.items():
            if current_time - timestamp > self.request_timeout:
                timeout_requests.append((chunk_key, peer_id))
        
        # å¤„ç†è¶…æ—¶è¯·æ±‚
        for chunk_key, peer_id in timeout_requests:
            # ğŸ”´ chunk_keyç°åœ¨åŒ…å«è½®æ¬¡ä¿¡æ¯
            round_num, source_id, chunk_id = chunk_key
            retry_count = self.retry_count.get(chunk_key, 0)
            
            if retry_count < self.max_retries:
                # é‡æ–°è¯·æ±‚
                logger.warning(f"[BT] Request timeout for chunk {chunk_key}, retrying ({retry_count+1}/{self.max_retries})")
                
                # ä»å…¶ä»–peerè¯·æ±‚
                alternative_peers = self._find_alternative_peers(chunk_key, exclude=peer_id)
                if alternative_peers:
                    new_peer = alternative_peers[0]
                    # ğŸ”´ ä¼ é€’æ­£ç¡®çš„å‚æ•°ç»™_send_request
                    self._send_request(new_peer, source_id, chunk_id)
                    self.pending_requests[chunk_key] = (new_peer, current_time)
                    self.retry_count[chunk_key] = retry_count + 1
                else:
                    logger.error(f"[BT] No alternative peers for chunk {chunk_key}")
                    del self.pending_requests[chunk_key]
            else:
                # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                logger.error(f"[BT] Max retries reached for chunk {chunk_key}")
                del self.pending_requests[chunk_key]
                if chunk_key in self.retry_count:
                    del self.retry_count[chunk_key]
                        
    def _send_request(self, peer_id: int, source_id: int, chunk_id: int):
        """å‘é€chunkè¯·æ±‚ï¼ˆè®°å½•pendingçŠ¶æ€ï¼‰"""
        # ğŸ”´ chunk_keyåŒ…å«è½®æ¬¡ä¿¡æ¯
        chunk_key = (self.round_num, source_id, chunk_id)
        self.pending_requests[chunk_key] = (peer_id, time.time())
        
        logger.debug(f"[BT-REQ] Client {self.client_id}: Sending request to peer {peer_id} for chunk {source_id}:{chunk_id}")
        logger.debug(f"[BT-REQ] Client {self.client_id}: Request details - chunk_key={chunk_key}, pending_count={len(self.pending_requests)}")
        
        from federatedscope.core.message import Message
        self.comm_manager.send(
            Message(msg_type='request',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=self.round_num,
                   content={
                       'round_num': self.round_num,  # ğŸ”´ è¯·æ±‚çš„è½®æ¬¡
                       'source_client_id': source_id,
                       'chunk_id': chunk_id
                   })
        )
    
    def _send_piece(self, peer_id: int, round_num: int, source_client_id: int, chunk_id: int, chunk_data):
        """å‘é€chunkæ•°æ®"""
        # ğŸ”§ ä¿®å¤ï¼šé¢„åºåˆ—åŒ–chunk_dataå¹¶base64ç¼–ç é¿å…ç½‘ç»œä¼ è¾“ä¸­çš„æ•°æ®ç±»å‹å˜åŒ–
        import pickle
        import base64
        serialized_data = pickle.dumps(chunk_data)
        encoded_data = base64.b64encode(serialized_data).decode('utf-8')
        checksum = hashlib.sha256(serialized_data).hexdigest()
        
        logger.debug(f"[BT-SEND] Client {self.client_id}: Serializing chunk {source_client_id}:{chunk_id}, original_type={type(chunk_data)}, serialized_size={len(serialized_data)}, encoded_size={len(encoded_data)}")
        
        # ğŸ”´ æ¶ˆæ¯åŒ…å«è½®æ¬¡ä¿¡æ¯
        from federatedscope.core.message import Message
        self.comm_manager.send(
            Message(msg_type='piece',
                   sender=self.client_id,
                   receiver=[peer_id],
                   state=round_num,
                   content={
                       'round_num': round_num,  # ğŸ”´ chunkæ‰€å±è½®æ¬¡
                       'source_client_id': source_client_id,
                       'chunk_id': chunk_id,
                       'data': encoded_data,  # ğŸ”§ å‘é€base64ç¼–ç çš„å­—ç¬¦ä¸²
                       'checksum': checksum
                   })
        )
        
        # æ›´æ–°ä¸Šä¼ ç»Ÿè®¡
        self.total_uploaded += len(serialized_data)
        
    def _has_interesting_chunks(self, peer_id: int) -> bool:
        """æ£€æŸ¥peeræ˜¯å¦æœ‰æˆ‘éœ€è¦çš„chunks"""
        if peer_id not in self.peer_bitfields:
            return False
            
        my_bitfield = self.chunk_manager.get_global_bitfield(self.round_num)
        peer_bitfield = self.peer_bitfields[peer_id]
        
        # æ£€æŸ¥peeræ˜¯å¦æœ‰æˆ‘æ²¡æœ‰çš„chunks
        for chunk_key, has_chunk in peer_bitfield.items():
            if has_chunk and chunk_key not in my_bitfield and chunk_key[0] == self.round_num:
                return True
        return False
        
    def _evaluate_unchoke(self, peer_id: int):
        """è¯„ä¼°æ˜¯å¦unchokeæŒ‡å®špeer"""
        if len(self.unchoked_peers) < self.MAX_UPLOAD_SLOTS:
            self._send_unchoke(peer_id)
            self.unchoked_peers.add(peer_id)
            self.ever_unchoked.add(peer_id)
            
    def _schedule_regular_unchoke(self):
        """å®‰æ’å®šæœŸunchoke"""
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™åº”è¯¥é€šè¿‡å®šæ—¶å™¨æˆ–æ¶ˆæ¯å¾ªç¯è°ƒç”¨
        self.last_unchoke_time = time.time()
        
    def _schedule_optimistic_unchoke(self):
        """å®‰æ’optimistic unchoke"""
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™åº”è¯¥é€šè¿‡å®šæ—¶å™¨æˆ–æ¶ˆæ¯å¾ªç¯è°ƒç”¨
        pass
        
    def _update_download_rate(self, peer_id: int, bytes_received: int):
        """æ›´æ–°ä¸‹è½½é€Ÿç‡ç»Ÿè®¡"""
        current_time = time.time()
        if peer_id not in self.last_activity:
            self.last_activity[peer_id] = current_time
            self.download_rate[peer_id] = 0
            
        time_diff = current_time - self.last_activity[peer_id]
        if time_diff > 0:
            # ç®€å•çš„é€Ÿç‡è®¡ç®—
            rate = bytes_received / time_diff
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡
            if peer_id in self.download_rate:
                self.download_rate[peer_id] = 0.8 * self.download_rate[peer_id] + 0.2 * rate
            else:
                self.download_rate[peer_id] = rate
                
    def get_progress(self) -> Dict[str, Any]:
        """è·å–äº¤æ¢è¿›åº¦ä¿¡æ¯"""
        my_bitfield = self.chunk_manager.get_global_bitfield(self.round_num)
        total_expected = len(self.neighbors) * self.chunks_per_client + self.chunks_per_client  # åŒ…æ‹¬è‡ªå·±çš„chunks
        
        return {
            'chunks_collected': len(my_bitfield),
            'total_expected': total_expected,
            'progress_ratio': len(my_bitfield) / total_expected if total_expected > 0 else 0,
            'active_peers': len(self.peer_bitfields),
            'pending_requests': len(self.pending_requests),
            'bytes_downloaded': self.total_downloaded,
            'bytes_uploaded': self.total_uploaded
        }