import logging
import time
import threading
import hashlib
import pickle
import json
from collections import deque

from federatedscope.core.proto import gRPC_comm_manager_pb2, \
    gRPC_comm_manager_pb2_grpc

logger = logging.getLogger(__name__)


class gRPCComServeFunc(gRPC_comm_manager_pb2_grpc.gRPCComServeFuncServicer):
    def __init__(self, chunk_manager=None):
        self.msg_queue = deque()
        # ğŸš€ Streaming queues for chunk transfer
        self.chunk_stream_queues = {}  # {client_id: deque()}
        # ğŸš€ CRITICAL FIX: Add chunk_manager reference for data access (will be set by client)
        self.chunk_manager = chunk_manager
        
        # ğŸ”§ FIX: å•ä¾‹çº¿ç¨‹ç®¡ç† - å¹³æ—¶å¾…æœºï¼Œéœ€è¦æ—¶å¯åŠ¨
        self._background_processor = None
        self._processor_lock = threading.Lock()
        self._active_uploads = 0  # æ´»è·ƒä¸Šä¼ è¿æ¥è®¡æ•°å™¨
    
    def _ensure_background_processor(self):
        """ğŸ”§ æ‡’åŠ è½½ï¼šåªåœ¨éœ€è¦æ—¶å¯åŠ¨åå°å¤„ç†çº¿ç¨‹"""
        with self._processor_lock:
            if self._background_processor is None or not self._background_processor.is_alive():
                self._background_processor = threading.Thread(
                    target=self._background_chunk_processor,
                    daemon=True,
                    name="SharedBackgroundProcessor"
                )
                self._background_processor.start()
                logger.info("[ğŸ¯ gRPCServer] ğŸ”§ Background processor started (lazy-loaded)")
    
    def _background_chunk_processor(self):
        """ğŸ”§ å…±äº«çš„åå°å¤„ç†çº¿ç¨‹ - å¾…æœºæ¨¡å¼ï¼Œå¤„ç†æ‰€æœ‰å®¢æˆ·ç«¯çš„chunkæ•°æ®"""
        logger.info("[ğŸ¯ gRPCServer] ğŸš‡ Background processor thread started, entering standby mode")
        
        while True:
            try:
                # å¾…æœºæ¨¡å¼ï¼šå½“æ²¡æœ‰æ´»è·ƒè¿æ¥æ—¶ä¼‘çœ 
                if self._active_uploads == 0:
                    time.sleep(0.1)  # 100mså¾…æœºæ£€æŸ¥é—´éš”
                    continue
                
                # å¤„ç†æ¨¡å¼ï¼šå½“æœ‰æ´»è·ƒè¿æ¥æ—¶å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—
                # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„chunkå¤„ç†é€»è¾‘
                time.sleep(0.01)  # 10mså¤„ç†é—´éš”
                
            except Exception as e:
                logger.error(f"[ğŸ¯ gRPCServer] ğŸš‡ Background processor error: {e}")
                time.sleep(1.0)  # é”™è¯¯æ¢å¤é—´éš”
        
    def sendMessage(self, request, context):
        self.msg_queue.append(request)
        return gRPC_comm_manager_pb2.MessageResponse(msg='ACK')
        
    def streamChunks(self, request_iterator, context):
        """ğŸš€ åŒå‘streaming RPC for chunk control messages"""
        logger.debug("[gRPCServer] streamChunks method called")
        logger.info(f"[ğŸ” gRPCServer] streamChunks called from peer: {context.peer()}")
        
        try:
            for request in request_iterator:
                logger.info(f"[ğŸ” gRPCServer] Received request: sender_id={request.sender_id}, receiver_id={request.receiver_id}, chunk_type={request.chunk_type}, from peer: {context.peer()}")
                # Process control messages (HAVE, BITFIELD, REQUEST, CANCEL)
                if request.chunk_type in [gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL]:
                    # ğŸ”§ CRITICAL FIX: Only send REQUEST messages to the target receiver, not back to sender
                    if request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST:
                        # REQUEST messages should only go to the receiver (target peer), not be broadcast
                        converted_msg = self._convert_chunk_to_message(request)
                        # Only queue the message if it's meant for a specific receiver
                        self.msg_queue.append(converted_msg)
                        logger.info(f"[ğŸ¯ gRPCServer] Routing REQUEST from {request.sender_id} to {request.receiver_id}")
                    else:
                        # Other messages (HAVE, BITFIELD, CANCEL) can be processed normally
                        self.msg_queue.append(self._convert_chunk_to_message(request))
                    
                    # Send acknowledgment  
                    yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                        sender_id=request.sender_id,
                        receiver_id=request.receiver_id,
                        success=True,
                        response_type=gRPC_comm_manager_pb2.ChunkResponseType.CHUNK_ACK,
                        round_num=request.round_num,
                        chunk_id=request.chunk_id
                    )
        except Exception as e:
            logger.error(f"[gRPCServer] streamChunks error: {e}")
            yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                success=False,
                error_message=str(e)
            )
            
    def uploadChunks(self, request_iterator, context):
        """ğŸš€ ä¼˜åŒ–2ï¼šå¢å¼ºçš„åœ°ä¸‹ç®¡é“æ¨¡å¼ - æ°¸ä¸åœæ­¢çš„é«˜æ€§èƒ½chunkä¸Šä¼ å¤„ç†"""
        logger.debug("[ğŸ¯ gRPCServer] ğŸ“¤ Enhanced upload pipeline started - UNDERGROUND MODE")
        
        # ğŸš€ åœ°ä¸‹ç®¡é“æ€§èƒ½å‚æ•°
        successful_chunks = 0
        failed_chunks = 0
        error_messages = []
        processing_start_time = time.time()
        client_id = 0  # å°†ä»ç¬¬ä¸€ä¸ªè¯·æ±‚ä¸­è·å–
        
        # ğŸš€ æ€§èƒ½ç›‘æ§
        chunk_sizes = []
        processing_times = []
        last_performance_report = time.time()
        
        def enhanced_underground_processor():
            """ğŸš€ å¢å¼ºçš„åœ°ä¸‹ç®¡é“å¤„ç†å™¨ - é«˜æ€§èƒ½ã€æ°¸ä¸åœæ­¢ã€æ™ºèƒ½é”™è¯¯å¤„ç†"""
            nonlocal successful_chunks, failed_chunks, error_messages, chunk_sizes, processing_times, client_id, last_performance_report
            
            logger.debug("[ğŸ¯ gRPCServer] ğŸš‡ Enhanced underground pipeline started - PERFORMANCE MODE")
            
            # ğŸš€ åœ°ä¸‹ç®¡é“æ‰¹å¤„ç†ä¼˜åŒ–
            chunk_batch = []
            batch_size = 10  # æ‰¹å¤„ç†å¤§å°
            batch_timeout = 0.1  # 100msæ‰¹å¤„ç†è¶…æ—¶
            last_batch_time = time.time()
            
            try:
                for request in request_iterator:
                    request_start_time = time.time()
                    
                    # ğŸš€ è·å–client_idï¼ˆä»ç¬¬ä¸€ä¸ªè¯·æ±‚ä¸­ï¼‰
                    if client_id == 0 and request.sender_id:
                        client_id = request.sender_id
                        logger.info(f"[ğŸ¯ gRPCServer] ğŸ“¤ Client {client_id} connected to upload pipeline")
                    
                    # ğŸš€ å¿«é€Ÿè¯·æ±‚åˆ†ç±»å’Œå¤„ç†
                    if request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE:
                        chunk_size = len(request.chunk_data) if request.chunk_data else 0
                        logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ Processing CHUNK_PIECE - size={chunk_size}B, chunk={request.source_client_id}:{request.chunk_id}")
                        
                        try:
                            # ğŸš€ æ‰¹é‡è½¬æ¢ä¼˜åŒ– - æ”¶é›†åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
                            chunk_batch.append(request)
                            
                            # ğŸš€ æ™ºèƒ½æ‰¹å¤„ç†è§¦å‘æ¡ä»¶
                            current_time = time.time()
                            should_process_batch = (
                                len(chunk_batch) >= batch_size or  # æ‰¹å¤§å°è¾¾åˆ°
                                (current_time - last_batch_time) > batch_timeout or  # è¶…æ—¶
                                chunk_size > 1024 * 1024  # å¤§chunkç«‹å³å¤„ç†
                            )
                            
                            if should_process_batch:
                                # ğŸš€ æ‰¹é‡å¤„ç†chunk
                                batch_start_time = time.time()
                                for chunk_req in chunk_batch:
                                    converted_msg = self._convert_chunk_to_message(chunk_req)
                                    self.msg_queue.append(converted_msg)
                                    successful_chunks += 1
                                    
                                    # æ€§èƒ½ç»Ÿè®¡
                                    if chunk_req.chunk_data:
                                        chunk_sizes.append(len(chunk_req.chunk_data))
                                
                                batch_time = time.time() - batch_start_time
                                processing_times.append(batch_time)
                                
                                logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ Batch processed: {len(chunk_batch)} chunks in {batch_time:.3f}s")
                                
                                chunk_batch.clear()
                                last_batch_time = current_time
                                
                        except Exception as e:
                            failed_chunks += 1
                            error_msg = f"Chunk processing error: {e}"
                            error_messages.append(error_msg)
                            logger.error(f"[ğŸ¯ gRPCServer] ğŸš‡ {error_msg}")
                            
                    elif request.chunk_type in [
                        gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE,
                        gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD,
                        gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL
                    ]:
                        # ğŸš€ æ§åˆ¶æ¶ˆæ¯å¿«é€Ÿå¤„ç†é€šé“
                        logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ Processing control message - type={request.chunk_type}")
                        converted_msg = self._convert_chunk_to_message(request)
                        self.msg_queue.append(converted_msg)
                        successful_chunks += 1
                        
                    else:
                        # ğŸš€ å¿ƒè·³æ¶ˆæ¯å¤„ç†
                        if request.chunk_data == b'heartbeat':
                            logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ğŸ’“ Heartbeat received from client {request.sender_id}")
                        else:
                            failed_chunks += 1
                            error_msg = f"Unknown chunk type: {request.chunk_type}"
                            error_messages.append(error_msg)
                            logger.warning(f"[ğŸ¯ gRPCServer] ğŸš‡ {error_msg}")
                    
                    # ğŸš€ å¤„ç†æ—¶é—´ç›‘æ§
                    processing_time = time.time() - request_start_time
                    if processing_time > 0.05:  # è¶…è¿‡50msçš„æ…¢å¤„ç†
                        logger.warning(f"[ğŸ¯ gRPCServer] ğŸŒ Slow chunk processing: {processing_time:.3f}s")
                    
                    # ğŸš€ å®šæœŸæ€§èƒ½æŠ¥å‘Š
                    current_time = time.time()
                    if current_time - last_performance_report > 30.0:  # æ¯30ç§’æŠ¥å‘Š
                        if chunk_sizes:
                            avg_chunk_size = sum(chunk_sizes) / len(chunk_sizes)
                            avg_processing_time = sum(processing_times) / len(processing_times)
                            logger.info(f"[ğŸ¯ gRPCServer] ğŸ“Š Underground pipeline performance:")
                            logger.info(f"[ğŸ¯ gRPCServer] ğŸ“Š   {successful_chunks} chunks processed, {failed_chunks} failed")
                            logger.info(f"[ğŸ¯ gRPCServer] ğŸ“Š   Avg chunk size: {avg_chunk_size:.0f}B, processing time: {avg_processing_time:.3f}s")
                        last_performance_report = current_time
                
                # ğŸš€ å¤„ç†å‰©ä½™çš„æ‰¹å¤„ç†æ•°æ®
                if chunk_batch:
                    logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Processing final batch: {len(chunk_batch)} chunks")
                    for chunk_req in chunk_batch:
                        converted_msg = self._convert_chunk_to_message(chunk_req)
                        self.msg_queue.append(converted_msg)
                        successful_chunks += 1
                
                total_processing_time = time.time() - processing_start_time
                logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ Underground pipeline completed - total time: {total_processing_time:.3f}s")
                        
            except Exception as e:
                logger.error(f"[ğŸ¯ gRPCServer] ğŸš‡ Underground pipeline fatal error: {e}")
                failed_chunks += 1
                error_messages.append(str(e))
            finally:
                # ğŸš€ æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡
                total_time = time.time() - processing_start_time
                logger.debug(f"[ğŸ¯ gRPCServer] ğŸš‡ Underground pipeline finished:")
                logger.debug(f"[ğŸ¯ gRPCServer] ğŸ“Š   Success: {successful_chunks}, Failed: {failed_chunks}")
                logger.debug(f"[ğŸ¯ gRPCServer] ğŸ“Š   Total time: {total_time:.3f}s")
                if successful_chunks > 0:
                    logger.debug(f"[ğŸ¯ gRPCServer] ğŸ“Š   Throughput: {successful_chunks/total_time:.1f} chunks/sec")
        
        # ğŸ”§ FIX: ä½¿ç”¨å…±äº«åå°çº¿ç¨‹ï¼Œé¿å…ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºæ–°çº¿ç¨‹
        with self._processor_lock:
            self._active_uploads += 1
        
        # ğŸ”§ ç¡®ä¿åå°å¤„ç†çº¿ç¨‹å­˜åœ¨ï¼ˆæ‡’åŠ è½½ï¼‰
        self._ensure_background_processor()
        
        # ğŸš€ ç›´æ¥åœ¨å½“å‰çº¿ç¨‹å¤„ç†ï¼Œæˆ–å°†æ•°æ®ä¼ é€’ç»™åå°çº¿ç¨‹
        logger.debug(f"[ğŸ¯ gRPCServer] Processing upload request for client {client_id}")
        enhanced_underground_processor()
        
        # ğŸ”§ å¤„ç†å®Œæˆåå‡å°‘æ´»è·ƒè¿æ¥è®¡æ•°
        with self._processor_lock:
            self._active_uploads = max(0, self._active_uploads - 1)
        
        # ğŸš€ è¿”å›å¤„ç†ç»“æœ
        logger.debug("[ğŸ¯ gRPCServer] Upload processing completed")
        return gRPC_comm_manager_pb2.ChunkBatchResponse(
            client_id=client_id,
            successful_chunks=successful_chunks,
            failed_chunks=failed_chunks,
            error_messages=error_messages
        )
        
    def downloadChunks(self, request, context):
        """ğŸš€ æœåŠ¡ç«¯æµå¼RPC for batch chunk download"""
        logger.debug(f"[gRPCServer] downloadChunks method called for client {request.client_id}")
        
        try:
            # Convert batch request to individual message requests
            for chunk_req in request.chunk_requests:
                # Create chunk request message for compatibility
                chunk_request = gRPC_comm_manager_pb2.ChunkStreamRequest(
                    sender_id=request.sender_id,   
                    receiver_id=request.client_id,          
                    round_num=request.round_num,
                    source_client_id=chunk_req.source_client_id,
                    chunk_id=chunk_req.chunk_id,
                    chunk_type=gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
                    importance_score=chunk_req.importance_score
                )
                
                # Add to message queue for traditional BitTorrent compatibility
                self.msg_queue.append(self._convert_chunk_to_message(chunk_request))
                
                # ğŸš€ å¢å¼ºé”™è¯¯å¤„ç†ï¼šæ£€æŸ¥chunk_managerå¹¶è·å–chunkæ•°æ®
                chunk_data = None
                error_message = None
                
                if not hasattr(self, 'chunk_manager') or self.chunk_manager is None:
                    error_message = "Chunk manager not initialized on server"
                    logger.error(f"[gRPCServer] ğŸš« {error_message} for chunk {chunk_req.source_client_id}:{chunk_req.chunk_id}")
                else:
                    try:
                        chunk_data = self.chunk_manager.get_chunk_data(request.round_num, chunk_req.source_client_id, chunk_req.chunk_id)
                        logger.debug(f"[gRPCServer] ğŸ“¥ Chunk lookup: round={request.round_num}, source={chunk_req.source_client_id}, chunk={chunk_req.chunk_id}, found={chunk_data is not None}")
                        
                        if chunk_data is None:
                            error_message = f"Chunk {chunk_req.source_client_id}:{chunk_req.chunk_id} not found in storage"
                            
                    except Exception as e:
                        error_message = f"Error accessing chunk data: {str(e)}"
                        logger.error(f"[gRPCServer] ğŸš« Exception during chunk lookup: {e}")
                
                # ğŸš€ ç»Ÿä¸€é”™è¯¯å“åº”å¤„ç†
                if error_message:
                    logger.warning(f"[gRPCServer] ğŸ“¤ Sending NACK for chunk {chunk_req.source_client_id}:{chunk_req.chunk_id}: {error_message}")
                    yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                        sender_id=chunk_req.source_client_id,
                        receiver_id=request.client_id,
                        success=False,
                        response_type=gRPC_comm_manager_pb2.ChunkResponseType.CHUNK_NACK,
                        round_num=request.round_num,
                        chunk_id=chunk_req.chunk_id,
                        error_message=error_message
                    )
                    continue
                
                # ğŸš€ æˆåŠŸå“åº”ï¼šè¿”å›å®é™…chunkæ•°æ®
                logger.info(f"[gRPCServer] ğŸ“¤ Sending chunk data for {chunk_req.source_client_id}:{chunk_req.chunk_id} to client {request.client_id}")
                
                serialized_data = pickle.dumps(chunk_data)
                checksum = hashlib.sha256(serialized_data).hexdigest()
                data_size = len(serialized_data)
                
                logger.debug(f"[gRPCServer] ğŸ“¤ Chunk data prepared: size={data_size}B, checksum={checksum[:8]}...")
                
                yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                    sender_id=chunk_req.source_client_id,
                    receiver_id=request.client_id,
                    success=True,
                    response_type=gRPC_comm_manager_pb2.ChunkResponseType.CHUNK_ACK,
                    round_num=request.round_num,
                    chunk_id=chunk_req.chunk_id,
                    response_data=serialized_data
                )
                
        except Exception as e:
            logger.error(f"[gRPCServer] downloadChunks error: {e}")
            yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                success=False,
                error_message=str(e)
            )
            
    def _convert_chunk_to_message(self, chunk_request):
        """ğŸ”§ Convert chunk stream request to traditional message format for compatibility"""
        # This is a compatibility bridge - convert streaming chunk requests 
        # back to the traditional message format that the existing system expects
        
        if chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE:
            # ğŸš€ CRITICAL FIX: æ­£ç¡®åˆ›å»ºpieceæ¶ˆæ¯ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„chunkæ•°æ®
            from federatedscope.core.message import ChunkData
            
            
            # åˆ›å»ºChunkDataåŒ…è£…å™¨
            chunk_wrapper = ChunkData(chunk_request.chunk_data, chunk_request.checksum)
            
            # åˆ›å»ºå®Œæ•´çš„protobufæ¶ˆæ¯ï¼ŒåŒ…å«æ‰€æœ‰pieceæ•°æ®
            message_request = gRPC_comm_manager_pb2.MessageRequest()
            
            # è®¾ç½®æ¶ˆæ¯å†…å®¹ - æ¨¡æ‹Ÿä¼ ç»Ÿpieceæ¶ˆæ¯çš„ç»“æ„
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ„é€ æ¶ˆæ¯å†…å®¹ï¼Œå°±åƒ_send_pieceä¸­çš„ä¼ ç»Ÿæ¶ˆæ¯ä¸€æ ·
            from federatedscope.core.message import Message
            
            # åˆ›å»ºä¼ ç»Ÿæ ¼å¼çš„Messageå¯¹è±¡
            traditional_msg = Message(
                msg_type='piece',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id,
                    'data': chunk_wrapper,  # ChunkDataå¯¹è±¡ï¼ŒåŒ…å«åŸå§‹bytes
                    'checksum': chunk_request.checksum
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Created traditional message: type={traditional_msg.msg_type}, sender={traditional_msg.sender}")
            logger.info(f"[ğŸ”§ gRPCServer] Message content keys: {list(traditional_msg.content.keys())}")
            
            # å°†Messageå¯¹è±¡è½¬æ¢ä¸ºprotobufæ ¼å¼
            message_request = traditional_msg.transform(to_list=True)
            
            logger.info(f"[ğŸ”§ gRPCServer] Successfully converted CHUNK_PIECE to MessageRequest")
            return message_request
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST:
            # å¤„ç†requestæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='request',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id
                }
            )
            
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE:
            # ğŸš€ å¤„ç†haveæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='have',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id,
                    'importance_score': chunk_request.importance_score
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_HAVE to traditional message format")
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD:
            # ğŸš€ å¤„ç†bitfieldæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            # è§£ç bitfieldæ•°æ®
            bitfield_data = []
            if chunk_request.chunk_data:
                try:
                    bitfield_data = json.loads(chunk_request.chunk_data.decode('utf-8'))
                except Exception as e:
                    logger.error(f"[ğŸ”§ gRPCServer] Failed to decode bitfield data: {e}")
            
            traditional_msg = Message(
                msg_type='bitfield',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'bitfield': bitfield_data
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_BITFIELD to traditional message format, chunks: {len(bitfield_data)}")
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL:
            # ğŸš€ å¤„ç†cancelæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='cancel',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_CANCEL to traditional message format")
            return traditional_msg.transform(to_list=True)
            
        else:
            logger.warning(f"[ğŸ”§ gRPCServer] Unknown chunk_type: {chunk_request.chunk_type}")
            # è¿”å›ç©ºçš„MessageRequestä½œä¸ºfallback
            return gRPC_comm_manager_pb2.MessageRequest()

    def receive(self):
        while len(self.msg_queue) == 0:
            continue
        msg = self.msg_queue.popleft()
        return msg
