import queue
import logging
from collections import deque

from federatedscope.core.proto import gRPC_comm_manager_pb2, \
    gRPC_comm_manager_pb2_grpc

logger = logging.getLogger(__name__)


class gRPCComServeFunc(gRPC_comm_manager_pb2_grpc.gRPCComServeFuncServicer):
    def __init__(self):
        self.msg_queue = deque()
        # ğŸš€ Streaming queues for chunk transfer
        self.chunk_stream_queues = {}  # {client_id: deque()}
        
    def sendMessage(self, request, context):
        self.msg_queue.append(request)
        return gRPC_comm_manager_pb2.MessageResponse(msg='ACK')
        
    def streamChunks(self, request_iterator, context):
        """ğŸš€ åŒå‘streaming RPC for chunk control messages"""
        logger.debug("[gRPCServer] streamChunks method called")
        
        try:
            for request in request_iterator:
                # Process control messages (HAVE, BITFIELD, REQUEST, CANCEL)
                if request.chunk_type in [gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
                                         gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL]:
                    # ğŸ”§ CRITICAL FIX: Only send REQUEST messages to the target receiver, not back to sender
                    if request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST:
                        # REQUEST messages should only go to the receiver (target peer), not be broadcast
                        converted_msg = self._convert_chunk_to_message(request)
                        # Only queue the message if it's meant for a specific receiver
                        self.msg_queue.append(converted_msg)
                        logger.info(f"[ğŸ¯ gRPCServer] Routing REQUEST from {request.sender_id} to {request.receiver_id}")
                    else:
                        # Other messages (HAVE, BITFIELD, CANCEL) can be processed normally
                        self.msg_queue.append(self._convert_chunk_to_message(request))
                    
                    # Send acknowledgment  
                    yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                        sender_id=request.sender_id,
                        receiver_id=request.receiver_id,
                        success=True,
                        response_type=gRPC_comm_manager_pb2.ChunkResponseType.CHUNK_ACK,
                        round_num=request.round_num,
                        chunk_id=request.chunk_id
                    )
        except Exception as e:
            logger.error(f"[gRPCServer] streamChunks error: {e}")
            yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                success=False,
                error_message=str(e)
            )
            
    def uploadChunks(self, request_iterator, context):
        """ğŸš€ å®¢æˆ·ç«¯æµå¼RPC for chunk data upload - åœ°ä¸‹ç®¡é“æ¨¡å¼ï¼šåå°æŒç»­å¤„ç†"""
        logger.info("[ğŸ¯ gRPCServer] uploadChunks method called - STREAMING CHUNK UPLOAD started")
        
        successful_chunks = 0
        failed_chunks = 0
        error_messages = []
        
        # ç”¨äºä¼ é€’å¤„ç†ç»“æœçš„é˜Ÿåˆ—
        import threading
        import queue
        result_queue = queue.Queue()
        
        def underground_pipeline_processor():
            """ğŸš€ åœ°ä¸‹ç®¡é“å¤„ç†å™¨ï¼šæ°¸è¿œå¾ªç¯ï¼Œä¸é€€å‡ºï¼ŒæŒç»­ç­‰å¾…æ•°æ®"""
            nonlocal successful_chunks, failed_chunks, error_messages
            
            logger.info("[ğŸ¯ gRPCServer] ğŸš‡ Underground pipeline started - waiting for data forever")
            
            try:
                # ğŸ”§ CRITICAL FIX: ä½¿ç”¨æ°¸è¿œå¾ªç¯çš„åœ°ä¸‹ç®¡é“æ¨¡å¼
                for request in request_iterator:
                    logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Pipeline received streaming request - chunk_type={request.chunk_type}")
                    logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Request details - sender={request.sender_id}, round={request.round_num}, source={request.source_client_id}, chunk={request.chunk_id}")
                    
                    # Process chunk data uploads
                    if request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE:
                        logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Processing CHUNK_PIECE data - size={len(request.chunk_data) if request.chunk_data else 0}")
                        
                        # Convert to traditional message format for compatibility
                        converted_msg = self._convert_chunk_to_message(request)
                        self.msg_queue.append(converted_msg)
                        successful_chunks += 1
                        
                        logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Successfully processed chunk upload: {request.source_client_id}:{request.chunk_id}")
                        logger.info(f"[ğŸ¯ gRPCServer] ğŸš‡ Added to msg_queue, queue size now: {len(self.msg_queue)}")
                    else:
                        failed_chunks += 1
                        error_msg = f"Invalid chunk type for upload: {request.chunk_type}"
                        error_messages.append(error_msg)
                        logger.warning(f"[ğŸ¯ gRPCServer] ğŸš‡ {error_msg}")
                        
                # ğŸš‡ åªæœ‰å½“å®¢æˆ·ç«¯å…³é—­è¿æ¥æ—¶ï¼Œforå¾ªç¯æ‰ä¼šç»“æŸ
                logger.info("[ğŸ¯ gRPCServer] ğŸš‡ Client closed connection - pipeline ending")
                        
            except Exception as e:
                logger.error(f"[ğŸ¯ gRPCServer] ğŸš‡ Pipeline processing error: {e}")
                failed_chunks += 1
                error_messages.append(str(e))
            finally:
                # é€šçŸ¥ä¸»çº¿ç¨‹å¤„ç†å®Œæˆ
                result_queue.put({
                    'successful_chunks': successful_chunks,
                    'failed_chunks': failed_chunks,
                    'error_messages': error_messages
                })
                logger.info("[ğŸ¯ gRPCServer] ğŸš‡ Underground pipeline completed")
        
        # å¯åŠ¨åœ°ä¸‹ç®¡é“å¤„ç†å™¨
        pipeline_thread = threading.Thread(
            target=underground_pipeline_processor,
            daemon=True,
            name="UndergroundPipeline"
        )
        pipeline_thread.start()
        logger.info("[ğŸ¯ gRPCServer] ğŸš‡ Started underground pipeline processor")
        
        # ç«‹å³è¿”å›å“åº”ï¼Œåœ°ä¸‹ç®¡é“ç»§ç»­è¿è¡Œ
        logger.info("[ğŸ¯ gRPCServer] Returning immediate response - underground pipeline active")
        return gRPC_comm_manager_pb2.ChunkBatchResponse(
            client_id=0,
            successful_chunks=0,
            failed_chunks=0,
            error_messages=["Underground pipeline active"]
        )
        
    def downloadChunks(self, request, context):
        """ğŸš€ æœåŠ¡ç«¯æµå¼RPC for batch chunk download"""
        logger.debug(f"[gRPCServer] downloadChunks method called for client {request.client_id}")
        
        try:
            # Convert batch request to individual message requests
            for chunk_req in request.chunk_requests:
                # Create chunk request message for compatibility
                chunk_request = gRPC_comm_manager_pb2.ChunkStreamRequest(
                    sender_id=chunk_req.source_client_id,    # ğŸ”§ FIX: æ‹¥æœ‰chunkçš„å®¢æˆ·ç«¯ä½œä¸ºå‘é€æ–¹
                    receiver_id=request.client_id,           # ğŸ”§ FIX: è¯·æ±‚chunkçš„å®¢æˆ·ç«¯ä½œä¸ºæ¥æ”¶æ–¹
                    round_num=request.round_num,
                    source_client_id=chunk_req.source_client_id,
                    chunk_id=chunk_req.chunk_id,
                    chunk_type=gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST,
                    importance_score=chunk_req.importance_score
                )
                
                # Add to message queue
                self.msg_queue.append(self._convert_chunk_to_message(chunk_request))
                
                # Send acknowledgment (could be enhanced to send actual chunk data)
                yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                    sender_id=chunk_req.source_client_id,    # æ‹¥æœ‰chunkçš„å®¢æˆ·ç«¯ä½œä¸ºå“åº”å‘é€æ–¹
                    receiver_id=request.client_id,           # è¯·æ±‚å®¢æˆ·ç«¯ä½œä¸ºå“åº”æ¥æ”¶æ–¹
                    success=True,
                    response_type=gRPC_comm_manager_pb2.ChunkResponseType.CHUNK_ACK,
                    round_num=request.round_num,
                    chunk_id=chunk_req.chunk_id
                )
                
        except Exception as e:
            logger.error(f"[gRPCServer] downloadChunks error: {e}")
            yield gRPC_comm_manager_pb2.ChunkStreamResponse(
                success=False,
                error_message=str(e)
            )
            
    def _convert_chunk_to_message(self, chunk_request):
        """ğŸ”§ Convert chunk stream request to traditional message format for compatibility"""
        # This is a compatibility bridge - convert streaming chunk requests 
        # back to the traditional message format that the existing system expects
        
        if chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_PIECE:
            # ğŸš€ CRITICAL FIX: æ­£ç¡®åˆ›å»ºpieceæ¶ˆæ¯ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„chunkæ•°æ®
            from federatedscope.core.message import ChunkData
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_PIECE to traditional message format")
            logger.info(f"[ğŸ”§ gRPCServer] Original chunk data size: {len(chunk_request.chunk_data) if chunk_request.chunk_data else 0}")
            
            # åˆ›å»ºChunkDataåŒ…è£…å™¨
            chunk_wrapper = ChunkData(chunk_request.chunk_data, chunk_request.checksum)
            
            # åˆ›å»ºå®Œæ•´çš„protobufæ¶ˆæ¯ï¼ŒåŒ…å«æ‰€æœ‰pieceæ•°æ®
            message_request = gRPC_comm_manager_pb2.MessageRequest()
            
            # è®¾ç½®æ¶ˆæ¯å†…å®¹ - æ¨¡æ‹Ÿä¼ ç»Ÿpieceæ¶ˆæ¯çš„ç»“æ„
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ„é€ æ¶ˆæ¯å†…å®¹ï¼Œå°±åƒ_send_pieceä¸­çš„ä¼ ç»Ÿæ¶ˆæ¯ä¸€æ ·
            from federatedscope.core.message import Message
            
            # åˆ›å»ºä¼ ç»Ÿæ ¼å¼çš„Messageå¯¹è±¡
            traditional_msg = Message(
                msg_type='piece',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id,
                    'data': chunk_wrapper,  # ChunkDataå¯¹è±¡ï¼ŒåŒ…å«åŸå§‹bytes
                    'checksum': chunk_request.checksum
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Created traditional message: type={traditional_msg.msg_type}, sender={traditional_msg.sender}")
            logger.info(f"[ğŸ”§ gRPCServer] Message content keys: {list(traditional_msg.content.keys())}")
            
            # å°†Messageå¯¹è±¡è½¬æ¢ä¸ºprotobufæ ¼å¼
            message_request = traditional_msg.transform(to_list=True)
            
            logger.info(f"[ğŸ”§ gRPCServer] Successfully converted CHUNK_PIECE to MessageRequest")
            return message_request
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_REQUEST:
            # å¤„ç†requestæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='request',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id
                }
            )
            
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_HAVE:
            # ğŸš€ å¤„ç†haveæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='have',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id,
                    'importance_score': chunk_request.importance_score
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_HAVE to traditional message format")
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_BITFIELD:
            # ğŸš€ å¤„ç†bitfieldæ¶ˆæ¯
            from federatedscope.core.message import Message
            import json
            
            # è§£ç bitfieldæ•°æ®
            bitfield_data = []
            if chunk_request.chunk_data:
                try:
                    bitfield_data = json.loads(chunk_request.chunk_data.decode('utf-8'))
                except Exception as e:
                    logger.error(f"[ğŸ”§ gRPCServer] Failed to decode bitfield data: {e}")
            
            traditional_msg = Message(
                msg_type='bitfield',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'bitfield': bitfield_data
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_BITFIELD to traditional message format, chunks: {len(bitfield_data)}")
            return traditional_msg.transform(to_list=True)
            
        elif chunk_request.chunk_type == gRPC_comm_manager_pb2.ChunkType.CHUNK_CANCEL:
            # ğŸš€ å¤„ç†cancelæ¶ˆæ¯
            from federatedscope.core.message import Message
            
            traditional_msg = Message(
                msg_type='cancel',
                sender=chunk_request.sender_id,
                receiver=[chunk_request.receiver_id],
                state=chunk_request.round_num,
                content={
                    'round_num': chunk_request.round_num,
                    'source_client_id': chunk_request.source_client_id,
                    'chunk_id': chunk_request.chunk_id
                }
            )
            
            logger.info(f"[ğŸ”§ gRPCServer] Converting CHUNK_CANCEL to traditional message format")
            return traditional_msg.transform(to_list=True)
            
        else:
            logger.warning(f"[ğŸ”§ gRPCServer] Unknown chunk_type: {chunk_request.chunk_type}")
            # è¿”å›ç©ºçš„MessageRequestä½œä¸ºfallback
            return gRPC_comm_manager_pb2.MessageRequest()

    def receive(self):
        while len(self.msg_queue) == 0:
            continue
        msg = self.msg_queue.popleft()
        return msg
