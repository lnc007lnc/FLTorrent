#!/usr/bin/env python3
"""
Ray FederatedScope Test Script
=============================

ç®€åŒ–çš„æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯Rayç‰ˆæœ¬çš„FederatedScopeæ˜¯å¦å·¥ä½œæ­£å¸¸
"""

import os
import sys
import time
import subprocess
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥Rayå’Œå…¶ä»–ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    try:
        import ray
        logger.info(f"âœ… Rayç‰ˆæœ¬: {ray.__version__}")
    except ImportError:
        logger.error("âŒ Rayæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install ray")
        return False
    
    try:
        import torch
        logger.info(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        gpu_count = torch.cuda.device_count() if torch.cuda.is_available() else 0
        logger.info(f"ğŸ¯ å¯ç”¨GPUæ•°é‡: {gpu_count}")
    except ImportError:
        logger.warning("âš ï¸ PyTorchæœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨CPU")
    
    return True

def test_basic_ray_functionality():
    """æµ‹è¯•RayåŸºæœ¬åŠŸèƒ½"""
    import ray
    
    # åˆå§‹åŒ–Ray
    ray.init(ignore_reinit_error=True)
    
    @ray.remote
    def test_function(x):
        return x * 2
    
    # æµ‹è¯•è¿œç¨‹å‡½æ•°
    result = ray.get(test_function.remote(21))
    assert result == 42, f"Rayæµ‹è¯•å¤±è´¥: {result} != 42"
    
    # æ˜¾ç¤ºé›†ç¾¤èµ„æº
    resources = ray.cluster_resources()
    logger.info(f"ğŸ“Š Rayé›†ç¾¤èµ„æº: {dict(resources)}")
    
    ray.shutdown()
    logger.info("âœ… RayåŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def prepare_test_configs():
    """å‡†å¤‡æµ‹è¯•é…ç½®æ–‡ä»¶"""
    config_dir = "multi_process_test_v2/configs"
    
    if not os.path.exists(config_dir):
        logger.warning(f"âš ï¸ é…ç½®ç›®å½•ä¸å­˜åœ¨: {config_dir}")
        logger.info("ğŸ”§ å°è¯•è¿è¡ŒåŸå§‹è„šæœ¬åˆ›å»ºé…ç½®...")
        
        # è¿è¡ŒåŸå§‹è„šæœ¬æ¥åˆ›å»ºé…ç½®
        try:
            result = subprocess.run(['bash', 'multi_process_fl_test_v2.sh'], 
                                  capture_output=True, text=True, timeout=30)
            if os.path.exists(config_dir):
                logger.info("âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º")
                # ç«‹å³åœæ­¢åŸå§‹è„šæœ¬å¯åŠ¨çš„è¿›ç¨‹
                subprocess.run(['pkill', '-f', 'python.*federatedscope'], check=False)
                time.sleep(2)
                return True
            else:
                logger.error("âŒ é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥")
                return False
        except subprocess.TimeoutExpired:
            logger.info("âœ… é…ç½®åˆ›å»ºè¶…æ—¶ä½†å¯èƒ½å·²æˆåŠŸ")
            subprocess.run(['pkill', '-f', 'python.*federatedscope'], check=False)
            return os.path.exists(config_dir)
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºé…ç½®å¤±è´¥: {e}")
            return False
    else:
        logger.info("âœ… é…ç½®ç›®å½•å·²å­˜åœ¨")
        return True

def test_ray_federated_learning():
    """æµ‹è¯•Rayç‰ˆæœ¬çš„è”é‚¦å­¦ä¹ """
    from ray_distributed_fl import RayFederatedLearning
    
    logger.info("ğŸš€ å¼€å§‹Rayè”é‚¦å­¦ä¹ æµ‹è¯•...")
    
    # åˆ›å»ºRay FLå®ä¾‹
    ray_fl = RayFederatedLearning()
    
    try:
        # åˆå§‹åŒ–Rayé›†ç¾¤ï¼ˆæœ¬åœ°æ¨¡å¼ï¼Œ2GPUï¼‰
        ray_fl.initialize_ray_cluster(num_cpus=4, num_gpus=2)
        
        # æ˜¾ç¤ºé›†ç¾¤ä¿¡æ¯
        cluster_info = ray_fl.get_cluster_info()
        logger.info(f"ğŸŒ é›†ç¾¤ä¿¡æ¯: {cluster_info['total_resources']}")
        
        # å¯åŠ¨å°è§„æ¨¡æµ‹è¯•ï¼ˆ2å®¢æˆ·ç«¯ï¼Œ1è½®æ¬¡ï¼Œ2åˆ†é’Ÿç›‘æ§ï¼‰
        logger.info("ğŸ§ª å¯åŠ¨å°è§„æ¨¡æµ‹è¯•...")
        ray_fl.start_federated_learning(
            num_clients=2,
            total_rounds=1,
            monitor_duration=120  # 2åˆ†é’Ÿæµ‹è¯•
        )
        
        logger.info("âœ… Rayè”é‚¦å­¦ä¹ æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ Rayè”é‚¦å­¦ä¹ æµ‹è¯•å¤±è´¥: {e}")
    finally:
        ray_fl.stop_all()
        import ray
        ray.shutdown()

def quick_performance_comparison():
    """å¿«é€Ÿæ€§èƒ½å¯¹æ¯”ï¼šä¼ ç»Ÿå¤šè¿›ç¨‹ vs Ray"""
    logger.info("ğŸ“Š å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    
    # 1. Rayç‰ˆæœ¬æµ‹è¯•
    ray_start_time = time.time()
    try:
        test_ray_federated_learning()
        ray_duration = time.time() - ray_start_time
        logger.info(f"âš¡ Rayç‰ˆæœ¬è€—æ—¶: {ray_duration:.2f}ç§’")
    except Exception as e:
        logger.error(f"âŒ Rayç‰ˆæœ¬æµ‹è¯•å¤±è´¥: {e}")
        ray_duration = float('inf')
    
    # 2. ä¼ ç»Ÿç‰ˆæœ¬æµ‹è¯•ï¼ˆç®€åŒ–ï¼‰
    logger.info("ğŸ”„ ä¼ ç»Ÿå¤šè¿›ç¨‹ç‰ˆæœ¬æµ‹è¯•å·²è·³è¿‡ï¼ˆé¿å…å†²çªï¼‰")
    
    # ç»“æœå¯¹æ¯”
    logger.info("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    logger.info(f"   Rayç‰ˆæœ¬: {ray_duration:.2f}ç§’")
    logger.info("   ä¼ ç»Ÿç‰ˆæœ¬: è·³è¿‡")
    
    if ray_duration < float('inf'):
        logger.info("âœ… Rayç‰ˆæœ¬æµ‹è¯•æˆåŠŸå®Œæˆ")
    
def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Ray FederatedScope æµ‹è¯•")
    print("=" * 40)
    
    # 1. æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    # 2. æµ‹è¯•RayåŸºæœ¬åŠŸèƒ½
    try:
        test_basic_ray_functionality()
    except Exception as e:
        logger.error(f"âŒ RayåŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return
    
    # 3. å‡†å¤‡æµ‹è¯•é…ç½®
    if not prepare_test_configs():
        logger.error("âŒ æ— æ³•å‡†å¤‡æµ‹è¯•é…ç½®ï¼Œè·³è¿‡è”é‚¦å­¦ä¹ æµ‹è¯•")
        return
    
    # 4. æµ‹è¯•Rayè”é‚¦å­¦ä¹ 
    quick_performance_comparison()
    
    print("\nğŸ‰ Ray FederatedScope æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()