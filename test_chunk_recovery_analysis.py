#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æchunkæ¢å¤æµ‹è¯•ç»“æœ
é‡ç‚¹å…³æ³¨BatchNormå±‚çš„bufferé—®é¢˜
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from federatedscope.core.chunk_manager import ChunkManager
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SimpleModel(nn.Module):
    """ä¸åŒ…å«BatchNormçš„ç®€å•æ¨¡å‹"""
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(100, 50)
        self.fc2 = nn.Linear(50, 20)
        self.fc3 = nn.Linear(20, 1)
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x


class ModelWithBN(nn.Module):
    """åŒ…å«BatchNormçš„æ¨¡å‹"""
    def __init__(self):
        super(ModelWithBN, self).__init__()
        self.fc1 = nn.Linear(100, 50)
        self.bn1 = nn.BatchNorm1d(50)
        self.fc2 = nn.Linear(50, 20)
        self.bn2 = nn.BatchNorm1d(20)
        self.fc3 = nn.Linear(20, 1)
        
    def forward(self, x):
        x = torch.relu(self.bn1(self.fc1(x)))
        x = torch.relu(self.bn2(self.fc2(x)))
        x = self.fc3(x)
        return x


def test_simple_model_recovery():
    """æµ‹è¯•ç®€å•æ¨¡å‹ï¼ˆæ— BatchNormï¼‰çš„æ¢å¤"""
    print("ğŸ§ª æµ‹è¯•ç®€å•æ¨¡å‹æ¢å¤ï¼ˆæ— BatchNormï¼‰...")
    print("=" * 60)
    
    try:
        # åˆ›å»ºç®€å•æ¨¡å‹
        original_model = SimpleModel()
        torch.manual_seed(42)
        with torch.no_grad():
            for param in original_model.parameters():
                param.data.normal_(0, 0.1)
        
        chunk_manager = ChunkManager(client_id=400)
        
        # æµ‹è¯•ä¸åŒchunkæ•°é‡
        for num_chunks in [2, 4, 8]:
            print(f"\n--- æµ‹è¯• {num_chunks} ä¸ªchunks ---")
            
            # ä¿å­˜chunks
            saved_hashes = chunk_manager.save_model_chunks(
                model=original_model,
                round_num=num_chunks,
                num_chunks=num_chunks
            )
            
            # æ¢å¤æ¨¡å‹
            recovered_model = SimpleModel()
            success = chunk_manager.reconstruct_model_from_chunks(
                round_num=num_chunks,
                target_model=recovered_model
            )
            
            if not success:
                print(f"âŒ {num_chunks} chunksæ¢å¤å¤±è´¥")
                continue
            
            # æ¯”è¾ƒå‚æ•°
            original_params = ChunkManager.model_to_params(original_model)
            recovered_params = ChunkManager.model_to_params(recovered_model)
            
            perfect_match = True
            for name in original_params:
                diff = np.abs(original_params[name] - recovered_params[name]).max()
                if diff > 1e-8:
                    print(f"âŒ å‚æ•° {name} å·®å¼‚: {diff:.2e}")
                    perfect_match = False
            
            if perfect_match:
                print(f"âœ… {num_chunks} chunkså®Œç¾æ¢å¤")
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            test_input = torch.randn(10, 100)
            with torch.no_grad():
                original_output = original_model(test_input)
                recovered_output = recovered_model(test_input)
                output_diff = torch.abs(original_output - recovered_output).max().item()
                
                if output_diff < 1e-6:
                    print(f"âœ… å‰å‘ä¼ æ’­å®Œå…¨ä¸€è‡´ (diff: {output_diff:.2e})")
                else:
                    print(f"âŒ å‰å‘ä¼ æ’­æœ‰å·®å¼‚ (diff: {output_diff:.2e})")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç®€å•æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def analyze_batchnorm_issue():
    """åˆ†æBatchNormå±‚çš„bufferé—®é¢˜"""
    print("\nğŸ” åˆ†æBatchNorm Bufferé—®é¢˜...")
    print("=" * 60)
    
    try:
        # åˆ›å»ºåŒ…å«BatchNormçš„æ¨¡å‹
        model = ModelWithBN()
        torch.manual_seed(123)
        
        # æ˜¾ç¤ºæ¨¡å‹çš„æ‰€æœ‰å‚æ•°å’Œç¼“å†²åŒº
        print("ğŸ“Š æ¨¡å‹å‚æ•°å’ŒBuffer:")
        for name, param in model.named_parameters():
            print(f"   å‚æ•°: {name} - {param.shape} (requires_grad: {param.requires_grad})")
        
        for name, buffer in model.named_buffers():
            print(f"   Buffer: {name} - {buffer.shape} (requires_grad: False)")
        
        # ä½¿ç”¨ChunkManagerè½¬æ¢
        params = ChunkManager.model_to_params(model)
        print(f"\nğŸ“‹ ChunkManageræ•è·çš„å‚æ•°:")
        for name, array in params.items():
            print(f"   {name}: {array.shape} - ç±»å‹: {array.dtype}")
        
        # æ¨¡æ‹Ÿè®­ç»ƒå‡ ä¸ªstepæ¥æ”¹å˜BatchNormçš„running stats
        model.train()
        for i in range(5):
            dummy_input = torch.randn(16, 100)
            output = model(dummy_input)
            print(f"   è®­ç»ƒæ­¥éª¤ {i+1}: running_meanå˜åŒ–")
        
        print(f"\nğŸ“Š è®­ç»ƒåçš„BatchNormçŠ¶æ€:")
        for name, buffer in model.named_buffers():
            print(f"   {name}: {buffer.data}")
        
        # ä¿å­˜å’Œæ¢å¤
        chunk_manager = ChunkManager(client_id=500)
        saved_hashes = chunk_manager.save_model_chunks(model, round_num=1, num_chunks=3)
        
        # åˆ›å»ºæ–°æ¨¡å‹å¹¶æ¢å¤
        new_model = ModelWithBN()
        success = chunk_manager.reconstruct_model_from_chunks(round_num=1, target_model=new_model)
        
        print(f"\nğŸ”„ æ¢å¤åçš„BatchNormçŠ¶æ€:")
        for name, buffer in new_model.named_buffers():
            print(f"   {name}: {buffer.data}")
        
        # æ¯”è¾ƒå·®å¼‚
        print(f"\nğŸ“Š Bufferå·®å¼‚åˆ†æ:")
        for name, buffer in model.named_buffers():
            original_buffer = buffer.data.numpy()
            recovered_buffer = dict(new_model.named_buffers())[name].data.numpy()
            diff = np.abs(original_buffer - recovered_buffer).max()
            print(f"   {name}: max_diff = {diff:.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ BatchNormåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_parameters_only_recovery():
    """æµ‹è¯•åªæ¢å¤å¯è®­ç»ƒå‚æ•°ï¼ˆå¿½ç•¥buffersï¼‰"""
    print("\nğŸ¯ æµ‹è¯•åªæ¢å¤å¯è®­ç»ƒå‚æ•°...")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        original_model = ModelWithBN()
        torch.manual_seed(456)
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ”¹å˜BatchNormçŠ¶æ€
        original_model.train()
        for _ in range(3):
            dummy_input = torch.randn(8, 100)
            _ = original_model(dummy_input)
        
        # åªä¿å­˜å¯è®­ç»ƒå‚æ•°
        trainable_params = {name: param.data.cpu().numpy() 
                          for name, param in original_model.named_parameters() 
                          if param.requires_grad}
        
        print(f"ğŸ“Š å¯è®­ç»ƒå‚æ•°æ•°é‡: {len(trainable_params)}")
        for name in trainable_params:
            print(f"   {name}")
        
        # ä½¿ç”¨ChunkManagerä¿å­˜
        chunk_manager = ChunkManager(client_id=600)
        saved_hashes = chunk_manager.save_model_chunks(original_model, round_num=1, num_chunks=4)
        
        # æ¢å¤åˆ°æ–°æ¨¡å‹
        recovered_model = ModelWithBN()
        success = chunk_manager.reconstruct_model_from_chunks(round_num=1, target_model=recovered_model)
        
        if not success:
            print("âŒ æ¢å¤å¤±è´¥")
            return False
        
        # åªæ¯”è¾ƒå¯è®­ç»ƒå‚æ•°
        print(f"\nğŸ” æ¯”è¾ƒå¯è®­ç»ƒå‚æ•°:")
        all_match = True
        for name, param in original_model.named_parameters():
            if param.requires_grad:
                original_param = param.data.numpy()
                recovered_param = dict(recovered_model.named_parameters())[name].data.numpy()
                diff = np.abs(original_param - recovered_param).max()
                
                if diff < 1e-8:
                    print(f"âœ… {name}: å®Œå…¨åŒ¹é…")
                else:
                    print(f"âŒ {name}: diff = {diff:.2e}")
                    all_match = False
        
        if all_match:
            print("âœ… æ‰€æœ‰å¯è®­ç»ƒå‚æ•°å®Œç¾æ¢å¤!")
        
        return all_match
        
    except Exception as e:
        print(f"âŒ å¯è®­ç»ƒå‚æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰åˆ†ææµ‹è¯•"""
    print("ğŸ”¬ Chunkæ¢å¤è¯¦ç»†åˆ†æ")
    print("=" * 80)
    
    tests = [
        ("ç®€å•æ¨¡å‹æ¢å¤", test_simple_model_recovery),
        ("BatchNormé—®é¢˜åˆ†æ", analyze_batchnorm_issue),
        ("åªæ¢å¤å¯è®­ç»ƒå‚æ•°", test_parameters_only_recovery)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª {test_name}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ åˆ†æç»“æœæ€»ç»“:")
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    print("\nğŸ’¡ ç»“è®º:")
    print("   1. æ¨¡å‹çš„å¯è®­ç»ƒå‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰å¯ä»¥å®Œç¾æ¢å¤")
    print("   2. BatchNormçš„running_mean/running_var/num_batches_trackedæ˜¯ä¸å¯è®­ç»ƒçš„buffer")
    print("   3. è¿™äº›bufferåœ¨æ¯æ¬¡å‰å‘ä¼ æ’­æ—¶ä¼šæ›´æ–°ï¼Œå¯¼è‡´å·®å¼‚")
    print("   4. å¯¹äºè”é‚¦å­¦ä¹ ï¼Œä¸»è¦å…³æ³¨çš„æ˜¯å¯è®­ç»ƒå‚æ•°ï¼Œbufferçš„å·®å¼‚ä¸å½±å“æ¨¡å‹åŠŸèƒ½")
    
    return True


if __name__ == "__main__":
    main()