#!/usr/bin/env python3
"""
åˆ†æä¸ºä»€ä¹ˆä¸åŒè½®æ¬¡çš„æœ¬åœ°chunkæ•°é‡ä¸ä¸€è‡´
ç†è®ºä¸Šæ¯è½®æ¬¡åº”è¯¥ç”Ÿæˆç›¸åŒæ•°é‡çš„chunk
"""

import sqlite3
import os
import hashlib
from datetime import datetime

def analyze_chunk_count_inconsistency():
    """åˆ†æchunkæ•°é‡ä¸ä¸€è‡´çš„åŸå› """
    print("ğŸ” åˆ†æï¼šä¸ºä»€ä¹ˆä¸åŒè½®æ¬¡çš„æœ¬åœ°chunkæ•°é‡ä¸ä¸€è‡´ï¼Ÿ")
    print("=" * 80)
    
    base_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/tmp"
    client_dbs = {
        1: os.path.join(base_path, "client_1", "client_1_chunks.db"),
        2: os.path.join(base_path, "client_2", "client_2_chunks.db"), 
        3: os.path.join(base_path, "client_3", "client_3_chunks.db")
    }
    
    empty_hash = hashlib.sha256(b'').hexdigest()
    
    for client_id, db_path in client_dbs.items():
        print(f"\n{'='*70}")
        print(f"ğŸ” å®¢æˆ·ç«¯ {client_id} - æœ¬åœ°chunkç”Ÿæˆåˆ†æ")
        print("=" * 70)
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        try:
            # 1. åˆ†ææ¯ä¸ªè½®æ¬¡çš„æœ¬åœ°chunkç”Ÿæˆæƒ…å†µ
            print("ğŸ“Š æ¯è½®æ¬¡æœ¬åœ°chunkè¯¦ç»†ç»Ÿè®¡:")
            cursor.execute("""
                SELECT round_num, 
                       COUNT(*) as total_chunks,
                       SUM(CASE WHEN chunk_hash = ? THEN 1 ELSE 0 END) as empty_chunks,
                       SUM(CASE WHEN chunk_hash != ? THEN 1 ELSE 0 END) as non_empty_chunks
                FROM chunk_metadata 
                GROUP BY round_num 
                ORDER BY round_num
            """, (empty_hash, empty_hash))
            
            local_stats = cursor.fetchall()
            
            for round_num, total, empty, non_empty in local_stats:
                print(f"   è½®æ¬¡{round_num}: æ€»è®¡{total}ä¸ªchunk (ç©º:{empty}, éç©º:{non_empty})")
            
            # 2. è¯¦ç»†æŸ¥çœ‹æ¯ä¸ªè½®æ¬¡çš„chunk_metadataè®°å½•
            print(f"\nğŸ“‹ chunk_metadataè¡¨è¯¦ç»†è®°å½•:")
            cursor.execute("""
                SELECT round_num, chunk_id, chunk_hash, created_at, 
                       CASE WHEN chunk_hash = ? THEN 'ç©ºchunk' ELSE 'éç©ºchunk' END as chunk_type
                FROM chunk_metadata 
                ORDER BY round_num, chunk_id
            """, (empty_hash,))
            
            metadata_records = cursor.fetchall()
            
            current_round = None
            for round_num, chunk_id, chunk_hash, created_at, chunk_type in metadata_records:
                if round_num != current_round:
                    print(f"\n   ã€è½®æ¬¡ {round_num}ã€‘")
                    current_round = round_num
                
                try:
                    created_time = datetime.fromtimestamp(created_at).strftime('%H:%M:%S')
                except:
                    created_time = str(created_at)
                
                print(f"     chunk_{chunk_id}: {chunk_type} | å“ˆå¸Œ:{chunk_hash[:16]}... | æ—¶é—´:{created_time}")
            
            # 3. æ£€æŸ¥chunk_dataè¡¨ä¸­å¯¹åº”çš„æ•°æ®
            print(f"\nğŸ’¾ chunk_dataè¡¨ä¸­å¯¹åº”çš„æœ¬åœ°chunk:")
            cursor.execute("""
                SELECT cd.chunk_hash, cd.created_at, length(cd.data) as data_size,
                       COUNT(cm.chunk_hash) as metadata_refs
                FROM chunk_data cd
                INNER JOIN chunk_metadata cm ON cd.chunk_hash = cm.chunk_hash
                GROUP BY cd.chunk_hash
                ORDER BY cd.created_at
            """)
            
            data_records = cursor.fetchall()
            
            for chunk_hash, created_at, data_size, refs in data_records:
                try:
                    created_time = datetime.fromtimestamp(created_at).strftime('%H:%M:%S')
                except:
                    created_time = str(created_at)
                
                chunk_type = "ç©ºchunk" if chunk_hash == empty_hash else "éç©ºchunk"
                print(f"   {chunk_type}: å“ˆå¸Œ:{chunk_hash[:16]}... | å¤§å°:{data_size}å­—èŠ‚ | å¼•ç”¨:{refs}æ¬¡ | æ—¶é—´:{created_time}")
            
            # 4. æ£€æŸ¥æ˜¯å¦æœ‰chunk_metadataè®°å½•ä½†æ²¡æœ‰å¯¹åº”chunk_dataçš„æƒ…å†µ
            print(f"\nâ“ æ£€æŸ¥æ•°æ®å®Œæ•´æ€§:")
            cursor.execute("""
                SELECT cm.round_num, cm.chunk_id, cm.chunk_hash
                FROM chunk_metadata cm
                LEFT JOIN chunk_data cd ON cm.chunk_hash = cd.chunk_hash
                WHERE cd.chunk_hash IS NULL
                ORDER BY cm.round_num, cm.chunk_id
            """)
            
            missing_data = cursor.fetchall()
            
            if missing_data:
                print("   âŒ å‘ç°chunk_metadataæœ‰è®°å½•ä½†chunk_dataç¼ºå¤±çš„æƒ…å†µ:")
                for round_num, chunk_id, chunk_hash in missing_data:
                    print(f"     è½®æ¬¡{round_num} chunk_{chunk_id}: {chunk_hash[:16]}...")
            else:
                print("   âœ… æ‰€æœ‰chunk_metadataè®°å½•éƒ½æœ‰å¯¹åº”çš„chunk_data")
            
            # 5. åˆ†ææ¸…ç†ç­–ç•¥çš„å½±å“
            print(f"\nğŸ§¹ æ¸…ç†ç­–ç•¥åˆ†æ:")
            cursor.execute("""
                SELECT COUNT(*) as total_chunks
                FROM chunk_metadata
            """)
            total_metadata = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(*) as total_data
                FROM chunk_data cd
                INNER JOIN chunk_metadata cm ON cd.chunk_hash = cm.chunk_hash
            """)
            preserved_data = cursor.fetchone()[0]
            
            print(f"   chunk_metadataæ€»è®°å½•: {total_metadata}")
            print(f"   chunk_dataä¸­ä¿ç•™çš„æœ¬åœ°æ•°æ®: {len(data_records)}")
            print(f"   æ•°æ®ä¿ç•™ç‡: {len(data_records)/total_metadata*100:.1f}%")
            
        finally:
            conn.close()

    # 6. æ£€æŸ¥æ¸…ç†è§„åˆ™çš„å…·ä½“å®ç°
    print(f"\n{'='*70}")
    print("ğŸ” æ£€æŸ¥æ¸…ç†è§„åˆ™å®ç°")
    print("=" * 70)
    
    chunk_manager_path = "/mnt/g/FLtorrent_combine/FederatedScope-master/federatedscope/core/chunk_manager.py"
    try:
        with open(chunk_manager_path, 'r') as f:
            content = f.read()
        
        # æŸ¥æ‰¾cleanupç›¸å…³çš„ä»£ç 
        import re
        cleanup_methods = re.findall(r'def (cleanup.*?)\(.*?\):', content)
        
        print(f"å‘ç°æ¸…ç†æ–¹æ³•: {cleanup_methods}")
        
        # æŸ¥æ‰¾ä¿ç•™è½®æ¬¡çš„é€»è¾‘
        retention_pattern = r'(retain_rounds|keep_rounds|rounds_to_keep|max_rounds).*?=.*?(\d+)'
        retention_matches = re.findall(retention_pattern, content, re.IGNORECASE)
        
        if retention_matches:
            print(f"å‘ç°è½®æ¬¡ä¿ç•™é…ç½®: {retention_matches}")
        else:
            print("æœªæ‰¾åˆ°æ˜ç¡®çš„è½®æ¬¡ä¿ç•™é…ç½®")
            
    except Exception as e:
        print(f"è¯»å–chunk_manager.pyå¤±è´¥: {e}")

if __name__ == "__main__":
    analyze_chunk_count_inconsistency()